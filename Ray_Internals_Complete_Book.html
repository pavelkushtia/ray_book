<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ray Internals: Complete Technical Guide</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default',
            themeVariables: {
                primaryColor: '#1e3a8a',
                primaryTextColor: '#ffffff',
                primaryBorderColor: '#3b82f6',
                lineColor: '#6b7280',
                background: '#f8fafc'
            }
        });
    </script>
    <style>
        body { font-family: Georgia, serif; line-height: 1.7; color: #1f2937; background: linear-gradient(to bottom, #f8fafc, #e2e8f0); margin: 0; padding: 0; }
        
        /* Cover styles */
        .book-cover { background: linear-gradient(135deg, #1e3a8a 0%, #3b82f6 50%, #60a5fa 100%); color: white; text-align: center; min-height: 100vh; display: flex; align-items: center; justify-content: center; position: relative; overflow: hidden; }
        .cover-pattern { position: absolute; top: 0; left: 0; right: 0; bottom: 0; background: radial-gradient(circle at 20% 20%, rgba(255,255,255,0.1) 0%, transparent 50%), radial-gradient(circle at 80% 80%, rgba(255,255,255,0.1) 0%, transparent 50%); }
        .cover-content { position: relative; z-index: 2; max-width: 800px; padding: 4rem 2rem; }
        .cover-badge { background: rgba(255,255,255,0.2); border: 2px solid rgba(255,255,255,0.3); border-radius: 30px; padding: 0.5rem 1.5rem; font-size: 0.9rem; font-weight: 600; letter-spacing: 1px; margin-bottom: 2rem; display: inline-block; }
        .title-main { display: block; font-size: 5rem; font-weight: 900; margin-bottom: 0.5rem; text-shadow: 2px 2px 4px rgba(0,0,0,0.3); }
        .title-sub { display: block; font-size: 2rem; font-weight: 300; opacity: 0.9; }
        .cover-description { font-size: 1.3rem; line-height: 1.6; margin: 3rem auto; opacity: 0.9; max-width: 600px; }
        .cover-features { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1rem; margin-bottom: 3rem; }
        .feature { background: rgba(255,255,255,0.15); border-radius: 10px; padding: 1rem; font-weight: 600; border: 1px solid rgba(255,255,255,0.2); }
        
        /* Content styles */
        .container { max-width: 1200px; margin: 0 auto; background: white; box-shadow: 0 4px 20px rgba(0,0,0,0.1); padding: 3rem 4rem; }
        .chapter { margin: 4rem 0; padding: 2rem 0; border-bottom: 3px solid #e5e7eb; }
        .chapter-title { background: linear-gradient(135deg, #1e3a8a 0%, #3b82f6 50%, #60a5fa 100%); color: white; font-size: 2.5rem; margin: -2rem -4rem 3rem -4rem; padding: 2rem 4rem; text-align: center; text-shadow: 2px 2px 4px rgba(0,0,0,0.3); border-bottom: 4px solid #d97706; }
        
        /* Typography */
        h1 { color: #1e3a8a; font-size: 2.2rem; margin: 2rem 0 1rem 0; border-bottom: 2px solid #e5e7eb; padding-bottom: 0.5rem; }
        h2 { color: #059669; font-size: 1.8rem; margin: 1.5rem 0 1rem 0; }
        h3 { color: #1f2937; font-size: 1.4rem; margin: 1.2rem 0 0.8rem 0; }
        h4 { color: #6b7280; font-size: 1.1rem; margin: 1rem 0 0.5rem 0; font-weight: 600; }
        
        p { margin-bottom: 1rem; text-align: justify; }
        
        /* Lists */
        ul { margin: 1rem 0; padding-left: 2rem; }
        li { margin-bottom: 0.5rem; }
        
        /* Code styling */
        .codehilite { background: #1e293b; color: #e2e8f0; border-radius: 10px; border-left: 4px solid #1e3a8a; margin: 1.5rem 0; box-shadow: 0 4px 20px rgba(0,0,0,0.1); }
        .codehilite pre { padding: 1.5rem; overflow-x: auto; margin: 0; }
        .codehilite code { background: none; color: inherit; padding: 0; }
        
        code { background: #f1f5f9; padding: 0.2rem 0.4rem; border-radius: 4px; font-family: 'Fira Code', Monaco, monospace; color: #dc2626; font-size: 0.9rem; }
        
        /* Diagram styles */
        .diagram-container { background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%); border: 2px solid #0284c7; border-radius: 15px; margin: 2rem 0; box-shadow: 0 4px 20px rgba(0,0,0,0.1); overflow: hidden; }
        .diagram-header { background: linear-gradient(135deg, #0284c7 0%, #0369a1 100%); color: white; padding: 1rem 1.5rem; display: flex; align-items: center; gap: 0.5rem; font-weight: 600; }
        
        /* Back cover */
        .back-cover { background: linear-gradient(135deg, #059669 0%, #10b981 50%, #34d399 100%); color: white; padding: 4rem 2rem; text-align: center; min-height: 60vh; display: flex; align-items: center; justify-content: center; }
        .back-title { font-size: 3rem; margin-bottom: 2rem; text-shadow: 2px 2px 4px rgba(0,0,0,0.3); }
        
        /* Responsive */
        @media (max-width: 768px) {
            .title-main { font-size: 3rem; }
            .title-sub { font-size: 1.5rem; }
            .container { padding: 2rem; }
            .chapter-title { margin: -2rem -2rem 2rem -2rem; padding: 2rem; }
        }
    </style>
</head>
<body>
    <div class="book-cover">
        <div class="cover-pattern"></div>
        <div class="cover-content">
            <div class="cover-badge">TECHNICAL GUIDE</div>
            <h1 class="cover-title">
                <span class="title-main">Ray Internals</span>
                <span class="title-sub">Complete Architecture Guide</span>
            </h1>
            <div class="cover-description">
                A comprehensive technical deep-dive into Ray's distributed computing architecture, 
                implementation details, and internal systems. Master the internals of one of the 
                most powerful distributed computing frameworks.
            </div>
            <div class="cover-features">
                <div class="feature">‚ú® 13 In-Depth Chapters</div>
                <div class="feature">üèóÔ∏è Interactive Diagrams</div>
                <div class="feature">üíª Code Examples</div>
                <div class="feature">üîß Implementation Details</div>
            </div>
            <div class="cover-meta">
                <strong>Advanced Distributed Computing Series</strong><br>
                Complete Technical Documentation<br>
                Generated June 06, 2025
            </div>
        </div>
    </div>
    
    <div class="container">

        <div class="chapter" id="chapter-1">
            <h1 class="chapter-title">Chapter 1: Part I: Ray Fundamentals</h1>
            <h1>Part I: Ray Fundamentals</h1>

<h2>Table of Contents</h2>

<p>1. [Introduction](#introduction)</p>
<p>2. [Ray Cluster Architecture](#ray-cluster-architecture)</p>
<p>3. [Core Components Overview](#core-components-overview)</p>
<p>4. [Scheduling Architecture](#scheduling-architecture)</p>
<p>5. [Communication Patterns](#communication-patterns)</p>
<p>6. [Resource Management](#resource-management)</p>
<p>7. [Process Architecture](#process-architecture)</p>
<p>8. [Component Interactions](#component-interactions)</p>
<p>9. [System Bootstrap](#system-bootstrap)</p>
<p>10. [Configuration System](#configuration-system)</p>
<p>11. [Performance Characteristics](#performance-characteristics)</p>
<p>12. [Fault Tolerance Overview](#fault-tolerance-overview)</p>
<p>13. [Development and Testing](#development-and-testing)</p>
<p>14. [Best Practices](#best-practices)</p>

<h2>Introduction</h2>

<p>Ray is a distributed computing framework designed for machine learning and AI workloads. This chapter provides a comprehensive overview of Ray's architecture, covering the fundamental components, their interactions, and the overall system design that enables scalable distributed computing.</p>

<h3>What is Ray?</h3>

<p>Ray is an open-source unified framework for scaling AI workloads. It provides:</p>
<ul>
<li><strong>Distributed Computing</strong>: Scale Python workloads across multiple machines</li>
<li><strong>Unified API</strong>: Single interface for tasks, actors, and data processing</li>
<li><strong>Fault Tolerance</strong>: Built-in error handling and recovery mechanisms</li>
<li><strong>Resource Management</strong>: Efficient allocation of CPU, GPU, and memory resources</li>
<li><strong>Ecosystem</strong>: Libraries for ML (Ray Train), reinforcement learning (Ray RLlib), hyperparameter tuning (Ray Tune), and more</li>
</ul>

<h3>Key Features</h3>

<ul>
<li><strong>Multi-level Scheduling</strong>: Task-level, actor-level, and placement group scheduling</li>
<li><strong>Resource-Aware</strong>: CPU, GPU, memory, and custom resource scheduling</li>
<li><strong>Placement Strategies</strong>: PACK, SPREAD, STRICT_PACK, STRICT_SPREAD</li>
<li><strong>Locality Optimization</strong>: Data locality-aware task placement</li>
<li><strong>Dynamic Scaling</strong>: Integration with autoscaler for cluster growth/shrinkage</li>
<li><strong>Label-Based Scheduling</strong>: Node affinity and label constraints</li>
<li><strong>Performance Optimization</strong>: Efficient algorithms for large-scale clusters</li>
</ul>

<h3>Scheduling Hierarchy</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[User Workload] --> B[Core Worker]
    B --> C[Lease Policy]
    C --> D[Raylet Node Manager]
    D --> E[Cluster Task Manager]
    E --> F[Cluster Resource Scheduler]
    F --> G[Scheduling Policies]
    G --> H[Local Task Manager]
    H --> I[Worker Pool]
    
    J[GCS Server] --> K[GCS Actor Scheduler]
    J --> L[GCS Placement Group Scheduler]
    
    K --> F
    L --> F
    
    M[Autoscaler] --> N[Resource Demand Scheduler]
    N --> O[Node Provider]
        </div>
    </div>
</div>
</p>

<h2>Scheduling Architecture Overview</h2>

<h3>Multi-Level Scheduling Architecture</h3>

<p>Ray implements a hierarchical scheduling architecture with multiple decision points:</p>

<h4>1. Client-Side Scheduling</h4>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    A[ray.remote Call] --> B[Core Worker]
    B --> C[Locality-Aware Lease Policy]
    C --> D[Best Node Selection]
    D --> E[Raylet RPC]
        </div>
    </div>
</div>
</p>

<p><strong>Location</strong>: <code>src/ray/core_worker/lease_policy.cc</code></p>

<p>The client-side scheduling makes initial placement decisions based on:</p>
<ul>
<li>Data locality (object location)</li>
<li>Scheduling strategies (spread, node affinity)</li>
<li>Resource requirements</li>
</ul>

<h4>2. Raylet-Level Scheduling</h4>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[Raylet Receives Task] --> B[Cluster Task Manager]
    B --> C[Resource Availability Check]
    C --> D{Resources Available?}
    D -->|Yes| E[Local Task Manager]
    D -->|No| F[Spillback Decision]
    F --> G[Remote Node Selection]
    G --> H[Forward to Remote Raylet]
    E --> I[Worker Assignment]
        </div>
    </div>
</div>
</p>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/cluster_task_manager.cc</code></p>

<h4>3. GCS-Level Scheduling</h4>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[GCS Scheduling Request] --> B{Task Type}
    B -->|Actor Creation| C[GCS Actor Scheduler]
    B -->|Placement Group| D[GCS Placement Group Scheduler]
    C --> E[Cluster Resource Scheduler]
    D --> E
    E --> F[Node Selection]
    F --> G[Resource Reservation]
        </div>
    </div>
</div>
</p>

<p><strong>Location</strong>: <code>src/ray/gcs/gcs_server/gcs_actor_scheduler.cc</code></p>

<h3>Core Scheduling Flow</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant CW as Core Worker
    participant LP as Lease Policy
    participant RM as Raylet Manager
    participant CTM as Cluster Task Manager
    participant CRS as Cluster Resource Scheduler
    participant LTM as Local Task Manager
    participant WP as Worker Pool

    CW->>LP: GetBestNodeForTask()
    LP->>LP: Analyze locality & strategy
    LP->>RM: RequestWorkerLease()
    RM->>CTM: QueueAndScheduleTask()
    CTM->>CRS: GetBestSchedulableNode()
    CRS->>CRS: Apply scheduling policy
    CRS-->>CTM: Selected node
    CTM->>LTM: QueueAndScheduleTask() [if local]
    LTM->>WP: PopWorker()
    WP-->>LTM: Worker instance
    LTM-->>CTM: Task dispatched
        </div>
    </div>
</div>
</p>

<h2>Core Scheduling Components</h2>

<h3>ClusterResourceScheduler</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/cluster_resource_scheduler.h</code></p>

<p>The central coordinator for cluster-wide resource scheduling decisions.</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterResourceScheduler {
  // Core scheduling method
  scheduling::NodeID GetBestSchedulableNode(
      const ResourceRequest &resource_request,
      const rpc::SchedulingStrategy &scheduling_strategy,
      bool actor_creation,
      bool force_spillback,
      const std::string &preferred_node_id,
      int64_t *total_violations,
      bool *is_infeasible);
      
  // Bundle scheduling for placement groups
  SchedulingResult Schedule(
      const std::vector<const ResourceRequest *> &resource_request_list,
      SchedulingOptions options);
}</code></pre>
</div>
</p>

<p><strong>Key Responsibilities</strong>:</p>
<ul>
<li>Node feasibility checking</li>
<li>Resource availability tracking</li>
<li>Scheduling strategy implementation</li>
<li>Placement group bundle scheduling</li>
</ul>

<h3>ClusterTaskManager</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/cluster_task_manager.h</code></p>

<p>Manages task queuing and scheduling at the cluster level.</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
</p>

<p><strong>Scheduling Queues</strong>:</p>
<ul>
<li>`tasks_to_schedule_`: Tasks waiting for resources</li>
<li>`infeasible_tasks_`: Tasks that cannot be scheduled</li>
</ul>

<h3>LocalTaskManager</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/local_task_manager.h</code></p>

<p>Handles local task execution and worker management.</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
</p>

<p><strong>Fairness Policy</strong>: Implements CPU-fair scheduling to prevent resource starvation:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
</p>

<h3>Scheduling Policies</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/policy/</code></p>

<p>Ray implements multiple scheduling policies:</p>

<h4>HybridSchedulingPolicy</h4>
<ul>
<li>Default scheduling strategy</li>
<li>Balances locality and load distribution</li>
<li>Configurable spread threshold</li>
</ul>

<h4>SpreadSchedulingPolicy</h4>
<ul>
<li>Distributes tasks across nodes</li>
<li>Minimizes resource contention</li>
<li>Used for embarrassingly parallel workloads</li>
</ul>

<h4>NodeAffinitySchedulingPolicy</h4>
<ul>
<li>Hard/soft node constraints</li>
<li>Supports spillback on unavailability</li>
<li>Critical for stateful workloads</li>
</ul>

<h4>NodeLabelSchedulingPolicy</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
</p>

<h3>Scheduling Context and Options</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/policy/scheduling_options.h</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
</p>

<h2>Resource Management and Allocation</h2>

<h3>Resource Model</h3>

<p>Ray uses a multi-dimensional resource model:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
</p>

<h3>Resource Request Structure</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
</p>

<h3>NodeResources</h3>

<p><strong>Location</strong>: <code>src/ray/common/scheduling/cluster_resource_data.h</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">struct NodeResources {
  NodeResourceSet total;      // Total node capacity
  NodeResourceSet available; // Currently available
  NodeResourceSet normal_task_resources; // Reserved for tasks
  absl::flat_hash_map<std::string, std::string> labels; // Node labels
  bool object_pulls_queued;   // Object store status
  
  bool IsAvailable(const ResourceRequest &resource_request) const;
  bool IsFeasible(const ResourceRequest &resource_request) const;
  bool HasRequiredLabels(const LabelSelector &label_selector) const;
  float CalculateCriticalResourceUtilization() const;
};</code></pre>
</div>
</p>

<h3>Resource Allocation Algorithm</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">bool ClusterResourceScheduler::IsSchedulable(
    const ResourceRequest &resource_request,
    scheduling::NodeID node_id) const {
  
  return cluster_resource_manager_->HasAvailableResources(
             node_id,
             resource_request,
             /*ignore_object_store_memory_requirement*/ 
             node_id == local_node_id_) &&
         NodeAvailable(node_id);
}</code></pre>
</div>
</p>

<h3>Dynamic Resource Management</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
0</p>

<h3>Resource Binpacking</h3>

<p>Ray implements sophisticated binpacking for resource allocation:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[Resource Request] --> B[Sort by Resource Requirements]
    B --> C[Find Best Fit Node]
    C --> D{Resources Available?}
    D -->|Yes| E[Allocate Resources]
    D -->|No| F[Try Next Node]
    F --> G{More Nodes?}
    G -->|Yes| C
    G -->|No| H[Request Infeasible]
    E --> I[Update Node Resources]
        </div>
    </div>
</div>
</p>

<h2>Task Scheduling Algorithms</h2>

<h3>Hybrid Scheduling Algorithm</h3>

<p><strong>Default Strategy</strong>: Balances locality and load distribution</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
1</p>

<p><strong>Algorithm Steps</strong>:</p>
<p>1. <strong>Score Calculation</strong>: Based on resource utilization</p>
<p>2. <strong>Top-K Selection</strong>: Choose from best k nodes (default: 20% of cluster)</p>
<p>3. <strong>Random Selection</strong>: Within top-k for load balancing</p>

<p><strong>Scoring Function</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
2</p>

<h3>Spread Scheduling Algorithm</h3>

<p><strong>Purpose</strong>: Distribute tasks across maximum number of nodes</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
3</p>

<p><strong>Implementation</strong>:</p>
<ul>
<li>Prioritizes nodes with lowest task count</li>
<li>Avoids resource hotspots</li>
<li>Maximizes fault tolerance</li>
</ul>

<h3>Node Affinity Scheduling</h3>

<p><strong>Hard Affinity</strong>: Must run on specific node</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
4</p>

<p><strong>Soft Affinity</strong>: Prefer specific node but allow spillback</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
5</p>

<h3>Fair Scheduling</h3>

<p><strong>CPU Fair Scheduling</strong>: Prevents starvation across scheduling classes</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
6</p>

<h2>Actor Placement and Scheduling</h2>

<h3>Actor Scheduling Architecture</h3>

<p><strong>Location</strong>: <code>src/ray/gcs/gcs_server/gcs_actor_scheduler.cc</code></p>

<p>Ray provides two actor scheduling modes:</p>

<h4>1. GCS-Based Actor Scheduling</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
7</p>

<h4>2. Raylet-Based Actor Scheduling</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
8</p>

<h3>Actor Resource Requirements</h3>

<p><strong>Placement vs Execution Resources</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
9</p>

<p><strong>Actor Creation Example</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
0</p>

<h3>Actor Lifecycle and Scheduling</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[Actor Creation Request] --> B[GCS Actor Scheduler]
    B --> C{Scheduling Mode}
    C -->|GCS Scheduling| D[Cluster Task Manager]
    C -->|Raylet Scheduling| E[Select Forwarding Node]
    D --> F[Resource Allocation]
    E --> G[Direct Worker Lease]
    F --> H[Worker Assignment]
    G --> H
    H --> I[Actor Initialization]
    I --> J[Ready for Method Calls]
        </div>
    </div>
</div>
</p>

<h3>Actor Scheduling Considerations</h3>

<p><strong>Resource Lifetime</strong>: Actors hold resources for their entire lifetime</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
1</p>

<p><strong>Scheduling Class</strong>: Actors use placement resources for scheduling decisions</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
2</p>

<h2>Placement Group Scheduling</h2>

<h3>Placement Group Architecture</h3>

<p><strong>Location</strong>: <code>src/ray/gcs/gcs_server/gcs_placement_group_scheduler.cc</code></p>

<p>Placement groups enable gang scheduling of related resources across multiple nodes.</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
3</p>

<h3>Bundle Specification</h3>

<p><strong>Location</strong>: <code>src/ray/common/bundle_spec.h</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
4</p>

<h3>Placement Strategies</h3>

<h4>PACK Strategy</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
5</p>
<ul>
<li><strong>Goal</strong>: Minimize number of nodes used</li>
<li><strong>Use Case</strong>: Maximize locality, minimize network overhead</li>
<li><strong>Algorithm</strong>: First-fit decreasing binpacking</li>
</ul>

<h4>SPREAD Strategy</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
6</p>
<ul>
<li><strong>Goal</strong>: Distribute bundles across nodes</li>
<li><strong>Use Case</strong>: Fault tolerance, load distribution</li>
<li><strong>Algorithm</strong>: Round-robin placement with load balancing</li>
</ul>

<h4>STRICT_PACK Strategy</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
7</p>
<ul>
<li><strong>Goal</strong>: All bundles on single node (if possible)</li>
<li><strong>Use Case</strong>: Shared memory, minimal latency</li>
<li><strong>Algorithm</strong>: Single-node placement with fallback</li>
</ul>

<h4>STRICT_SPREAD Strategy</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
8</p>
<ul>
<li><strong>Goal</strong>: Each bundle on different node</li>
<li><strong>Use Case</strong>: Maximum fault tolerance</li>
<li><strong>Algorithm</strong>: One bundle per node constraint</li>
</ul>

<h3>Bundle Scheduling Algorithm</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[Placement Group Request] --> B[Parse Bundles]
    B --> C[Sort by Resource Requirements]
    C --> D[Apply Placement Strategy]
    D --> E{Strategy Type}
    E -->|PACK| F[First-Fit Decreasing]
    E -->|SPREAD| G[Round-Robin Distribution]
    E -->|STRICT_PACK| H[Single Node Placement]
    E -->|STRICT_SPREAD| I[One Bundle Per Node]
    F --> J[Resource Reservation]
    G --> J
    H --> J
    I --> J
    J --> K[Bundle Commitment]
        </div>
    </div>
</div>
</p>

<h3>Bundle Resource Formatting</h3>

<p>Ray formats placement group resources with special naming:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
9</p>

<h3>CPU Fraction Limits</h3>

<p><strong>Purpose</strong>: Prevent placement groups from monopolizing nodes</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
0</p>

<h3>Placement Group Lifecycle</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant User
    participant GCS as GCS PG Scheduler
    participant CRS as Cluster Resource Scheduler
    participant Raylet
    participant Worker

    User->>GCS: ray.util.placement_group()
    GCS->>GCS: Parse bundles & strategy
    GCS->>CRS: Schedule(bundle_list, options)
    CRS->>CRS: Apply placement strategy
    CRS-->>GCS: Selected nodes
    GCS->>Raylet: PrepareBundleResources()
    Raylet-->>GCS: Resources reserved
    GCS->>Raylet: CommitBundleResources()
    Raylet-->>GCS: Resources committed
    GCS-->>User: Placement group ready
    
    User->>Worker: Task with PG scheduling strategy
    Worker->>Raylet: Use PG bundle resources
        </div>
    </div>
</div>
</p>

<h2>Scheduling Strategies</h2>

<h3>Strategy Types and Implementation</h3>

<p>Ray supports multiple scheduling strategies through the <code>rpc::SchedulingStrategy</code> protocol buffer:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
1</p>

<h3>DEFAULT Strategy</h3>

<p><strong>Implementation</strong>: Hybrid policy with configurable parameters</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
2</p>

<p><strong>Algorithm</strong>:</p>
<p>1. Calculate node scores based on resource utilization</p>
<p>2. Select top-k nodes with lowest scores</p>
<p>3. Randomly choose from top-k for load balancing</p>

<h3>SPREAD Strategy</h3>

<p><strong>Purpose</strong>: Maximize distribution across nodes</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
3</p>

<p><strong>Implementation Details</strong>:</p>
<ul>
<li>Prioritizes nodes with fewer running tasks</li>
<li>Considers resource utilization as secondary factor</li>
<li>Useful for embarrassingly parallel workloads</li>
</ul>

<h3>Node Affinity Strategy</h3>

<p><strong>Hard Affinity</strong>: Must run on specific node</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
4</p>

<p><strong>Soft Affinity</strong>: Prefer specific node with fallback</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
5</p>

<h3>Placement Group Strategy</h3>

<p><strong>Bundle-Specific Scheduling</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
6</p>

<h2>Node Affinity and Label-Based Scheduling</h2>

<h3>Node Label Scheduling Policy</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/policy/node_label_scheduling_policy.cc</code></p>

<p>Ray supports sophisticated label-based scheduling for fine-grained node selection:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
7</p>

<h3>Label Matching Implementation</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
8</p>

<h3>Label Selector Usage</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
9</p>

<h3>Node Label Management</h3>

<p><strong>Static Labels</strong>: Set during node startup</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
0</p>

<p><strong>Dynamic Labels</strong>: Updated at runtime</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
1</p>

<h2>Locality-Aware Scheduling</h2>

<h3>Locality-Aware Lease Policy</h3>

<p><strong>Location</strong>: <code>src/ray/core_worker/lease_policy.cc</code></p>

<p>Ray implements data locality-aware scheduling to minimize data movement:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
2</p>

<h3>Locality Calculation</h3>

<p><strong>Criteria</strong>: Node with most object bytes local</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
3</p>

<h3>Locality vs Strategy Priority</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[Task Submission] --> B{Explicit Strategy?}
    B -->|Yes| C[Use Explicit Strategy]
    B -->|No| D[Check Data Locality]
    D --> E{Objects Local?}
    E -->|Yes| F[Select Node with Most Data]
    E -->|No| G[Use Default Strategy]
    C --> H[Schedule Task]
    F --> H
    G --> H
        </div>
    </div>
</div>
</p>

<h3>Locality Testing</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
4</p>

<h2>Cluster Resource Scheduling</h2>

<h3>Cluster Resource Manager</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/cluster_resource_manager.h</code></p>

<p>Maintains global view of cluster resources:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
5</p>

<h3>Resource Synchronization</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    A[ray.remote Call] --> B[Core Worker]
    B --> C[Locality-Aware Lease Policy]
    C --> D[Best Node Selection]
    D --> E[Raylet RPC]
        </div>
    </div>
</div>
0</p>

<h3>Resource Reporting</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/scheduler_resource_reporter.cc</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
6</p>

<h2>Autoscaler Integration</h2>

<h3>Resource Demand Scheduler</h3>

<p><strong>Location</strong>: <code>python/ray/autoscaler/v2/scheduler.py</code></p>

<p>The autoscaler uses sophisticated scheduling algorithms to determine cluster scaling decisions:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
7</p>

<h3>Binpacking Algorithm</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
8</p>

<h3>Placement Group Autoscaling</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
9</p>

<h3>Autoscaler Configuration</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
0</p>

<h2>Performance Characteristics</h2>

<h3>Scheduling Latency</h3>

<p><strong>Typical Latencies</strong>:</p>
<ul>
<li>Local scheduling: 1-5ms</li>
<li>Remote scheduling: 10-50ms</li>
<li>Placement group creation: 100-1000ms</li>
<li>Autoscaler response: 30-300s</li>
</ul>

<h3>Scalability Metrics</h3>

<p><strong>Cluster Size</strong>: Ray scheduling tested up to 1000+ nodes</p>

<p><strong>Task Throughput</strong>:</p>
<ul>
<li>Simple tasks: 100K+ tasks/second</li>
<li>Complex scheduling: 10K+ tasks/second</li>
<li>Placement groups: 100+ groups/second</li>
</ul>

<h3>Memory Usage</h3>

<p><strong>Scheduler Memory Overhead</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
1</p>

<p><strong>Task Queue Memory</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
2</p>

<h3>Performance Optimization</h3>

<p><strong>Top-K Selection</strong>: Reduces scheduling complexity from O(N) to O(K)</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
3</p>

<p><strong>Caching</strong>: Resource views cached to avoid repeated calculations</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
4</p>

<h2>Configuration and Tuning</h2>

<h3>Environment Variables</h3>

<p><strong>Core Scheduling</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
5</p>

<p><strong>Resource Management</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
6</p>

<p><strong>Placement Groups</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
7</p>

<h3>Runtime Configuration</h3>

<p><strong>Cluster Resource Constraints</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
8</p>

<p><strong>Node Type Configuration</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
9</p>

<h3>Performance Tuning</h3>

<p><strong>For High Throughput</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
0</p>

<p><strong>For Low Latency</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
1</p>

<p><strong>For Large Clusters</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
2</p>

<h2>Best Practices</h2>

<h3>Task Scheduling</h3>

<p><strong>1. Use Appropriate Scheduling Strategies</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
3</p>

<p><strong>2. Resource Specification</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
4</p>

<h3>Actor Placement</h3>

<p><strong>1. Consider Resource Lifetime</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
5</p>

<p><strong>2. Use Placement Groups for Related Actors</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
6</p>

<h3>Placement Group Design</h3>

<p><strong>1. Choose Appropriate Strategies</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
7</p>

<p><strong>2. Bundle Size Optimization</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
8</p>

<h3>Autoscaler Optimization</h3>

<p><strong>1. Configure Appropriate Limits</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
9</p>

<p><strong>2. Use Resource Constraints</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
0</p>

<h2>Troubleshooting</h2>

<h3>Common Scheduling Issues</h3>

<p><strong>1. Tasks Stuck in Pending State</strong>:</p>

<p><em>Symptoms</em>: Tasks remain in PENDING_SCHEDULING state</p>
<p><em>Causes</em>:</p>
<ul>
<li>Insufficient cluster resources</li>
<li>Infeasible resource requirements</li>
<li>Node affinity to unavailable nodes</li>
</ul>

<p><em>Debugging</em>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
1</p>

<p><strong>2. Poor Load Balancing</strong>:</p>

<p><em>Symptoms</em>: Some nodes overloaded while others idle</p>
<p><em>Causes</em>:</p>
<ul>
<li>Inappropriate scheduling strategy</li>
<li>Data locality overriding load balancing</li>
<li>Sticky worker assignment</li>
</ul>

<p><em>Solutions</em>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
2</p>

<p><strong>3. Placement Group Creation Failures</strong>:</p>

<p><em>Symptoms</em>: Placement groups fail to create or timeout</p>
<p><em>Causes</em>:</p>
<ul>
<li>Insufficient cluster capacity</li>
<li>Conflicting resource constraints</li>
<li>Network partitions</li>
</ul>

<p><em>Debugging</em>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
3</p>

<h3>Performance Issues</h3>

<p><strong>1. High Scheduling Latency</strong>:</p>

<p><em>Symptoms</em>: Long delays between task submission and execution</p>
<p><em>Causes</em>:</p>
<ul>
<li>Large cluster with inefficient node selection</li>
<li>Complex placement constraints</li>
<li>Resource fragmentation</li>
</ul>

<p><em>Solutions</em>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
4</p>

<p><strong>2. Memory Issues in Scheduler</strong>:</p>

<p><em>Symptoms</em>: Raylet OOM, high memory usage in scheduling components</p>
<p><em>Causes</em>:</p>
<ul>
<li>Large number of queued tasks</li>
<li>Memory leaks in scheduling data structures</li>
<li>Excessive resource tracking overhead</li>
</ul>

<p><em>Solutions</em>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
5</p>

<h3>Debugging Tools</h3>

<p><strong>1. Ray Status Commands</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
6</p>

<p><strong>2. Programmatic Debugging</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
7</p>

<p><strong>3. Logging Configuration</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
8</p>

<h3>Monitoring and Observability</h3>

<p><strong>1. Metrics Collection</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
9</p>

<p><strong>2. Dashboard Integration</strong>:</p>
<ul>
<li>Use Ray Dashboard for real-time cluster monitoring</li>
<li>Monitor resource utilization trends</li>
<li>Track placement group creation success rates</li>
<li>Observe task scheduling patterns</li>
</ul>

<p>This comprehensive guide covers Ray's distributed scheduling system from architecture to implementation details, providing developers and operators with the knowledge needed to effectively use and optimize Ray's scheduling capabilities in production environments.</p>
        </div>
            
        <div class="chapter" id="chapter-2">
            <h1 class="chapter-title">Chapter 2: Part I: Ray Fundamentals</h1>
            <h1>Part I: Ray Fundamentals</h1>


<h2>Table of Contents</h2>

<p>1. [Introduction](#introduction)</p>
<p>2. [Driver Architecture Overview](#driver-architecture-overview)</p>
<p>3. [Driver Lifecycle Deep Dive](#driver-lifecycle-deep-dive)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Driver-GCS Integration](#driver-gcs-integration)</p>
<p>6. [Driver-Raylet Communication](#driver-raylet-communication)</p>
<p>7. [Object Management and References](#object-management-and-references)</p>
<p>8. [Task and Actor Submission](#task-and-actor-submission)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code Navigation Guide](#code-navigation-guide)</p>
<p>12. [Common Patterns and Best Practices](#common-patterns-and-best-practices)</p>
<p>13. [Troubleshooting and Debugging](#troubleshooting-and-debugging)</p>

<h2>Introduction</h2>

<p>The Ray driver is like the conductor of an orchestra - it coordinates all the distributed computation in your Ray cluster. When you run a Python script with <code>ray.init()</code>, that script becomes the <strong>driver process</strong>. The driver is responsible for submitting tasks, creating actors, managing object references, and collecting results from the distributed cluster.</p>

<h3>What Makes the Ray Driver Special?</h3>

<p><strong>Centralized Control with Distributed Execution</strong>: The driver provides a single point of control for your distributed program while execution happens across many machines. Think of it as the "brain" that sends instructions to "hands" (workers) throughout the cluster.</p>

<p><strong>Seamless Local-to-Distributed</strong>: Your Python code looks almost identical whether running locally or on a 1000-node cluster. The driver handles all the complexity of distribution transparently.</p>

<p><strong>Fault-Tolerant Coordination</strong>: The driver can recover from worker failures, network partitions, and other distributed system challenges while maintaining program correctness.</p>

<h3>Core Driver Responsibilities</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üé≠ Driver Process"
        SCRIPT["Python Script<br/>üìù Your application code"]
        RAY_API["Ray API Layer<br/>üîß @ray.remote decorators"]
        CORE_WORKER["CoreWorker<br/>üß† Driver's execution engine"]
    end
    
    subgraph "üåê Cluster Coordination"
        TASK_SUB["Task Submission<br/>üìã Distribute work"]
        ACTOR_MGT["Actor Management<br/>üé≠ Create/destroy actors"]
        OBJ_MGT["Object Management<br/>üíæ Track references"]
        RESULT_COL["Result Collection<br/>üìä Gather outputs"]
    end
    
    subgraph "üîó Communication Channels"
        GCS_CONN["GCS Connection<br/>üèõÔ∏è Global state"]
        RAYLET_CONN["Raylet Connections<br/>üîß Local execution"]
        OBJ_STORE_CONN["Object Store<br/>üíø Data storage"]
    end
    
    SCRIPT --> RAY_API
    RAY_API --> CORE_WORKER
    CORE_WORKER --> TASK_SUB
    CORE_WORKER --> ACTOR_MGT
    CORE_WORKER --> OBJ_MGT
    CORE_WORKER --> RESULT_COL
    
    TASK_SUB --> GCS_CONN
    ACTOR_MGT --> GCS_CONN
    OBJ_MGT --> RAYLET_CONN
    RESULT_COL --> OBJ_STORE_CONN
    
    style SCRIPT fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    style CORE_WORKER fill:#f3e5f5,stroke:#4a148c,stroke-width:3px,color:#000
    style TASK_SUB fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style ACTOR_MGT fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style OBJ_MGT fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
    style RESULT_COL fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style GCS_CONN fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style RAYLET_CONN fill:#fff8e1,stroke:#f57c00,stroke-width:2px,color:#000
    style OBJ_STORE_CONN fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h2>Driver Architecture Overview</h2>

<h3>High-Level Architecture</h3>

<p>The Ray driver is built on a multi-layered architecture where each layer handles specific aspects of distributed computing:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üéØ Application Layer"
        USER_CODE["User Python Code<br/>üìù Your business logic"]
        RAY_DECORATORS["@ray.remote Functions/Classes<br/>üé≠ Distributed annotations"]
    end
    
    subgraph "üîß Ray API Layer"
        RAY_GET["ray.get()<br/>üì• Retrieve results"]
        RAY_PUT["ray.put()<br/>üì§ Store objects"]
        RAY_WAIT["ray.wait()<br/>‚è≥ Wait for completion"]
        RAY_REMOTE["ray.remote()<br/>üöÄ Submit work"]
    end
    
    subgraph "üß† Core Worker Layer"
        TASK_MANAGER["Task Manager<br/>üìã Track submissions"]
        ACTOR_MANAGER["Actor Manager<br/>üé≠ Lifecycle management"]
        OBJECT_MANAGER["Object Manager<br/>üíæ Reference tracking"]
        REF_COUNTER["Reference Counter<br/>üî¢ Memory management"]
    end
    
    subgraph "üåê Transport Layer"
        RPC_CLIENT["RPC Client<br/>üìû Remote calls"]
        SERIALIZER["Serialization<br/>üì¶ Data encoding"]
        CORE_WORKER_CLIENT["CoreWorker Client<br/>üîó Internal communication"]
    end
    
    subgraph "üèõÔ∏è Cluster Services"
        GCS["Global Control Service<br/>üèõÔ∏è Cluster metadata"]
        RAYLET["Raylet<br/>üîß Local scheduling"]
        OBJECT_STORE["Object Store<br/>üíø Distributed storage"]
    end
    
    USER_CODE --> RAY_DECORATORS
    RAY_DECORATORS --> RAY_GET
    RAY_DECORATORS --> RAY_PUT
    RAY_DECORATORS --> RAY_WAIT
    RAY_DECORATORS --> RAY_REMOTE
    
    RAY_GET --> TASK_MANAGER
    RAY_PUT --> OBJECT_MANAGER
    RAY_WAIT --> TASK_MANAGER
    RAY_REMOTE --> TASK_MANAGER
    RAY_REMOTE --> ACTOR_MANAGER
    
    TASK_MANAGER --> RPC_CLIENT
    ACTOR_MANAGER --> RPC_CLIENT
    OBJECT_MANAGER --> SERIALIZER
    REF_COUNTER --> CORE_WORKER_CLIENT
    
    RPC_CLIENT --> GCS
    RPC_CLIENT --> RAYLET
    SERIALIZER --> OBJECT_STORE
    CORE_WORKER_CLIENT --> RAYLET
    
    style USER_CODE fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    style RAY_DECORATORS fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style TASK_MANAGER fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style ACTOR_MANAGER fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style OBJECT_MANAGER fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
    style GCS fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style RAYLET fill:#fff8e1,stroke:#f57c00,stroke-width:2px,color:#000
    style OBJECT_STORE fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h3>Core Components Deep Dive</h3>

<h4>1. CoreWorker - The Heart of the Driver</h4>

<p><strong>Location</strong>: <code>src/ray/core_worker/core_worker.h</code> and <code>src/ray/core_worker/core_worker.cc</code></p>

<p>The CoreWorker is the most important component of the driver. Think of it as the driver's "execution engine" that handles all distributed operations.</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class CoreWorker {
  public:
    /// Constructor for driver process
    CoreWorker(const CoreWorkerOptions &options, const WorkerID &worker_id);
    
    /// Submit a task for remote execution
    Status SubmitTask(const RayFunction &function,
                     const std::vector<std::unique_ptr<TaskArg>> &args,
                     const TaskOptions &task_options,
                     std::vector<rpc::ObjectReference> *returned_refs);
    
    /// Create an actor
    Status CreateActor(const RayFunction &function,
                      const std::vector<std::unique_ptr<TaskArg>> &args,
                      const ActorCreationOptions &actor_creation_options,
                      std::vector<rpc::ObjectReference> *returned_refs);
    
    /// Get objects from the object store
    Status Get(const std::vector<ObjectID> &ids,
              int64_t timeout_ms,
              std::vector<std::shared_ptr<RayObject>> *results);
    
    /// Put an object into the object store
    Status Put(const RayObject &object,
              const std::vector<ObjectID> &contained_object_ids,
              ObjectID *object_id);
};</code></pre>
</div>
</p>

<p><strong>What the CoreWorker Does (In Simple Terms)</strong>:</p>
<ul>
<li><strong>Task Coordinator</strong>: When you call a @ray.remote function, CoreWorker packages it up and sends it to the right worker</li>
<li><strong>Object Tracker</strong>: Keeps track of all the data objects your program creates and where they're stored</li>
<li><strong>Communication Hub</strong>: Manages all the network connections to GCS, raylets, and other workers</li>
<li><strong>Memory Manager</strong>: Handles garbage collection of distributed objects when they're no longer needed</li>
</ul>

<h4>2. Task Management System</h4>

<p><strong>Location</strong>: <code>src/ray/core_worker/task_manager.h</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class TaskManager {
  private:
    /// Map from task ID to task specification and metadata
    absl::flat_hash_map<TaskID, TaskSpec> submittable_tasks_;
    
    /// Tasks that have been submitted but not yet completed
    absl::flat_hash_map<TaskID, rpc::TaskStatus> pending_tasks_;
    
  public:
    /// Add a task that is pending execution
    void AddPendingTask(const TaskID &task_id,
                       const TaskSpec &spec,
                       const std::string &call_site);
    
    /// Mark a task as completed and handle its return values
    void CompletePendingTask(const TaskID &task_id,
                           const rpc::PushTaskReply &reply,
                           const rpc::Address &worker_addr);
    
    /// Handle task failure and potential retry
    void FailPendingTask(const TaskID &task_id,
                        rpc::ErrorType error_type,
                        const Status *status);
};</code></pre>
</div>
</p>

<h4>3. Actor Management System</h4>

<p><strong>Location</strong>: <code>src/ray/core_worker/actor_manager.h</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ActorManager {
  private:
    /// Map from actor ID to actor handle information
    absl::flat_hash_map<ActorID, ActorHandle> actor_handles_;
    
    /// Actors created by this worker
    absl::flat_hash_map<ActorID, std::unique_ptr<ActorCreationState>> created_actors_;
    
  public:
    /// Create a new actor
    Status CreateActor(const TaskSpec &task_spec,
                      const gcs::ActorCreationOptions &options,
                      std::vector<rpc::ObjectReference> *returned_refs);
    
    /// Submit a task to an existing actor
    Status SubmitActorTask(const ActorID &actor_id,
                          const TaskSpec &task_spec,
                          std::vector<rpc::ObjectReference> *returned_refs);
    
    /// Handle actor death and cleanup
    void HandleActorStateNotification(const ActorID &actor_id,
                                    const gcs::ActorTableData &actor_data);
};</code></pre>
</div>
</p>

<h2>Driver Lifecycle Deep Dive</h2>

<h3>Phase 1: Initialization (`ray.init()`)</h3>

<p>When you call <code>ray.init()</code>, a complex initialization sequence begins:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant U as User Script
    participant API as Ray API
    participant CW as CoreWorker
    participant GCS as Global Control Service
    participant R as Local Raylet
    participant OS as Object Store
    
    U->>API: ray.init()
    Note over API: Parse configuration options
    API->>CW: Create CoreWorker instance
    CW->>GCS: Connect to GCS
    GCS-->>CW: Return cluster metadata
    CW->>R: Connect to local raylet
    R-->>CW: Return worker registration
    CW->>OS: Connect to object store
    OS-->>CW: Return object store handle
    CW->>GCS: Register as driver
    GCS-->>CW: Assign WorkerID
    CW-->>API: Initialization complete
    API-->>U: Ready for distributed computing
    
    Note over U,OS: Driver is now fully initialized and connected
        </div>
    </div>
</div>
</p>

<p><strong>Detailed Initialization Steps</strong>:</p>

<p>1. <strong>Configuration Resolution</strong>: Ray determines cluster address, resources, and other settings</p>
<p>2. <strong>CoreWorker Creation</strong>: The main driver execution engine is initialized</p>
<p>3. <strong>GCS Connection</strong>: Establishes connection to cluster metadata service</p>
<p>4. <strong>Raylet Connection</strong>: Connects to local scheduling and execution service</p>
<p>5. <strong>Object Store Connection</strong>: Sets up shared memory access for data storage</p>
<p>6. <strong>Driver Registration</strong>: Registers with GCS as a special "driver" worker type</p>

<p>
<div class="codehilite">
<pre><code class="python">def init(address=None, 
         num_cpus=None,
         num_gpus=None,
         resources=None,
         object_store_memory=None,
         local_mode=False,
         **kwargs):
    """Initialize Ray for distributed computing."""
    
    # Step 1: Process configuration
    config = _load_config(kwargs)
    
    # Step 2: Start or connect to cluster
    if address is None:
        # Start local cluster
        _global_node = ray._private.node.Node(
            head=True,
            shutdown_at_exit=True,
            ray_params=ray_params)
    else:
        # Connect to existing cluster
        ray_params.update_if_absent(redis_address=address)
    
    # Step 3: Initialize CoreWorker
    worker = Worker()
    worker.mode = LOCAL_MODE if local_mode else WORKER_MODE
    
    # Step 4: Connect to services
    gcs_client = GcsClient(address=gcs_address)
    worker.gcs_client = gcs_client
    
    # Step 5: Register as driver
    worker.worker_id = ray._private.utils.compute_driver_id_from_job(
        job_id, ray_params.driver_id)
    
    # CoreWorker handles the rest of initialization
    _global_worker = worker
    worker.check_connected()</code></pre>
</div>
</p>

<h3>Phase 2: Task and Actor Submission</h3>

<h4>Task Submission Flow</h4>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    subgraph "üéØ Python Level"
        FUNC_CALL["Function Call<br/>result = f.remote(args)"]
        RAY_GET["ray.get(result)<br/>Retrieve value"]
    end
    
    subgraph "üîß Ray API Layer"
        REMOTE_FUNC["RemoteFunction<br/>Decorated function wrapper"]
        TASK_SPEC["TaskSpec Creation<br/>Serialize function + args"]
    end
    
    subgraph "üß† CoreWorker"
        TASK_MANAGER["TaskManager<br/>Track pending tasks"]
        RPC_CLIENT["RPC Client<br/>Send to raylet"]
        OBJ_MANAGER["ObjectManager<br/>Handle return refs"]
    end
    
    subgraph "üåê Cluster Services"
        RAYLET["Raylet Scheduler<br/>Find worker"]
        WORKER["Worker Process<br/>Execute task"]
        OBJECT_STORE["Object Store<br/>Store results"]
    end
    
    FUNC_CALL --> REMOTE_FUNC
    REMOTE_FUNC --> TASK_SPEC
    TASK_SPEC --> TASK_MANAGER
    TASK_MANAGER --> RPC_CLIENT
    RPC_CLIENT --> RAYLET
    RAYLET --> WORKER
    WORKER --> OBJECT_STORE
    OBJECT_STORE --> OBJ_MANAGER
    OBJ_MANAGER --> RAY_GET
    
    style FUNC_CALL fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style TASK_SPEC fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style TASK_MANAGER fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style RAYLET fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style WORKER fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
    style OBJECT_STORE fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<p><strong>Code Deep Dive - Task Submission</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/core_worker/core_worker.cc
Status CoreWorker::SubmitTask(const RayFunction &function,
                             const std::vector<std::unique_ptr<TaskArg>> &args,
                             const TaskOptions &task_options,
                             std::vector<rpc::ObjectReference> *returned_refs) {
  
  // Step 1: Create unique task ID
  const TaskID task_id = TaskID::FromRandom();
  
  // Step 2: Build task specification
  TaskSpecBuilder builder;
  builder.SetCommonTaskSpec(task_id, function.GetLanguage(), 
                           function.GetFunctionDescriptor(),
                           job_id_, task_id, /*parent_counter=*/0, 
                           caller_id_, rpc_address_, 
                           task_options.resources,
                           task_options.placement_group_bundle_index);
  
  // Step 3: Add function arguments
  for (const auto &arg : args) {
    if (arg->IsPassedByReference()) {
      builder.AddByRefArg(arg->GetReference());
    } else {
      builder.AddByValueArg(*arg->GetValue());
    }
  }
  
  const TaskSpec task_spec = builder.Build();
  
  // Step 4: Generate return object references
  for (int i = 0; i < task_spec.NumReturns(); i++) {
    returned_refs->emplace_back();
    returned_refs->back().set_object_id(
        ObjectID::FromIndex(task_id, i + 1).Binary());
  }
  
  // Step 5: Submit to task manager for tracking
  task_manager_->AddPendingTask(task_id, task_spec, "");
  
  // Step 6: Send to raylet for scheduling
  return raylet_client_->SubmitTask(task_spec, task_options.concurrency_group_name);
}</code></pre>
</div>
</p>

<h3>Phase 3: Result Collection and Object Management</h3>

<h4>Object Reference System</h4>

<p>Ray uses a sophisticated object reference system where the driver tracks references to distributed objects:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üéØ Driver Process"
        USER_REF["ObjectRef<br/>üè∑Ô∏è User's handle"]
        REF_COUNTER["Reference Counter<br/>üî¢ Track usage"]
        OBJ_MANAGER["Object Manager<br/>üíæ Local tracking"]
    end
    
    subgraph "üåê Distributed Storage"
        OBJ_STORE_1["Object Store 1<br/>üíø Node A storage"]
        OBJ_STORE_2["Object Store 2<br/>üíø Node B storage"]
        OBJ_STORE_3["Object Store 3<br/>üíø Node C storage"]
    end
    
    subgraph "üèõÔ∏è Global Tracking"
        GCS_OBJ_MGR["GCS Object Manager<br/>üóÇÔ∏è Global object directory"]
        OWNER_INFO["Owner Information<br/>üë§ Who created object"]
        LOCATION_INFO["Location Information<br/>üìç Where object lives"]
    end
    
    USER_REF --> REF_COUNTER
    REF_COUNTER --> OBJ_MANAGER
    OBJ_MANAGER --> GCS_OBJ_MGR
    
    GCS_OBJ_MGR --> OWNER_INFO
    GCS_OBJ_MGR --> LOCATION_INFO
    
    LOCATION_INFO --> OBJ_STORE_1
    LOCATION_INFO --> OBJ_STORE_2
    LOCATION_INFO --> OBJ_STORE_3
    
    style USER_REF fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style REF_COUNTER fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style OBJ_MANAGER fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style GCS_OBJ_MGR fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style OBJ_STORE_1 fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
    style OBJ_STORE_2 fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
    style OBJ_STORE_3 fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h3>Phase 4: Cleanup and Shutdown</h3>

<p>When the driver shuts down, it must carefully clean up all distributed resources:</p>

<p>
<div class="codehilite">
<pre><code class="python">def shutdown(verbose=True):
    """Clean shutdown of Ray driver."""
    
    # Step 1: Cancel all pending tasks
    _global_worker.core_worker.cancel_all_tasks()
    
    # Step 2: Destroy all actors created by this driver
    for actor_id in _global_worker.actor_handles:
        _global_worker.core_worker.kill_actor(actor_id, no_restart=True)
    
    # Step 3: Clean up object references
    _global_worker.core_worker.shutdown()
    
    # Step 4: Disconnect from cluster services
    if _global_worker.gcs_client:
        _global_worker.gcs_client.disconnect()
    
    # Step 5: Cleanup local services if running standalone
    if _global_node:
        _global_node.kill_all_processes()</code></pre>
</div>
</p>

<h2>Communication Mechanisms</h2>

<p>The Ray driver uses multiple communication channels optimized for different types of operations:</p>

<h3>1. Driver-to-GCS Communication</h3>

<p><strong>Purpose</strong>: Cluster metadata, actor lifecycle, job management</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant D as Driver
    participant GCS as GCS Server
    participant DB as Metadata Store
    
    Note over D,DB: Actor Creation
    D->>GCS: CreateActor request
    GCS->>DB: Store actor metadata
    GCS-->>D: Actor created (ActorID)
    
    Note over D,DB: Global State Queries
    D->>GCS: Get cluster resources
    GCS->>DB: Query resource state
    GCS-->>D: Resource availability
    
    Note over D,DB: Job Management
    D->>GCS: Submit job metadata
    GCS->>DB: Store job info
    GCS-->>D: Job registered
        </div>
    </div>
</div>
</p>

<p><strong>Code Example - GCS Client</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/gcs/gcs_client/gcs_client.h
class GcsClient {
  public:
    /// Create an actor via GCS
    Status CreateActor(const TaskSpec &task_spec,
                      const gcs::ActorCreationOptions &options,
                      std::vector<rpc::ObjectReference> *returned_refs) {
      
      rpc::CreateActorRequest request;
      request.mutable_task_spec()->CopyFrom(task_spec.GetMessage());
      request.mutable_options()->CopyFrom(options);
      
      return actor_accessor_->AsyncCreateActor(
          request,
          [this, returned_refs](Status status, const rpc::CreateActorReply &reply) {
            if (status.ok()) {
              // Extract actor handle and return references
              for (const auto &ref : reply.returned_refs()) {
                returned_refs->push_back(ref);
              }
            }
          });
    }
};</code></pre>
</div>
</p>

<h3>2. Driver-to-Raylet Communication</h3>

<p><strong>Purpose</strong>: Task submission, resource requests, local scheduling</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "üéØ Driver Operations"
        SUBMIT_TASK["Submit Task<br/>üìã Function + Args"]
        REQUEST_WORKER["Request Worker<br/>üë§ Need execution slot"]
        GET_OBJECT["Get Object<br/>üì• Retrieve data"]
    end
    
    subgraph "üîß Raylet Services"
        SCHEDULER["Task Scheduler<br/>‚öñÔ∏è Find worker"]
        WORKER_POOL["Worker Pool<br/>üë• Manage processes"]
        OBJ_MGR["Object Manager<br/>üíæ Local objects"]
    end
    
    subgraph "üìû Communication Layer"
        RPC_CHANNEL["gRPC Channel<br/>üîó Persistent connection"]
        TASK_QUEUE["Task Queue<br/>üì¨ Pending work"]
        CALLBACK_MGR["Callback Manager<br/>üìû Async responses"]
    end
    
    SUBMIT_TASK --> RPC_CHANNEL
    REQUEST_WORKER --> RPC_CHANNEL
    GET_OBJECT --> RPC_CHANNEL
    
    RPC_CHANNEL --> SCHEDULER
    RPC_CHANNEL --> WORKER_POOL
    RPC_CHANNEL --> OBJ_MGR
    
    SCHEDULER --> TASK_QUEUE
    WORKER_POOL --> CALLBACK_MGR
    OBJ_MGR --> CALLBACK_MGR
    
    style SUBMIT_TASK fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style REQUEST_WORKER fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style GET_OBJECT fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style SCHEDULER fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style WORKER_POOL fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
    style OBJ_MGR fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h3>3. Driver-to-Object Store Communication</h3>

<p><strong>Purpose</strong>: High-bandwidth data transfer, shared memory access</p>

<p>The driver accesses the object store through optimized shared memory interfaces:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/object_store/plasma/client.h
class PlasmaClient {
  public:
    /// Get objects from local object store
    Status Get(const std::vector<ObjectID> &object_ids,
              int64_t timeout_ms,
              std::vector<ObjectBuffer> *object_buffers) {
      
      // Step 1: Check local availability
      std::vector<plasma::ObjectBuffer> results(object_ids.size());
      
      // Step 2: Wait for objects if needed
      Status wait_status = impl_->Wait(object_ids, timeout_ms, &results);
      
      // Step 3: Map shared memory segments
      for (size_t i = 0; i < results.size(); i++) {
        if (results[i].data != nullptr) {
          object_buffers->emplace_back(results[i].data, results[i].data_size);
        }
      }
      
      return wait_status;
    }
    
    /// Put object into local object store  
    Status Put(const ray::ObjectID &object_id,
              const uint8_t *data,
              size_t data_size) {
      
      // Step 1: Create plasma object
      std::shared_ptr<Buffer> buffer;
      Status create_status = impl_->Create(object_id, data_size, &buffer);
      
      // Step 2: Copy data into shared memory
      std::memcpy(buffer->mutable_data(), data, data_size);
      
      // Step 3: Seal object (make immutable)
      return impl_->Seal(object_id);
    }
};</code></pre>
</div>
</p>

<h2>Driver-GCS Integration</h2>

<p>The Global Control Service (GCS) acts as the cluster's "central nervous system" and the driver maintains a close relationship with it:</p>

<h3>Actor Lifecycle Management</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant D as Driver
    participant GCS as GCS Server
    participant SM as State Manager
    participant R as Raylet
    participant W as Worker
    
    Note over D,W: Actor Creation Flow
    D->>GCS: CreateActor(class, args, resources)
    GCS->>SM: Store actor metadata
    GCS->>R: Schedule actor placement
    R->>W: Start worker process
    W->>GCS: Register actor ready
    GCS-->>D: Return ActorHandle
    
    Note over D,W: Actor Method Calls
    D->>R: Submit actor task
    R->>W: Execute method
    W-->>R: Return result
    R-->>D: Task complete
    
    Note over D,W: Actor Death Handling
    W->>GCS: Actor died notification
    GCS->>SM: Update actor state
    GCS->>D: Notify actor dead
    D->>D: Clean up actor handle
        </div>
    </div>
</div>
</p>

<h3>Job Management and Driver Registration</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/gcs/gcs_server/gcs_job_manager.h
class GcsJobManager {
  public:
    /// Register a new driver/job with the cluster
    void HandleAddJob(const rpc::AddJobRequest &request,
                     rpc::AddJobReply *reply,
                     rpc::SendReplyCallback send_reply_callback) {
      
      // Extract job information
      const auto &job_data = request.data();
      const JobID job_id = JobID::FromBinary(job_data.job_id());
      
      // Store job metadata
      auto job_table_data = std::make_shared<rpc::JobTableData>();
      job_table_data->CopyFrom(job_data);
      
      // Add to job table in persistent store
      auto status = gcs_table_storage_->JobTable().Put(
          job_id,
          *job_table_data,
          [send_reply_callback, reply](Status status) {
            reply->set_success(status.ok());
            send_reply_callback(status, nullptr, nullptr);
          });
    }
};</code></pre>
</div>
</p>

<h3>Resource Management Integration</h3>

<p>The driver coordinates with GCS for cluster-wide resource management:</p>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote(num_cpus=4, num_gpus=1, memory=8000)
def gpu_task(data):
    # This task needs specific resources
    return process_on_gpu(data)</code></pre>
</div>
</p>

<h2>Code Navigation Guide</h2>

<h3>Key Entry Points for Driver Functionality</h3>

<h4>1. Python API Layer</h4>
<p><strong>Location</strong>: <code>python/ray/_private/worker.py</code></p>

<p>This is where the user-facing Ray API is implemented:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class TaskManager {
  private:
    /// Map from task ID to task specification and metadata
    absl::flat_hash_map<TaskID, TaskSpec> submittable_tasks_;
    
    /// Tasks that have been submitted but not yet completed
    absl::flat_hash_map<TaskID, rpc::TaskStatus> pending_tasks_;
    
  public:
    /// Add a task that is pending execution
    void AddPendingTask(const TaskID &task_id,
                       const TaskSpec &spec,
                       const std::string &call_site);
    
    /// Mark a task as completed and handle its return values
    void CompletePendingTask(const TaskID &task_id,
                           const rpc::PushTaskReply &reply,
                           const rpc::Address &worker_addr);
    
    /// Handle task failure and potential retry
    void FailPendingTask(const TaskID &task_id,
                        rpc::ErrorType error_type,
                        const Status *status);
};</code></pre>
</div>
0</p>

<h4>2. CoreWorker Implementation</h4>
<p><strong>Location</strong>: <code>src/ray/core_worker/core_worker.{h,cc}</code></p>

<p>The main C++ driver implementation:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class TaskManager {
  private:
    /// Map from task ID to task specification and metadata
    absl::flat_hash_map<TaskID, TaskSpec> submittable_tasks_;
    
    /// Tasks that have been submitted but not yet completed
    absl::flat_hash_map<TaskID, rpc::TaskStatus> pending_tasks_;
    
  public:
    /// Add a task that is pending execution
    void AddPendingTask(const TaskID &task_id,
                       const TaskSpec &spec,
                       const std::string &call_site);
    
    /// Mark a task as completed and handle its return values
    void CompletePendingTask(const TaskID &task_id,
                           const rpc::PushTaskReply &reply,
                           const rpc::Address &worker_addr);
    
    /// Handle task failure and potential retry
    void FailPendingTask(const TaskID &task_id,
                        rpc::ErrorType error_type,
                        const Status *status);
};</code></pre>
</div>
1</p>

<h4>3. Task and Actor Management</h4>
<p><strong>Location</strong>: <code>src/ray/core_worker/task_manager.{h,cc}</code> and <code>src/ray/core_worker/actor_manager.{h,cc}</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class TaskManager {
  private:
    /// Map from task ID to task specification and metadata
    absl::flat_hash_map<TaskID, TaskSpec> submittable_tasks_;
    
    /// Tasks that have been submitted but not yet completed
    absl::flat_hash_map<TaskID, rpc::TaskStatus> pending_tasks_;
    
  public:
    /// Add a task that is pending execution
    void AddPendingTask(const TaskID &task_id,
                       const TaskSpec &spec,
                       const std::string &call_site);
    
    /// Mark a task as completed and handle its return values
    void CompletePendingTask(const TaskID &task_id,
                           const rpc::PushTaskReply &reply,
                           const rpc::Address &worker_addr);
    
    /// Handle task failure and potential retry
    void FailPendingTask(const TaskID &task_id,
                        rpc::ErrorType error_type,
                        const Status *status);
};</code></pre>
</div>
2</p>

<h4>4. Communication Layers</h4>
<p><strong>Location</strong>: <code>src/ray/rpc/</code> and <code>src/ray/core_worker/transport/</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class TaskManager {
  private:
    /// Map from task ID to task specification and metadata
    absl::flat_hash_map<TaskID, TaskSpec> submittable_tasks_;
    
    /// Tasks that have been submitted but not yet completed
    absl::flat_hash_map<TaskID, rpc::TaskStatus> pending_tasks_;
    
  public:
    /// Add a task that is pending execution
    void AddPendingTask(const TaskID &task_id,
                       const TaskSpec &spec,
                       const std::string &call_site);
    
    /// Mark a task as completed and handle its return values
    void CompletePendingTask(const TaskID &task_id,
                           const rpc::PushTaskReply &reply,
                           const rpc::Address &worker_addr);
    
    /// Handle task failure and potential retry
    void FailPendingTask(const TaskID &task_id,
                        rpc::ErrorType error_type,
                        const Status *status);
};</code></pre>
</div>
3</p>

<h3>Debugging and Instrumentation Points</h3>

<h4>1. Driver State Inspection</h4>

<p>
<div class="codehilite">
<pre><code class="cpp">class TaskManager {
  private:
    /// Map from task ID to task specification and metadata
    absl::flat_hash_map<TaskID, TaskSpec> submittable_tasks_;
    
    /// Tasks that have been submitted but not yet completed
    absl::flat_hash_map<TaskID, rpc::TaskStatus> pending_tasks_;
    
  public:
    /// Add a task that is pending execution
    void AddPendingTask(const TaskID &task_id,
                       const TaskSpec &spec,
                       const std::string &call_site);
    
    /// Mark a task as completed and handle its return values
    void CompletePendingTask(const TaskID &task_id,
                           const rpc::PushTaskReply &reply,
                           const rpc::Address &worker_addr);
    
    /// Handle task failure and potential retry
    void FailPendingTask(const TaskID &task_id,
                        rpc::ErrorType error_type,
                        const Status *status);
};</code></pre>
</div>
4</p>

<h4>2. Enable Detailed Logging</h4>

<p>
<div class="codehilite">
<pre><code class="cpp">class TaskManager {
  private:
    /// Map from task ID to task specification and metadata
    absl::flat_hash_map<TaskID, TaskSpec> submittable_tasks_;
    
    /// Tasks that have been submitted but not yet completed
    absl::flat_hash_map<TaskID, rpc::TaskStatus> pending_tasks_;
    
  public:
    /// Add a task that is pending execution
    void AddPendingTask(const TaskID &task_id,
                       const TaskSpec &spec,
                       const std::string &call_site);
    
    /// Mark a task as completed and handle its return values
    void CompletePendingTask(const TaskID &task_id,
                           const rpc::PushTaskReply &reply,
                           const rpc::Address &worker_addr);
    
    /// Handle task failure and potential retry
    void FailPendingTask(const TaskID &task_id,
                        rpc::ErrorType error_type,
                        const Status *status);
};</code></pre>
</div>
5</p>

<h4>3. Ray Status and Debugging Tools</h4>

<p>
<div class="codehilite">
<pre><code class="cpp">class TaskManager {
  private:
    /// Map from task ID to task specification and metadata
    absl::flat_hash_map<TaskID, TaskSpec> submittable_tasks_;
    
    /// Tasks that have been submitted but not yet completed
    absl::flat_hash_map<TaskID, rpc::TaskStatus> pending_tasks_;
    
  public:
    /// Add a task that is pending execution
    void AddPendingTask(const TaskID &task_id,
                       const TaskSpec &spec,
                       const std::string &call_site);
    
    /// Mark a task as completed and handle its return values
    void CompletePendingTask(const TaskID &task_id,
                           const rpc::PushTaskReply &reply,
                           const rpc::Address &worker_addr);
    
    /// Handle task failure and potential retry
    void FailPendingTask(const TaskID &task_id,
                        rpc::ErrorType error_type,
                        const Status *status);
};</code></pre>
</div>
6</p>

<p>This comprehensive guide provides the foundation for understanding Ray's driver implementation. The driver serves as the central coordinator for distributed Ray applications, managing task submission, actor lifecycles, object references, and communication with cluster services through sophisticated APIs and communication protocols.</p>
        </div>
            
        <div class="chapter" id="chapter-3">
            <h1 class="chapter-title">Chapter 3: Part I: Ray Fundamentals</h1>
            <h1>Part I: Ray Fundamentals</h1>

<h2>Table of Contents</h2>

<p>1. [Introduction](#introduction)</p>
<p>2. [Task Architecture Overview](#task-architecture-overview)</p>
<p>3. [Task Creation and Submission](#task-creation-and-submission)</p>
<p>4. [Task Scheduling and Placement](#task-scheduling-and-placement)</p>
<p>5. [Task Execution Engine](#task-execution-engine)</p>
<p>6. [Task Dependencies and Lineage](#task-dependencies-and-lineage)</p>
<p>7. [Error Handling and Retry Logic](#error-handling-and-retry-logic)</p>
<p>8. [Performance Optimization](#performance-optimization)</p>
<p>9. [Code Navigation Guide](#code-navigation-guide)</p>

<h2>Introduction</h2>

<p>Ray tasks are the <strong>fundamental units of computation</strong> in the Ray ecosystem. Think of a task as a <strong>function call that can run anywhere</strong> in your cluster - it could execute on your local machine, a machine in another data center, or even on a different cloud provider. Tasks are stateless, immutable, and designed for maximum parallelism.</p>

<h3>What Makes Ray Tasks Special?</h3>

<p><strong>Stateless Execution</strong>: Tasks don't maintain state between calls, making them easy to distribute, retry, and scale horizontally.</p>

<p><strong>Automatic Parallelism</strong>: When you call a remote function, Ray automatically distributes the work across available workers without you having to think about threads, processes, or network communication.</p>

<p><strong>Fault Tolerance</strong>: If a task fails, Ray can automatically retry it on different machines, ensuring your computation completes even in the face of hardware failures.</p>

<p><strong>Efficient Data Sharing</strong>: Tasks can share large datasets efficiently through Ray's distributed object store without copying data unnecessarily.</p>

<h3>Core Task Concepts</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üìã Task Lifecycle"
        SUBMISSION["Task Submission<br/>üì§ Driver calls remote function"]
        SCHEDULING["Task Scheduling<br/>‚öñÔ∏è Find suitable worker"]
        EXECUTION["Task Execution<br/>‚ö° Run function logic"]
        COMPLETION["Task Completion<br/>‚úÖ Store results"]
    end
    
    subgraph "üîß Task Components"
        TASK_SPEC["Task Specification<br/>üìã Function + arguments"]
        OBJECT_REFS["Object References<br/>üè∑Ô∏è Future results"]
        DEPENDENCIES["Dependencies<br/>üîó Input requirements"]
        RESOURCES["Resource Requirements<br/>üí∞ CPU/GPU/Memory"]
    end
    
    subgraph "üåê Execution Context"
        WORKER_PROCESS["Worker Process<br/>üîß Isolated execution"]
        OBJECT_STORE["Object Store<br/>üíø Shared data"]
        TASK_MANAGER["Task Manager<br/>üìä Lifecycle tracking"]
    end
    
    SUBMISSION --> SCHEDULING
    SCHEDULING --> EXECUTION
    EXECUTION --> COMPLETION
    
    TASK_SPEC --> WORKER_PROCESS
    OBJECT_REFS --> OBJECT_STORE
    DEPENDENCIES --> TASK_MANAGER
    RESOURCES --> WORKER_PROCESS
    
    style SUBMISSION fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    style EXECUTION fill:#e8f5e8,stroke:#1b5e20,stroke-width:3px,color:#000
    style TASK_SPEC fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style WORKER_PROCESS fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h2>Task Architecture Overview</h2>

<h3>High-Level Task System Architecture</h3>

<p>Ray's task system is built on multiple layers that handle different aspects of distributed task execution:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üéØ Application Layer"
        USER_FUNC["@ray.remote Function<br/>üìù User-defined computation"]
        REMOTE_CALL["Function.remote()<br/>üìû Asynchronous invocation"]
        RAY_GET["ray.get()<br/>üì• Result retrieval"]
    end
    
    subgraph "üîß Ray API Layer"
        TASK_FACTORY["Task Factory<br/>üèóÔ∏è Task specification creation"]
        OBJECT_MGR["Object Manager<br/>üè∑Ô∏è Reference tracking"]
        SERIALIZER["Serialization<br/>üì¶ Data encoding"]
    end
    
    subgraph "ÔøΩÔøΩ Core Worker Layer"
        TASK_SUBMITTER["Task Submitter<br/>üìã Dispatch coordination"]
        DEPENDENCY_MGR["Dependency Manager<br/>üîó Input resolution"]
        RESULT_MGR["Result Manager<br/>üìä Output handling"]
    end
    
    subgraph "üåê Cluster Services"
        TASK_SCHEDULER["Task Scheduler<br/>‚öñÔ∏è Worker selection"]
        RAYLET["Raylet<br/>üîß Local coordination"]
        WORKER_POOL["Worker Pool<br/>üë• Process management"]
    end
    
    subgraph "‚ö° Execution Layer"
        WORKER_PROCESS["Worker Process<br/>üéØ Task execution"]
        FUNCTION_RUNTIME["Function Runtime<br/>‚öôÔ∏è Python execution"]
        OBJECT_STORE["Object Store<br/>üíø Data storage"]
    end
    
    USER_FUNC --> TASK_FACTORY
    REMOTE_CALL --> OBJECT_MGR
    RAY_GET --> SERIALIZER
    
    TASK_FACTORY --> TASK_SUBMITTER
    OBJECT_MGR --> DEPENDENCY_MGR
    SERIALIZER --> RESULT_MGR
    
    TASK_SUBMITTER --> TASK_SCHEDULER
    DEPENDENCY_MGR --> RAYLET
    RESULT_MGR --> WORKER_POOL
    
    TASK_SCHEDULER --> WORKER_PROCESS
    RAYLET --> FUNCTION_RUNTIME
    WORKER_POOL --> OBJECT_STORE
    
    style USER_FUNC fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    style REMOTE_CALL fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style TASK_SUBMITTER fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style TASK_SCHEDULER fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style WORKER_PROCESS fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h3>Task vs Actor Comparison</h3>

<p>Understanding the differences between tasks and actors is crucial for designing Ray applications:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "üìã Task Model"
        TASK_STATELESS["Stateless<br/>üîÑ No persistent memory"]
        TASK_IMMUTABLE["Immutable<br/>üîí Cannot change state"]
        TASK_PARALLEL["Massively Parallel<br/>‚ö° Unlimited instances"]
        TASK_EPHEMERAL["Ephemeral<br/>‚è∞ Short-lived execution"]
    end
    
    subgraph "üé≠ Actor Model"
        ACTOR_STATEFUL["Stateful<br/>üíæ Persistent memory"]
        ACTOR_MUTABLE["Mutable<br/>üîß Can change state"]
        ACTOR_SEQUENTIAL["Sequential<br/>üìã Ordered execution"]
        ACTOR_PERSISTENT["Persistent<br/>üè† Long-lived process"]
    end
    
    subgraph "üéØ Use Cases"
        BATCH_PROCESSING["Batch Processing<br/>üìä Data transformation"]
        STREAMING["Streaming Computation<br/>üåä Real-time processing"]
        STATEFUL_SERVICE["Stateful Services<br/>üè™ Databases, caches"]
        COORDINATION["Coordination<br/>ü§ù System orchestration"]
    end
    
    TASK_STATELESS --> BATCH_PROCESSING
    TASK_PARALLEL --> STREAMING
    ACTOR_STATEFUL --> STATEFUL_SERVICE
    ACTOR_PERSISTENT --> COORDINATION
    
    style TASK_STATELESS fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style TASK_PARALLEL fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style ACTOR_STATEFUL fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style ACTOR_PERSISTENT fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style BATCH_PROCESSING fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style STATEFUL_SERVICE fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h2>Task Creation and Submission</h2>

<h3>Phase 1: Function Registration</h3>

<p>When you decorate a function with <code>@ray.remote</code>, Ray prepares it for distributed execution:</p>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote(num_cpus=2, memory=1000)
def process_data(data_chunk, model_params):
    """Example computation-intensive task"""
    import numpy as np
    
    # Simulate data processing
    processed = np.array(data_chunk) * np.array(model_params)
    result = np.sum(processed ** 2)
    
    return {
        'result': result,
        'chunk_size': len(data_chunk),
        'processing_time': time.time()
    }

data_chunks = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
model_params = [0.1, 0.2, 0.3]

futures = [process_data.remote(chunk, model_params) for chunk in data_chunks]

results = ray.get(futures)</code></pre>
</div>
</p>

<p><strong>Behind the Scenes - Function Registration</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="python">def make_function_remote(function, num_cpus, num_gpus, memory, **kwargs):
    """Convert a regular function into a Ray remote function."""
    
    # Step 1: Create function metadata
    function_id = compute_function_id(function)
    
    # Step 2: Register function with driver's core worker
    driver_worker = ray._private.worker.global_worker
    driver_worker.function_actor_manager.export_function(
        function, function_id, num_cpus, num_gpus, memory)
    
    # Step 3: Create remote function wrapper
    def remote(*args, **kwargs):
        return RemoteFunction._remote(
            args=args, kwargs=kwargs,
            num_cpus=num_cpus, num_gpus=num_gpus, memory=memory)
    
    # Step 4: Return enhanced function
    function.remote = remote
    return function</code></pre>
</div>
</p>

<h3>Phase 2: Task Specification Creation</h3>

<p>When you call <code>function.remote()</code>, Ray creates a detailed task specification:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant U as User Code
    participant RF as RemoteFunction
    participant CW as CoreWorker
    participant TS as TaskSubmitter
    participant GCS as GCS
    participant R as Raylet
    
    U->>RF: process_data.remote(chunk, params)
    RF->>CW: Create task specification
    CW->>TS: Build TaskSpec with metadata
    TS->>GCS: Register task dependencies
    GCS->>R: Forward to appropriate raylet
    R->>R: Queue task for scheduling
    RF-->>U: Return ObjectRef immediately
    
    Note over U,R: Task is now in the system pipeline
        </div>
    </div>
</div>
</p>

<p><strong>Detailed Task Specification Code</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/core_worker/core_worker.cc
Status CoreWorker::SubmitTask(const RayFunction &function,
                             const std::vector<std::unique_ptr<TaskArg>> &args,
                             const TaskOptions &task_options,
                             std::vector<rpc::ObjectReference> *returned_refs) {
  
  // Step 1: Generate unique task ID
  const TaskID task_id = TaskID::FromRandom();
  
  // Step 2: Build comprehensive task specification
  TaskSpecBuilder builder;
  builder.SetCommonTaskSpec(
      task_id,                                    // Unique identifier
      function.GetLanguage(),                     // Python/Java/C++
      function.GetFunctionDescriptor(),           // Function metadata
      job_id_,                                    // Current job
      TaskID::Nil(),                             // Parent task (for nested)
      /*parent_counter=*/0,                      // Ordering within parent
      caller_id_,                                // Calling worker ID
      rpc_address_,                              // Return address
      task_options.resources,                    // Resource requirements
      task_options.placement_group_bundle_index  // Placement constraints
  );
  
  // Step 3: Process function arguments
  for (size_t i = 0; i < args.size(); i++) {
    const auto &arg = args[i];
    if (arg->IsPassedByReference()) {
      // Argument is an ObjectRef from another task
      builder.AddByRefArg(arg->GetReference());
    } else {
      // Argument is a direct value (serialized)
      builder.AddByValueArg(*arg->GetValue());
    }
  }
  
  const TaskSpec task_spec = builder.Build();
  
  // Step 4: Create return object references
  for (int i = 0; i < task_spec.NumReturns(); i++) {
    returned_refs->emplace_back();
    returned_refs->back().set_object_id(
        ObjectID::FromIndex(task_id, i + 1).Binary());
    returned_refs->back().set_owner_id(GetWorkerID().Binary());
  }
  
  // Step 5: Submit to task manager for tracking
  task_manager_->AddPendingTask(task_id, task_spec, "user_task");
  
  // Step 6: Forward to appropriate scheduler
  return raylet_client_->SubmitTask(task_spec, "");
}</code></pre>
</div>
</p>

<h3>Phase 3: Argument Processing and Serialization</h3>

<p>Ray carefully handles different types of task arguments:</p>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote
def complex_task(
    simple_value,          # Serialized directly
    numpy_array,           # Efficient serialization
    object_ref,            # Reference to distributed object
    large_dataset,         # Stored in object store
    custom_object          # User-defined class
):
    # Function body
    pass

simple_result = ray.put("large data")                    # Explicit put
array_result = other_task.remote()                       # Task dependency
large_data = np.random.random((1000000,))               # Auto-stored

result = complex_task.remote(
    42,                    # Simple value
    np.array([1, 2, 3]),  # Small array (serialized)
    array_result,          # ObjectRef dependency
    large_data,            # Large data (auto-put)
    MyCustomClass()        # Custom object
)</code></pre>
</div>
</p>

<p><strong>Argument Processing Logic</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/core_worker/core_worker.cc
std::unique_ptr<TaskArg> CreateTaskArg(const py::object &obj) {
  // Check if object is already an ObjectRef
  if (IsObjectRef(obj)) {
    ObjectID object_id = GetObjectID(obj);
    return std::make_unique<TaskArgByReference>(object_id);
  }
  
  // Check object size to decide on storage strategy
  size_t serialized_size = GetSerializedSize(obj);
  
  if (serialized_size > kObjectStoreThreshold) {
    // Large object: store in object store and pass by reference
    ObjectID object_id;
    Status status = Put(obj, &object_id);
    RAY_CHECK_OK(status);
    return std::make_unique<TaskArgByReference>(object_id);
  } else {
    // Small object: serialize and pass by value
    auto serialized_obj = SerializeObject(obj);
    return std::make_unique<TaskArgByValue>(std::move(serialized_obj));
  }
}</code></pre>
</div>
</p>

<h2>Task Scheduling and Placement</h2>

<h3>Cluster-Level Task Scheduling</h3>

<p>Ray's task scheduler makes intelligent decisions about where to run tasks:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üìä Scheduling Inputs"
        TASK_QUEUE["Task Queue<br/>üìã Pending work"]
        RESOURCE_REQ["Resource Requirements<br/>üí∞ CPU/GPU/Memory"]
        NODE_STATE["Node State<br/>üñ•Ô∏è Available resources"]
        LOCALITY["Data Locality<br/>üìç Input object locations"]
    end
    
    subgraph "üß† Scheduling Logic"
        RESOURCE_MATCHING["Resource Matching<br/>‚öñÔ∏è Can node handle task?"]
        LOAD_BALANCING["Load Balancing<br/>üìä Distribute work evenly"]
        LOCALITY_OPT["Locality Optimization<br/>üéØ Minimize data movement"]
        PRIORITY_HANDLING["Priority Handling<br/>üîù Critical tasks first"]
    end
    
    subgraph "üéØ Scheduling Decisions"
        NODE_SELECTION["Node Selection<br/>üñ•Ô∏è Best fit worker"]
        RESOURCE_ALLOCATION["Resource Allocation<br/>üîí Reserve capacity"]
        TASK_DISPATCH["Task Dispatch<br/>üì§ Send to worker"]
    end
    
    TASK_QUEUE --> RESOURCE_MATCHING
    RESOURCE_REQ --> RESOURCE_MATCHING
    NODE_STATE --> LOAD_BALANCING
    LOCALITY --> LOCALITY_OPT
    
    RESOURCE_MATCHING --> NODE_SELECTION
    LOAD_BALANCING --> NODE_SELECTION
    LOCALITY_OPT --> RESOURCE_ALLOCATION
    PRIORITY_HANDLING --> TASK_DISPATCH
    
    style TASK_QUEUE fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style RESOURCE_MATCHING fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style NODE_SELECTION fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style TASK_DISPATCH fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h3>Local Task Scheduling (Raylet)</h3>

<p>Once a task arrives at a raylet, local scheduling decisions are made:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
void LocalTaskManager::ScheduleAndDispatchTasks() {
  // Step 1: Process tasks waiting for dependencies
  SchedulePendingTasks();
  
  // Step 2: Dispatch ready tasks to workers
  DispatchScheduledTasksToWorkers();
  
  // Step 3: Handle task completion and cleanup
  ProcessTaskCompletion();
}

void LocalTaskManager::SchedulePendingTasks() {
  auto it = tasks_to_schedule_.begin();
  while (it != tasks_to_schedule_.end()) {
    const auto &task_id = it->first;
    const auto &task_spec = it->second;
    
    // Check if all dependencies are satisfied
    if (task_dependency_manager_->CheckTaskReady(task_id)) {
      // Check if resources are available
      if (cluster_resource_scheduler_->HasSufficientResource(
              task_spec.GetRequiredResources())) {
        
        // Move to dispatch queue
        tasks_to_dispatch_[task_id] = task_spec;
        it = tasks_to_schedule_.erase(it);
        
        // Reserve resources for this task
        cluster_resource_scheduler_->AllocateTaskResources(
            task_id, task_spec.GetRequiredResources());
      } else {
        ++it;  // Keep waiting for resources
      }
    } else {
      ++it;  // Keep waiting for dependencies
    }
  }
}</code></pre>
</div>
</p>

<h3>Intelligent Worker Selection</h3>

<p>The scheduler considers multiple factors when selecting workers:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "üéØ Selection Criteria"
        RESOURCE_FIT["Resource Fit<br/>‚úÖ Has required CPU/GPU"]
        CURRENT_LOAD["Current Load<br/>üìä Worker utilization"]
        DATA_LOCALITY["Data Locality<br/>üìç Input object location"]
        WORKER_TYPE["Worker Type<br/>üîß Language compatibility"]
    end
    
    subgraph "‚öñÔ∏è Scoring Algorithm"
        RESOURCE_SCORE["Resource Score<br/>üíØ 0-100 based on fit"]
        LOCALITY_SCORE["Locality Score<br/>üíØ 0-100 based on data"]
        LOAD_SCORE["Load Score<br/>üíØ 0-100 based on utilization"]
        COMPOSITE_SCORE["Composite Score<br/>üéØ Weighted combination"]
    end
    
    subgraph "üèÜ Final Decision"
        BEST_WORKER["Best Worker<br/>üëë Highest scoring worker"]
        FALLBACK["Fallback<br/>üîÑ Alternative if first choice fails"]
        QUEUING["Queuing<br/>‚è≥ Wait if no suitable worker"]
    end
    
    RESOURCE_FIT --> RESOURCE_SCORE
    CURRENT_LOAD --> LOAD_SCORE
    DATA_LOCALITY --> LOCALITY_SCORE
    WORKER_TYPE --> COMPOSITE_SCORE
    
    RESOURCE_SCORE --> COMPOSITE_SCORE
    LOCALITY_SCORE --> COMPOSITE_SCORE
    LOAD_SCORE --> COMPOSITE_SCORE
    
    COMPOSITE_SCORE --> BEST_WORKER
    BEST_WORKER --> FALLBACK
    FALLBACK --> QUEUING
    
    style RESOURCE_FIT fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style DATA_LOCALITY fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style COMPOSITE_SCORE fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style BEST_WORKER fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h2>Task Execution Engine</h2>

<h3>Worker Process Task Execution</h3>

<p>Once a task is assigned to a worker, a sophisticated execution engine takes over:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant R as Raylet
    participant W as Worker Process
    participant TE as Task Executor
    participant OS as Object Store
    participant F as Function Runtime
    
    R->>W: Assign task
    W->>TE: Initialize task execution
    TE->>OS: Resolve input dependencies
    OS-->>TE: Return input objects
    TE->>F: Execute user function
    F->>F: Run Python code
    F-->>TE: Return result
    TE->>OS: Store result objects
    TE->>W: Mark task complete
    W->>R: Report task success
    
    Note over R,F: Task execution with dependency resolution
        </div>
    </div>
</div>
</p>

<p><strong>Task Execution Implementation</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="python">class TaskExecutor:
    def execute_task(self, task_spec, task_execution_spec):
        """Execute a single task in the worker process."""
        
        # Step 1: Extract task information
        function_descriptor = task_spec.function_descriptor
        args = task_spec.args
        task_id = task_spec.task_id
        
        # Step 2: Resolve function from registry
        function = worker.function_actor_manager.get_function(function_descriptor)
        
        # Step 3: Resolve input arguments
        resolved_args = []
        for arg in args:
            if arg.is_by_ref:
                # Resolve ObjectRef to actual value
                obj = ray.get(ObjectRef(arg.object_ref.object_id))
                resolved_args.append(obj)
            else:
                # Deserialize direct value
                obj = ray._private.serialization.deserialize(arg.data)
                resolved_args.append(obj)
        
        # Step 4: Execute the function
        try:
            with ray._private.profiling.profile_task(task_id):
                result = function(*resolved_args)
            
            # Step 5: Store result in object store
            if isinstance(result, tuple):
                # Multiple return values
                return_refs = []
                for i, ret_val in enumerate(result):
                    object_id = ObjectID.from_task_and_index(task_id, i + 1)
                    ray.put(ret_val, object_id=object_id)
                    return_refs.append(object_id)
                return return_refs
            else:
                # Single return value
                object_id = ObjectID.from_task_and_index(task_id, 1)
                ray.put(result, object_id=object_id)
                return [object_id]
                
        except Exception as e:
            # Handle task execution error
            error_info = TaskExecutionError(e, traceback.format_exc())
            self._store_task_error(task_id, error_info)
            raise</code></pre>
</div>
</p>

<h3>Dependency Resolution System</h3>

<p>Ray automatically resolves task dependencies before execution:</p>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote
def load_data(filename):
    """Load data from file"""
    import pandas as pd
    return pd.read_csv(filename)

@ray.remote  
def preprocess_data(data):
    """Clean and prepare data"""
    # Remove nulls, normalize, etc.
    cleaned = data.dropna()
    normalized = (cleaned - cleaned.mean()) / cleaned.std()
    return normalized

@ray.remote
def train_model(train_data, test_data):
    """Train ML model"""
    from sklearn.linear_model import LinearRegression
    model = LinearRegression()
    model.fit(train_data[['feature1', 'feature2']], train_data['target'])
    score = model.score(test_data[['feature1', 'feature2']], test_data['target'])
    return {'model': model, 'score': score}

@ray.remote
def evaluate_model(model_data, validation_data):
    """Evaluate trained model"""
    model = model_data['model']
    predictions = model.predict(validation_data[['feature1', 'feature2']])
    accuracy = calculate_accuracy(predictions, validation_data['target'])
    return accuracy

raw_train = load_data.remote("train.csv")        # Independent
raw_test = load_data.remote("test.csv")          # Independent  
raw_val = load_data.remote("validation.csv")    # Independent

clean_train = preprocess_data.remote(raw_train)  # Depends on raw_train
clean_test = preprocess_data.remote(raw_test)    # Depends on raw_test
clean_val = preprocess_data.remote(raw_val)      # Depends on raw_val

model_result = train_model.remote(clean_train, clean_test)  # Depends on both

final_accuracy = evaluate_model.remote(model_result, clean_val)  # Depends on all

print(f"Final model accuracy: {ray.get(final_accuracy)}")</code></pre>
</div>
</p>

<h2>Task Dependencies and Lineage</h2>

<h3>Dependency Graph Management</h3>

<p>Ray maintains a sophisticated dependency graph for tasks:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    subgraph "üìä Data Sources"
        FILE1["load_data('train.csv')<br/>üìÑ Raw training data"]
        FILE2["load_data('test.csv')<br/>üìÑ Raw test data"]
        FILE3["load_data('validation.csv')<br/>üìÑ Raw validation data"]
    end
    
    subgraph "üßπ Preprocessing"
        CLEAN1["preprocess_data(train)<br/>üßπ Clean training data"]
        CLEAN2["preprocess_data(test)<br/>üßπ Clean test data"]
        CLEAN3["preprocess_data(val)<br/>üßπ Clean validation data"]
    end
    
    subgraph "ü§ñ Model Training"
        TRAIN["train_model(clean_train, clean_test)<br/>ü§ñ Trained model"]
    end
    
    subgraph "üìä Evaluation"
        EVAL["evaluate_model(model, clean_val)<br/>üìä Final accuracy"]
    end
    
    FILE1 --> CLEAN1
    FILE2 --> CLEAN2
    FILE3 --> CLEAN3
    
    CLEAN1 --> TRAIN
    CLEAN2 --> TRAIN
    
    TRAIN --> EVAL
    CLEAN3 --> EVAL
    
    style FILE1 fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style FILE2 fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style FILE3 fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style CLEAN1 fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style CLEAN2 fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style CLEAN3 fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style TRAIN fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style EVAL fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h3>Lineage Tracking and Fault Tolerance</h3>

<p>Ray tracks the complete lineage of objects to enable fault tolerance:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/core_worker/reference_count.h
class ReferenceCounter {
 private:
  // Maps object ID to its lineage information
  absl::flat_hash_map<ObjectID, ObjectLineage> object_lineage_map_;
  
  // Maps object ID to the task that created it
  absl::flat_hash_map<ObjectID, TaskID> object_to_task_map_;
  
 public:
  /// Add lineage information when object is created
  void AddObjectLineage(const ObjectID &object_id,
                       const TaskID &task_id,
                       const std::vector<ObjectID> &dependencies) {
    ObjectLineage lineage;
    lineage.task_id = task_id;
    lineage.dependencies = dependencies;
    lineage.creation_time = absl::Now();
    
    object_lineage_map_[object_id] = lineage;
    object_to_task_map_[object_id] = task_id;
  }
  
  /// Reconstruct object by re-executing its task
  Status ReconstructObject(const ObjectID &object_id) {
    auto it = object_lineage_map_.find(object_id);
    if (it == object_lineage_map_.end()) {
      return Status::NotFound("Object lineage not found");
    }
    
    const auto &lineage = it->second;
    
    // First ensure all dependencies are available
    for (const auto &dep_id : lineage.dependencies) {
      if (!IsObjectAvailable(dep_id)) {
        // Recursively reconstruct dependencies
        auto status = ReconstructObject(dep_id);
        if (!status.ok()) {
          return status;
        }
      }
    }
    
    // Re-execute the task that created this object
    return ReExecuteTask(lineage.task_id);
  }
};</code></pre>
</div>
</p>

<p>This comprehensive guide covers the essential aspects of Ray's task system, from creation through execution to fault tolerance. Tasks form the foundation of Ray's distributed computing model, enabling scalable and fault-tolerant parallel computation.</p>
        </div>
            
        <div class="chapter" id="chapter-4">
            <h1 class="chapter-title">Chapter 4: Part I: Ray Fundamentals</h1>
            <h1>Part I: Ray Fundamentals</h1>

<h2>Table of Contents</h2>

<p>1. [Introduction](#introduction)</p>
<p>2. [Actor Architecture Overview](#actor-architecture-overview)</p>
<p>3. [Actor Creation Deep Dive](#actor-creation-deep-dive)</p>
<p>4. [Method Invocation and Execution](#method-invocation-and-execution)</p>
<p>5. [Fault Tolerance and Recovery](#fault-tolerance-and-recovery)</p>
<p>6. [Performance Optimization](#performance-optimization)</p>

<h2>Introduction</h2>

<p>Ray actors are <strong>long-running, stateful workers</strong> that live somewhere in your cluster and can be called like remote objects. Think of an actor as a combination of a <strong>server process</strong> and a <strong>Python object</strong> - it has its own memory, state, and can handle multiple requests over time.</p>

<h3>What Makes Ray Actors Special?</h3>

<p><strong>Stateful Distributed Computing</strong>: Unlike functions that are stateless, actors maintain state between calls. Imagine having a database connection, machine learning model, or game state that persists across multiple operations.</p>

<p><strong>Location Transparency</strong>: You interact with actors using handles that look like regular Python objects, even though the actor might be running on a machine thousands of miles away.</p>

<h3>Core Actor Concepts</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üé≠ Actor Lifecycle"
        CREATION["Actor Creation<br/>üèóÔ∏è Spawn new process"]
        INITIALIZATION["Initialization<br/>üöÄ Run __init__ method"]
        READY["Ready State<br/>‚úÖ Accept method calls"]
        EXECUTION["Method Execution<br/>‚ö° Process requests"]
        TERMINATION["Termination<br/>üíÄ Cleanup and exit"]
    end
    
    CREATION --> INITIALIZATION
    INITIALIZATION --> READY
    READY --> EXECUTION
    EXECUTION --> READY
    EXECUTION --> TERMINATION
    
    style CREATION fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    style READY fill:#e8f5e8,stroke:#1b5e20,stroke-width:3px,color:#000
        </div>
    </div>
</div>
</p>

<h2>Actor Architecture Overview</h2>

<h3>High-Level Actor System Architecture</h3>

<p>Ray's actor system is built on several layers that work together to provide the illusion of stateful, distributed objects:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üéØ User Level"
        ACTOR_CLASS["@ray.remote Actor Class<br/>üìù User-defined behavior"]
        ACTOR_HANDLE["Actor Handle<br/>üé≠ Remote object reference"]
        METHOD_CALLS["Method Calls<br/>üìû actor.method.remote()"]
    end
    
    subgraph "üß† Core Worker Layer"
        ACTOR_MGR["Actor Manager<br/>üé≠ Lifecycle coordination"]
        TASK_SUBMITTER["Task Submitter<br/>üìã Method dispatching"]
        REF_COUNTER["Reference Counter<br/>üî¢ Garbage collection"]
    end
    
    subgraph "üåê Cluster Services"
        GCS_ACTOR_MGR["GCS Actor Manager<br/>üèõÔ∏è Global state"]
        ACTOR_SCHEDULER["Actor Scheduler<br/>‚öñÔ∏è Placement decisions"]
        RAYLET_MGR["Raylet Manager<br/>üîß Local execution"]
    end
    
    ACTOR_CLASS --> ACTOR_MGR
    ACTOR_HANDLE --> TASK_SUBMITTER
    METHOD_CALLS --> REF_COUNTER
    
    ACTOR_MGR --> GCS_ACTOR_MGR
    TASK_SUBMITTER --> ACTOR_SCHEDULER
    REF_COUNTER --> RAYLET_MGR
    
    style ACTOR_CLASS fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    style ACTOR_HANDLE fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style ACTOR_MGR fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h2>Actor Creation Deep Dive</h2>

<h3>Phase 1: Actor Definition and Registration</h3>

<p>When you define an actor class, Ray prepares it for distributed execution:</p>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote(num_cpus=2, num_gpus=1)
class GameServer:
    def __init__(self, max_players=100):
        self.players = {}
        self.max_players = max_players
        self.game_state = "waiting"
    
    def add_player(self, player_id, player_data):
        if len(self.players) < self.max_players:
            self.players[player_id] = player_data
            return True
        return False

game_server = GameServer.remote(max_players=50)</code></pre>
</div>
</p>

<p><strong>Behind the Scenes - Class Registration</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="python">def make_actor(cls, num_cpus, num_gpus, memory, **kwargs):
    """Convert a regular class into a Ray actor class."""
    
    # Step 1: Create actor class metadata
    class_id = compute_class_id(cls)
    
    # Step 2: Register class with driver's core worker
    driver_worker = ray._private.worker.global_worker
    driver_worker.function_actor_manager.export_actor_class(
        cls, class_id, num_cpus, num_gpus, memory)
    
    # Step 3: Create actor handle factory
    def remote(*args, **kwargs):
        return ActorHandle._remote(args=args, kwargs=kwargs)
    
    # Step 4: Return modified class with remote() method
    cls.remote = remote
    return cls</code></pre>
</div>
</p>

<h3>Phase 2: Actor Instance Creation</h3>

<p>When you call <code>ClassName.remote()</code>, a complex creation process begins:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant U as User Code
    participant API as Ray API
    participant CW as CoreWorker
    participant GCS as GCS Server
    participant R as Raylet
    participant AW as Actor Worker
    
    U->>API: GameServer.remote(max_players=50)
    API->>CW: Create actor request
    CW->>GCS: Submit actor creation task
    GCS->>R: Assign actor to node
    R->>AW: Start actor worker process
    AW->>AW: Initialize actor instance
    AW->>GCS: Register actor as ready
    GCS->>CW: Return actor handle
    CW->>API: Return ActorHandle
    API->>U: Return game_server handle
        </div>
    </div>
</div>
</p>

<p><strong>Detailed Actor Creation Code</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/core_worker/core_worker.cc
Status CoreWorker::CreateActor(const RayFunction &function,
                              const std::vector<std::unique_ptr<TaskArg>> &args,
                              const ActorCreationOptions &actor_creation_options,
                              std::vector<rpc::ObjectReference> *returned_refs) {
  
  // Step 1: Generate unique actor ID  
  const ActorID actor_id = ActorID::FromRandom();
  
  // Step 2: Build actor creation task spec
  TaskSpecBuilder builder;
  builder.SetActorCreationTask(
      actor_id, function, args,
      actor_creation_options.max_restarts,
      actor_creation_options.resources);
  
  const TaskSpec task_spec = builder.Build();
  
  // Step 3: Register with actor manager for tracking
  actor_manager_->RegisterActorHandle(actor_id, task_spec);
  
  // Step 4: Submit to GCS for global scheduling
  return gcs_client_->actor_accessor_->AsyncCreateActor(task_spec);
}</code></pre>
</div>
</p>

<h2>Method Invocation and Execution</h2>

<h3>Method Call Flow</h3>

<p>When you call a method on an actor handle, a sophisticated routing and execution process occurs:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant C as Client Code
    participant H as Actor Handle
    participant CW as CoreWorker
    participant R as Raylet
    participant AW as Actor Worker
    participant A as Actor Instance
    
    C->>H: game_server.add_player.remote(id, data)
    H->>CW: Submit actor task
    CW->>R: Route to actor's raylet
    R->>AW: Forward method call
    AW->>A: Invoke add_player(id, data)
    A->>A: Execute method logic
    A-->>AW: Return result
    AW-->>R: Send result
    R-->>CW: Return object reference
    CW-->>H: Return ObjectRef
    H-->>C: Return future result
        </div>
    </div>
</div>
</p>

<h3>Method Execution Engine</h3>

<p>Inside the actor worker, methods are executed by a specialized runtime:</p>

<p>
<div class="codehilite">
<pre><code class="python">class ActorMethodExecutor:
    def __init__(self, actor_instance):
        self.actor_instance = actor_instance
        self.method_queue = queue.Queue()
    
    def _execute_methods(self):
        """Main execution loop for actor methods"""
        while True:
            try:
                # Get next method call
                method_call = self.method_queue.get()
                
                if method_call is None:  # Shutdown signal
                    break
                
                # Extract method info
                method_name = method_call.function_name
                args = method_call.args
                kwargs = method_call.kwargs
                
                # Execute method on actor instance
                method = getattr(self.actor_instance, method_name)
                result = method(*args, **kwargs)
                
                # Store result in object store
                self._store_result(method_call.task_id, result)
                
            except Exception as e:
                # Handle method execution error
                self._store_error(method_call.task_id, e)</code></pre>
</div>
</p>

<h2>Fault Tolerance and Recovery</h2>

<h3>Actor Restart Policies</h3>

<p>Ray provides sophisticated fault tolerance mechanisms for actors:</p>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote(max_restarts=3, max_task_retries=2)
class FaultTolerantActor:
    def __init__(self):
        self.state = {"counter": 0, "last_update": time.time()}
    
    def increment(self):
        self.state["counter"] += 1
        self.state["last_update"] = time.time()
        
        # Simulate occasional failures
        if random.random() < 0.1:
            raise Exception("Simulated failure")
        
        return self.state["counter"]</code></pre>
</div>
</p>

<h3>Failure Detection and Recovery</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant C as Client
    participant H as Actor Handle
    participant GCS as GCS Server
    participant HM as Health Monitor
    participant R as Raylet
    participant AW as Actor Worker
    
    Note over C,AW: Normal Operation
    C->>H: Method call
    H->>AW: Execute method
    AW-->>H: Return result
    
    Note over C,AW: Failure Detection
    HM->>AW: Health check
    AW->>AW: ‚ùå Process crash
    HM->>GCS: Report actor death
    GCS->>GCS: Check restart policy
    
    Note over C,AW: Recovery Process
    GCS->>R: Start new actor instance
    R->>AW: Launch new worker
    AW->>GCS: Register as ready
    
    Note over C,AW: Resume Operation
    C->>H: Retry method call
    H->>AW: Execute on new instance
    AW-->>H: Return result
        </div>
    </div>
</div>
</p>

<p>This comprehensive guide covers the fundamental aspects of Ray's actor system. Actors provide a powerful abstraction for building stateful, distributed applications with strong consistency guarantees and fault tolerance features.</p>
        </div>
            
        <div class="chapter" id="chapter-5">
            <h1 class="chapter-title">Chapter 5: Part I: Ray Fundamentals</h1>
            <h1>Part I: Ray Fundamentals</h1>

<h2>Introduction</h2>

<p>Ray's memory and object reference system is like having a <strong>distributed, shared memory</strong> across your entire cluster. Instead of copying data between machines, Ray creates smart "pointers" (ObjectRefs) that can reference data stored anywhere in the cluster. This enables efficient sharing of large datasets and computation results.</p>

<h3>What Makes Ray's Memory System Special?</h3>

<p><strong>Zero-Copy Data Sharing</strong>: Large objects are stored once and referenced many times without copying.</p>

<p><strong>Automatic Garbage Collection</strong>: Objects are cleaned up automatically when no longer needed.</p>

<p><strong>Location Transparency</strong>: Your code doesn't need to know where data is physically stored.</p>

<p><strong>Fault Tolerance</strong>: Objects can be reconstructed if they're lost due to node failures.</p>

<h2>Architecture Overview</h2>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üéØ User Interface"
        OBJECT_REF["ObjectRef<br/>üè∑Ô∏è Smart pointer to data"]
        RAY_GET["ray.get()<br/>üì• Retrieve object value"]
        RAY_PUT["ray.put()<br/>üì§ Store object in cluster"]
    end
    
    subgraph "üß† Reference Management"
        REF_COUNTER["Reference Counter<br/>üî¢ Track object usage"]
        OWNERSHIP["Ownership Tracking<br/>üë§ Who owns what"]
        LINEAGE["Lineage Tracking<br/>üîó How objects were created"]
    end
    
    subgraph "üíæ Distributed Storage"
        OBJECT_STORE_1["Object Store 1<br/>üíø Node A storage"]
        OBJECT_STORE_2["Object Store 2<br/>üíø Node B storage"]
        OBJECT_STORE_3["Object Store 3<br/>üíø Node C storage"]
    end
    
    subgraph "üèõÔ∏è Global Coordination"
        GCS_OBJECT_MGR["GCS Object Manager<br/>üóÇÔ∏è Global object directory"]
        LOCATION_SERVICE["Location Service<br/>üìç Where is each object?"]
    end
    
    OBJECT_REF --> REF_COUNTER
    RAY_GET --> OWNERSHIP
    RAY_PUT --> LINEAGE
    
    REF_COUNTER --> GCS_OBJECT_MGR
    OWNERSHIP --> LOCATION_SERVICE
    LINEAGE --> OBJECT_STORE_1
    
    GCS_OBJECT_MGR --> OBJECT_STORE_1
    LOCATION_SERVICE --> OBJECT_STORE_2
    OBJECT_STORE_1 --> OBJECT_STORE_3
    
    style OBJECT_REF fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    style REF_COUNTER fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style OBJECT_STORE_1 fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style GCS_OBJECT_MGR fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h2>Object References (ObjectRefs)</h2>

<h3>What is an ObjectRef?</h3>

<p>An ObjectRef is like a "smart pointer" that references data stored somewhere in your Ray cluster:</p>

<p>
<div class="codehilite">
<pre><code class="python">import ray
import numpy as np

large_array = np.random.random((1000000, 100))

object_ref = ray.put(large_array)
print(f"ObjectRef: {object_ref}")

print(f"ObjectRef size in memory: {sys.getsizeof(object_ref)} bytes")

retrieved_array = ray.get(object_ref)
print(f"Retrieved array shape: {retrieved_array.shape}")</code></pre>
</div>
</p>

<h3>ObjectRef Lifecycle</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant U as User Code
    participant CW as CoreWorker
    participant OS as Object Store
    participant GCS as GCS
    participant RC as Reference Counter
    
    U->>CW: ray.put(large_data)
    CW->>OS: Store object
    OS-->>CW: Return ObjectID
    CW->>GCS: Register object metadata
    CW->>RC: Add reference count
    CW-->>U: Return ObjectRef
    
    Note over U,RC: Object is now stored and tracked
    
    U->>CW: ray.get(object_ref)
    CW->>OS: Retrieve object
    OS-->>CW: Return object data
    CW-->>U: Return actual data
    
    Note over U,RC: When ObjectRef goes out of scope...
    
    U->>RC: Reference deleted
    RC->>RC: Decrement count
    RC->>GCS: Count reached zero
    GCS->>OS: Delete object
        </div>
    </div>
</div>
</p>

<h3>Automatic Object Creation</h3>

<p>Objects are automatically stored when returned from remote functions:</p>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote
def create_large_dataset():
    # This creates a large object
    return np.random.random((100000, 1000))

@ray.remote
def process_dataset(data):
    # Process the data
    return np.mean(data, axis=0)

dataset_ref = create_large_dataset.remote()  # Returns ObjectRef immediately

result_ref = process_dataset.remote(dataset_ref)

final_result = ray.get(result_ref)</code></pre>
</div>
</p>

<h2>Distributed Object Store</h2>

<h3>Plasma Object Store</h3>

<p>Ray uses Apache Plasma for high-performance object storage:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/object_store/plasma/client.h
class PlasmaClient {
 public:
  /// Store an object in the plasma store
  Status Put(const ObjectID &object_id,
            const uint8_t *data,
            size_t data_size,
            const uint8_t *metadata = nullptr,
            size_t metadata_size = 0) {
    
    // Step 1: Create plasma object buffer
    std::shared_ptr<Buffer> buffer;
    Status create_status = Create(object_id, data_size, &buffer);
    if (!create_status.ok()) {
      return create_status;
    }
    
    // Step 2: Copy data into shared memory
    std::memcpy(buffer->mutable_data(), data, data_size);
    
    // Step 3: Seal object (make it immutable and available)
    return Seal(object_id);
  }
  
  /// Get objects from the plasma store
  Status Get(const std::vector<ObjectID> &object_ids,
            int64_t timeout_ms,
            std::vector<ObjectBuffer> *object_buffers) {
    
    // Wait for objects to become available
    return impl_->Wait(object_ids, timeout_ms, object_buffers);
  }
};</code></pre>
</div>
</p>

<h3>Multi-Node Object Access</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üñ•Ô∏è Node A"
        TASK_A["Task A<br/>Creates large_data"]
        STORE_A["Object Store A<br/>üíø Stores large_data"]
    end
    
    subgraph "üñ•Ô∏è Node B"
        TASK_B["Task B<br/>Needs large_data"]
        STORE_B["Object Store B<br/>üíø Local cache"]
    end
    
    subgraph "üñ•Ô∏è Node C"  
        TASK_C["Task C<br/>Also needs large_data"]
        STORE_C["Object Store C<br/>üíø Local cache"]
    end
    
    subgraph "üèõÔ∏è Global Directory"
        GCS_DIR["GCS Object Directory<br/>üìç Tracks object locations"]
    end
    
    TASK_A --> STORE_A
    STORE_A --> GCS_DIR
    
    TASK_B --> GCS_DIR
    GCS_DIR --> STORE_A
    STORE_A --> STORE_B
    STORE_B --> TASK_B
    
    TASK_C --> STORE_B
    STORE_B --> STORE_C
    STORE_C --> TASK_C
    
    style TASK_A fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style STORE_A fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style GCS_DIR fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style STORE_B fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h2>Memory Management Patterns</h2>

<h3>Efficient Data Sharing</h3>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote
def load_model():
    """Load a large ML model once"""
    import joblib
    model = joblib.load('large_model.pkl')  # 2GB model
    return model

@ray.remote  
def predict_batch(model_ref, data_batch):
    """Use shared model for prediction"""
    model = ray.get(model_ref)  # Gets reference, not copy
    return model.predict(data_batch)

model_ref = load_model.remote()

predictions = []
for batch in data_batches:
    pred_ref = predict_batch.remote(model_ref, batch)
    predictions.append(pred_ref)

results = ray.get(predictions)</code></pre>
</div>
</p>

<h3>Memory-Efficient Processing</h3>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote
def process_chunk(data_chunk):
    """Process a chunk of data"""
    # Process data and return smaller result
    processed = expensive_computation(data_chunk)
    return summarize(processed)  # Return summary, not full data

large_dataset = load_huge_dataset()  # 100GB dataset
chunk_size = len(large_dataset) // num_workers

chunk_refs = []
for i in range(0, len(large_dataset), chunk_size):
    chunk = large_dataset[i:i + chunk_size]
    chunk_ref = ray.put(chunk)  # Store chunk in object store
    chunk_refs.append(chunk_ref)

result_refs = [process_chunk.remote(chunk_ref) for chunk_ref in chunk_refs]

results = ray.get(result_refs)
final_result = combine_results(results)</code></pre>
</div>
</p>

<h2>Reference Counting and Garbage Collection</h2>

<h3>Automatic Cleanup</h3>

<p>Ray automatically cleans up objects when they're no longer needed:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/core_worker/reference_count.h
class ReferenceCounter {
 private:
  // Track reference counts for each object
  absl::flat_hash_map<ObjectID, int> object_ref_counts_;
  
  // Track which worker owns each object
  absl::flat_hash_map<ObjectID, WorkerID> object_owners_;
  
 public:
  /// Add a reference to an object
  void AddObjectRef(const ObjectID &object_id, const WorkerID &owner_id) {
    object_ref_counts_[object_id]++;
    object_owners_[object_id] = owner_id;
  }
  
  /// Remove a reference to an object
  void RemoveObjectRef(const ObjectID &object_id) {
    auto it = object_ref_counts_.find(object_id);
    if (it != object_ref_counts_.end()) {
      it->second--;
      
      if (it->second == 0) {
        // No more references - schedule for deletion
        ScheduleObjectDeletion(object_id);
        object_ref_counts_.erase(it);
        object_owners_.erase(object_id);
      }
    }
  }
  
 private:
  void ScheduleObjectDeletion(const ObjectID &object_id) {
    // Send deletion request to object store
    deletion_queue_.push(object_id);
  }
};</code></pre>
</div>
</p>

<h3>Manual Memory Management</h3>

<p>You can also manually control object lifecycle:</p>

<p>
<div class="codehilite">
<pre><code class="python">import ray

data = ray.put(large_dataset)

result = process_data.remote(data)
final_result = ray.get(result)

del data  # Remove reference
ray.internal.free([data])  # Force cleanup</code></pre>
</div>
</p>

<h2>Object Reconstruction and Fault Tolerance</h2>

<h3>Lineage-Based Recovery</h3>

<p>Ray can reconstruct lost objects using lineage information:</p>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote
def step1():
    return expensive_computation_1()

@ray.remote  
def step2(data1):
    return expensive_computation_2(data1)

@ray.remote
def step3(data2):
    return expensive_computation_3(data2)

result1 = step1.remote()
result2 = step2.remote(result1)  
result3 = step3.remote(result2)

final_result = ray.get(result3)  # Handles reconstruction transparently</code></pre>
</div>
</p>

<h3>Reconstruction Process</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant App as Application
    participant GCS as GCS
    participant Node1 as Node 1 (Failed)
    participant Node2 as Node 2
    participant RC as Reconstructor
    
    App->>GCS: ray.get(lost_object_ref)
    GCS->>GCS: Object not found in cluster
    GCS->>RC: Reconstruct object using lineage
    RC->>Node2: Re-run task that created object
    Node2->>Node2: Execute task
    Node2->>GCS: Store reconstructed object
    GCS-->>App: Return reconstructed object
    
    Note over App,RC: Transparent reconstruction
        </div>
    </div>
</div>
</p>

<h2>Performance Optimization</h2>

<h3>Object Store Memory Management</h3>

<p>
<div class="codehilite">
<pre><code class="python">ray.init(object_store_memory=8_000_000_000)  # 8GB for object store

print(ray.cluster_resources())

import psutil
object_store_memory = ray._private.utils.get_system_memory() // 2
print(f"Object store memory limit: {object_store_memory / 1e9:.1f} GB")</code></pre>
</div>
</p>

<h3>Best Practices</h3>

<p>
<div class="codehilite">
<pre><code class="python">large_model = load_model()
model_ref = ray.put(large_model)  # Store once

results = [predict.remote(model_ref, batch) for batch in batches]

@ray.remote
def process_large_data(big_data_ref):
    big_data = ray.get(big_data_ref)
    result = expensive_processing(big_data)
    return summarize(result)  # Return summary, not full result

@ray.remote
def pipeline_step1(data):
    return process_step1(data)

@ray.remote  
def pipeline_step2(step1_result_ref):
    # Pass reference, not actual data
    step1_result = ray.get(step1_result_ref)
    return process_step2(step1_result)</code></pre>
</div>
</p>

<p>This comprehensive guide covers Ray's sophisticated memory management system that enables efficient distributed computing with automatic garbage collection and fault tolerance.</p>
        </div>
            
        <div class="chapter" id="chapter-6">
            <h1 class="chapter-title">Chapter 6: Part II: Core Ray Services</h1>
            <h1>Part II: Core Ray Services</h1>


<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Architecture Overview](#architecture-overview)</p>
<p>3. [Core Components](#core-components)</p>
<p>4. [Node Lifecycle Management](#node-lifecycle-management)</p>
<p>5. [Resource Management](#resource-management)</p>
<p>6. [Actor Management](#actor-management)</p>
<p>7. [Job Management](#job-management)</p>
<p>8. [Storage and Persistence](#storage-and-persistence)</p>
<p>9. [Communication and RPC](#communication-and-rpc)</p>
<p>10. [Fault Tolerance and Recovery](#fault-tolerance-and-recovery)</p>
<p>11. [Performance Characteristics](#performance-characteristics)</p>
<p>12. [Implementation Details](#implementation-details)</p>
<p>13. [Code Modification Guidelines](#code-modification-guidelines)</p>

<h2>Introduction</h2>

<p>The GCS (Global Control Service) server is the <strong>central coordination hub</strong> of a Ray cluster. It maintains authoritative global state about all cluster resources, nodes, actors, jobs, and placement groups. The GCS serves as the single source of truth for cluster-wide metadata and coordinates distributed operations across the entire Ray cluster.</p>

<h3>Key Responsibilities</h3>

<p>1. <strong>Node Registration and Health Monitoring</strong>: Track all nodes joining/leaving the cluster</p>
<p>2. <strong>Resource Management</strong>: Coordinate cluster-wide resource allocation and scheduling</p>
<p>3. <strong>Actor Management</strong>: Handle actor creation, placement, and lifecycle</p>
<p>4. <strong>Job Coordination</strong>: Manage job submission, tracking, and cleanup</p>
<p>5. <strong>Metadata Storage</strong>: Persist critical cluster state and configuration</p>
<p>6. <strong>Service Discovery</strong>: Provide endpoints for cluster services</p>

<h2>Architecture Overview</h2>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Ray Cluster Architecture"
        subgraph "GCS Server (Head Node)"
            subgraph "Core Managers"
                NodeMgr["Node Manager<br/>Node lifecycle & health"]
                ResourceMgr["Resource Manager<br/>Cluster resources"]
                ActorMgr["Actor Manager<br/>Actor coordination"]
                JobMgr["Job Manager<br/>Job lifecycle"]
                PlacementMgr["Placement Group Manager<br/>Group scheduling"]
            end
            
            subgraph "Infrastructure"
                Storage["Table Storage<br/>Redis/Memory"]
                PubSub["Pub/Sub System<br/>Event distribution"]
                RPC["gRPC Server<br/>Client communication"]
                KVStore["KV Manager<br/>Configuration store"]
            end
        end
        
        subgraph "Worker Nodes"
            subgraph "Raylet 1"
                RM1["Resource Manager"]
                NM1["Node Manager"]
            end
            subgraph "Raylet 2"
                RM2["Resource Manager"]
                NM2["Node Manager"]
            end
        end
        
        subgraph "External Systems"
            Redis[(Redis Storage)]
            Clients["Ray Clients<br/>Drivers & SDKs"]
            Monitoring["Monitoring<br/>Prometheus/etc"]
        end
    end
    
    NodeMgr <--> RM1
    NodeMgr <--> RM2
    
    ResourceMgr <--> RM1
    ResourceMgr <--> RM2
    
    ActorMgr <--> NM1
    ActorMgr <--> NM2
    
    Storage <--> Redis
    PubSub <--> Storage
    
    RPC <--> Clients
    RPC <--> Monitoring
    
    NodeMgr <--> Storage
    ResourceMgr <--> Storage
    ActorMgr <--> Storage
    JobMgr <--> Storage
    
    style NodeMgr fill:#e1f5fe
    style ResourceMgr fill:#f3e5f5
    style Storage fill:#e8f5e8
    style RPC fill:#fff3e0
        </div>
    </div>
</div>
</p>

<h3>GCS Server Design Principles</h3>

<p>1. <strong>Single Source of Truth</strong>: All authoritative cluster state lives in GCS</p>
<p>2. <strong>Event-Driven Architecture</strong>: State changes trigger cascading updates</p>
<p>3. <strong>Scalable Storage</strong>: Pluggable backend storage (Redis, Memory)</p>
<p>4. <strong>Fault Recovery</strong>: Persistent state enables cluster recovery</p>
<p>5. <strong>Performance Optimization</strong>: Caching and batching for high throughput</p>

<h2>Core Components</h2>

<p>The GCS server consists of several specialized managers working together:</p>

<h3>Component Initialization Order</h3>

<p>From <code>src/ray/gcs/gcs_server/gcs_server.h:140-180</code>:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Main as Main Process
    participant GCS as GCS Server
    participant Storage as Table Storage
    participant Managers as Component Managers
    
    Note over Main,Managers: GCS Server Startup Flow
    
    Main->>GCS: Create GcsServer(config)
    GCS->>Storage: Initialize storage backend
    Storage->>Storage: Connect to Redis/Memory
    
    GCS->>GCS: InitGcsNodeManager()
    GCS->>GCS: InitGcsResourceManager()
    GCS->>GCS: InitGcsJobManager()
    GCS->>GCS: InitGcsActorManager()
    GCS->>GCS: InitGcsPlacementGroupManager()
    GCS->>GCS: InitGcsWorkerManager()
    GCS->>GCS: InitGcsTaskManager()
    
    GCS->>GCS: InitKVManager()
    GCS->>GCS: InitPubSubHandler()
    GCS->>GCS: InitRuntimeEnvManager()
    
    GCS->>Managers: Install event listeners
    GCS->>Main: Start RPC server
    
    Note over Main,Managers: Ready to handle requests
        </div>
    </div>
</div>
</p>

<h3>GCS Server Configuration</h3>

<p>From <code>src/ray/gcs/gcs_server/gcs_server.h:47-62</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">struct GcsServerConfig {
  std::string grpc_server_name = "GcsServer";
  uint16_t grpc_server_port = 0;               // GCS RPC port
  uint16_t grpc_server_thread_num = 1;         // RPC thread pool size
  std::string redis_username;                 // Redis authentication
  std::string redis_password;
  std::string redis_address;                  // Redis host address  
  uint16_t redis_port = 6379;                 // Redis port
  bool enable_redis_ssl = false;              // TLS encryption
  bool retry_redis = true;                    // Connection retry logic
  bool enable_sharding_conn = false;          // Redis sharding
  std::string node_ip_address;                // GCS server IP
  std::string log_dir;                        // Logging directory
  std::string raylet_config_list;             // Raylet configurations
  std::string session_name;                   // Cluster session ID
};</code></pre>
</div>
</p>

<h2>Node Lifecycle Management</h2>

<p>The GCS Node Manager is responsible for tracking all nodes in the cluster and their health status.</p>

<h3>Node State Machine</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
stateDiagram-v2
    [*] --> Registering: Node startup
    Registering --> Alive: Registration successful
    
    Alive --> Draining: Graceful shutdown request
    Alive --> Dead: Node failure detected
    
    Draining --> Dead: Drain timeout/completion
    
    Dead --> [*]: Node cleanup complete
    
    note right of Alive
        Node actively participating
        in cluster operations
    end note
    
    note right of Draining
        Node preparing for shutdown,
        tasks being migrated
    end note
    
    note right of Dead
        Node removed from cluster,
        resources deallocated
    end note
        </div>
    </div>
</div>
</p>

<h3>Node Registration Protocol</h3>

<p>From <code>src/ray/gcs/gcs_server/gcs_node_manager.h:54-62</code>:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Raylet as Raylet Process
    participant GCS as GCS Node Manager
    participant Storage as Table Storage
    participant PubSub as Pub/Sub System
    
    Note over Raylet,PubSub: Node Registration Flow
    
    Raylet->>GCS: RegisterNode(node_info, resources)
    GCS->>GCS: Validate node information
    GCS->>Storage: Store node in alive_nodes table
    Storage-->>GCS: Storage confirmation
    
    GCS->>PubSub: Publish NODE_ADDED event
    PubSub->>PubSub: Notify subscribers
    
    GCS->>GCS: Trigger node_added_listeners
    GCS->>Raylet: RegisterNodeReply(success)
    
    Note over Raylet,PubSub: Node now active in cluster
        </div>
    </div>
</div>
</p>

<p><strong>Node Information Structure:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From gcs.proto - rpc::GcsNodeInfo
message GcsNodeInfo {
  bytes node_id = 1;                    // Unique node identifier
  string node_manager_address = 2;      // Node IP address
  int32 node_manager_port = 3;         // Node manager port
  int32 object_manager_port = 4;       // Object manager port
  string node_name = 5;                // Human-readable name
  map<string, double> resources_total = 6;  // Total node resources
  GcsNodeState state = 7;              // Current node state
  NodeDeathInfo death_info = 8;        // Death information if dead
  int64 start_time_ms = 9;            // Node startup timestamp
}

enum GcsNodeState {
  ALIVE = 0;      // Node operational
  DEAD = 1;       // Node failed/removed
  DRAINING = 2;   // Node shutting down gracefully
}</code></pre>
</div>
</p>

<h3>Health Monitoring and Failure Detection</h3>

<p><strong>Health Check Mechanisms:</strong></p>

<p>1. <strong>Periodic Heartbeats</strong>: Raylets send regular health updates</p>
<p>2. <strong>Resource Reports</strong>: Nodes report resource usage changes</p>
<p>3. <strong>Task Status Updates</strong>: Monitor task execution health</p>
<p>4. <strong>Network Connectivity</strong>: Detect network partitions</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Health Monitoring System"
        subgraph "Detection Methods"
            Heartbeat["Periodic Heartbeats<br/>30s intervals"]
            ResourceReport["Resource Reports<br/>Real-time updates"]
            TaskStatus["Task Status<br/>Execution monitoring"]
            Network["Network Checks<br/>Connection monitoring"]
        end
        
        subgraph "Failure Response"
            Detection["Failure Detection"]
            Cleanup["Resource Cleanup"]
            Redistribution["Task Redistribution"]
            Notification["Event Notification"]
        end
    end
    
    Heartbeat --> Detection
    ResourceReport --> Detection
    TaskStatus --> Detection
    Network --> Detection
    
    Detection --> Cleanup
    Detection --> Redistribution
    Detection --> Notification
    
    style Detection fill:#ff9999
    style Cleanup fill:#ffcc99
    style Redistribution fill:#99ccff
    style Notification fill:#99ff99
        </div>
    </div>
</div>
</p>

<h2>Resource Management</h2>

<p>The GCS Resource Manager maintains a global view of all cluster resources and coordinates scheduling decisions.</p>

<h3>Resource Architecture</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Resource Management Hierarchy"
        subgraph "Global Level (GCS)"
            GlobalView["Global Resource View<br/>Cluster-wide aggregation"]
            Scheduler["Cluster Resource Scheduler<br/>Global scheduling decisions"]
            Policy["Scheduling Policies<br/>Placement strategies"]
        end
        
        subgraph "Node Level (Raylet)"
            NodeResources["Node Resource Manager<br/>Local resource tracking"]
            LocalScheduler["Local Task Manager<br/>Local scheduling"]
            Workers["Worker Pool<br/>Process management"]
        end
        
        subgraph "Task Level"
            TaskRequests["Task Resource Requests<br/>CPU, GPU, memory"]
            PlacementGroups["Placement Groups<br/>Co-location constraints"]
            Reservations["Resource Reservations<br/>Temporary allocations"]
        end
    end
    
    GlobalView <--> NodeResources
    Scheduler <--> LocalScheduler
    Policy <--> PlacementGroups
    
    NodeResources <--> Workers
    LocalScheduler <--> TaskRequests
    Reservations <--> Workers
    
    style GlobalView fill:#e1f5fe
    style Scheduler fill:#f3e5f5
    style NodeResources fill:#e8f5e8
    style TaskRequests fill:#fff3e0
        </div>
    </div>
</div>
</p>

<h3>Resource Types and Management</h3>

<p><strong>Core Resource Types:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// Resource categories managed by GCS
enum ResourceType {
  CPU,           // Compute cores
  GPU,           // Graphics processors  
  MEMORY,        // RAM allocation
  OBJECT_STORE_MEMORY,  // Plasma store memory
  CUSTOM         // User-defined resources
};

// Resource scheduling information
struct ResourceSchedulingState {
  map<string, double> total;      // Total available resources
  map<string, double> available;  // Currently available resources
  map<string, double> used;       // Currently used resources
  vector<TaskSpec> pending_tasks; // Tasks waiting for resources
};</code></pre>
</div>
</p>

<h3>Resource Synchronization Protocol</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Node as Raylet Node
    participant GCS as GCS Resource Manager
    participant Scheduler as Cluster Scheduler
    participant Client as Task Submitter
    
    Note over Node,Client: Resource Update Flow
    
    Node->>GCS: UpdateResources(current_usage)
    GCS->>GCS: Update global resource view
    GCS->>Scheduler: Notify resource changes
    
    Client->>GCS: SubmitTask(resource_requirements)
    GCS->>Scheduler: FindNodeForTask(requirements)
    Scheduler->>Scheduler: Evaluate placement options
    Scheduler->>GCS: NodeAssignment(node_id)
    
    GCS->>Node: ScheduleTask(task_spec)
    Node->>Node: Reserve resources locally
    Node->>GCS: ResourceReservationConfirm()
    
    Note over Node,Client: Task execution begins
        </div>
    </div>
</div>
</p>

<h2>Actor Management</h2>

<p>The GCS Actor Manager handles the distributed coordination of Ray actors, including creation, placement, and lifecycle management.</p>

<h3>Actor Lifecycle Management</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
stateDiagram-v2
    [*] --> Pending: Actor creation request
    Pending --> Alive: Actor successfully started
    Pending --> Failed: Creation failed
    
    Alive --> Restarting: Actor failure (restartable)
    Alive --> Dead: Actor termination
    
    Restarting --> Alive: Restart successful
    Restarting --> Dead: Restart failed/max attempts
    
    Failed --> [*]: Creation cleanup
    Dead --> [*]: Actor cleanup complete
    
    note right of Pending
        Waiting for resource allocation
        and worker assignment
    end note
    
    note right of Alive
        Actor processing tasks,
        state maintained
    end note
    
    note right of Restarting
        Actor failed but configured
        for automatic restart
    end note
        </div>
    </div>
</div>
</p>

<h3>Actor Creation Protocol</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Client as Ray Client
    participant GCS as GCS Actor Manager
    participant Scheduler as Resource Scheduler
    participant Node as Target Raylet
    participant Worker as Actor Worker
    
    Note over Client,Worker: Actor Creation Flow
    
    Client->>GCS: CreateActor(actor_spec, placement_options)
    GCS->>GCS: Generate unique ActorID
    GCS->>Scheduler: RequestWorkerLease(resource_requirements)
    
    Scheduler->>Node: GrantWorkerLease(lease_info)
    Node->>Worker: StartWorker(actor_spec)
    Worker->>Worker: Initialize actor state
    
    Worker->>Node: ActorCreationComplete(actor_id)
    Node->>GCS: ReportActorCreation(actor_id, worker_info)
    GCS->>GCS: Update actor registry
    GCS->>Client: CreateActorReply(actor_handle)
    
    Note over Client,Worker: Actor ready for method calls
        </div>
    </div>
</div>
</p>

<h3>Actor Placement Strategies</h3>

<p><strong>Placement Group Integration:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// Actor placement within placement groups
struct ActorPlacementSpec {
  PlacementGroupID placement_group_id;    // Target placement group
  int bundle_index;                       // Specific bundle in group
  PlacementStrategy strategy;             // PACK, SPREAD, STRICT_PACK
  map<string, double> resource_requirements;  // Resource needs
  vector<NodeID> blacklist_nodes;        // Nodes to avoid
};</code></pre>
</div>
</p>

<h2>Job Management</h2>

<p>The GCS Job Manager coordinates job submission, tracking, and resource cleanup across the cluster.</p>

<h3>Job Lifecycle Architecture</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Job Management System"
        subgraph "Job Coordination"
            Submission["Job Submission<br/>Driver registration"]
            Tracking["Job Tracking<br/>Status monitoring"]
            Cleanup["Job Cleanup<br/>Resource deallocation"]
        end
        
        subgraph "Resource Allocation"
            Resources["Resource Requests<br/>CPU, GPU, memory"]
            Placement["Placement Decisions<br/>Node assignments"]
            Monitoring["Usage Monitoring<br/>Real-time tracking"]
        end
        
        subgraph "Fault Handling"
            Detection["Failure Detection<br/>Job/task failures"]
            Recovery["Recovery Logic<br/>Restart policies"]
            Termination["Job Termination<br/>Cleanup procedures"]
        end
    end
    
    Submission --> Resources
    Tracking --> Monitoring
    Cleanup --> Termination
    
    Resources --> Placement
    Monitoring --> Detection
    Detection --> Recovery
    Recovery --> Termination
    
    style Submission fill:#e1f5fe
    style Resources fill:#f3e5f5
    style Detection fill:#e8f5e8
    style Cleanup fill:#fff3e0
        </div>
    </div>
</div>
</p>

<h3>Job State Management</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">// Job states tracked by GCS
enum JobState {
  PENDING = 0;     // Job submitted, awaiting resources
  RUNNING = 1;     // Job executing tasks
  STOPPED = 2;     // Job terminated normally
  FAILED = 3;      // Job failed due to error
};

// Job information maintained by GCS
struct JobInfo {
  JobID job_id;                          // Unique job identifier
  JobState state;                        // Current job state
  string driver_ip_address;              // Driver node IP
  int64_t driver_pid;                    // Driver process ID
  int64_t start_time;                    // Job start timestamp
  int64_t end_time;                      // Job end timestamp (if finished)
  map<string, double> resource_mapping;  // Allocated resources
  JobConfig config;                      // Job configuration
};</code></pre>
</div>
</p>

<h2>Storage and Persistence</h2>

<p>The GCS uses pluggable storage backends to persist critical cluster state and enable recovery.</p>

<h3>Storage Architecture</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Main as Main Process
    participant GCS as GCS Server
    participant Storage as Table Storage
    participant Managers as Component Managers
    
    Note over Main,Managers: GCS Server Startup Flow
    
    Main->>GCS: Create GcsServer(config)
    GCS->>Storage: Initialize storage backend
    Storage->>Storage: Connect to Redis/Memory
    
    GCS->>GCS: InitGcsNodeManager()
    GCS->>GCS: InitGcsResourceManager()
    GCS->>GCS: InitGcsJobManager()
    GCS->>GCS: InitGcsActorManager()
    GCS->>GCS: InitGcsPlacementGroupManager()
    GCS->>GCS: InitGcsWorkerManager()
    GCS->>GCS: InitGcsTaskManager()
    
    GCS->>GCS: InitKVManager()
    GCS->>GCS: InitPubSubHandler()
    GCS->>GCS: InitRuntimeEnvManager()
    
    GCS->>Managers: Install event listeners
    GCS->>Main: Start RPC server
    
    Note over Main,Managers: Ready to handle requests
        </div>
    </div>
</div>
0</p>

<h3>Storage Configuration Options</h3>

<p>From <code>src/ray/gcs/gcs_server/gcs_server.h:98-104</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">enum class StorageType {
  UNKNOWN = 0,
  IN_MEMORY = 1,      // Fast, non-persistent storage
  REDIS_PERSIST = 2,  // Persistent Redis storage
};

// Storage configuration constants
static constexpr char kInMemoryStorage[] = "memory";
static constexpr char kRedisStorage[] = "redis";</code></pre>
</div>
</p>

<p><strong>Storage Type Selection:</strong></p>

<p>| Storage Type | Use Case | Persistence | Performance | Fault Tolerance |</p>
<p>|-------------|----------|-------------|-------------|-----------------|</p>
<p>| Memory | Development/Testing | No | Highest | None |</p>
<p>| Redis | Production | Yes | High | Full recovery |</p>
<p>| File | Local debugging | Yes | Medium | Local only |</p>

<h3>Data Persistence Patterns</h3>

<p><strong>Critical Data Categories:</strong></p>

<p>1. <strong>Node Registry</strong>: All registered nodes and their states</p>
<p>2. <strong>Actor Registry</strong>: Actor metadata and placement information</p>
<p>3. <strong>Job Registry</strong>: Job specifications and execution state</p>
<p>4. <strong>Resource State</strong>: Cluster resource allocation and usage</p>
<p>5. <strong>Configuration</strong>: Cluster and component configurations</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Main as Main Process
    participant GCS as GCS Server
    participant Storage as Table Storage
    participant Managers as Component Managers
    
    Note over Main,Managers: GCS Server Startup Flow
    
    Main->>GCS: Create GcsServer(config)
    GCS->>Storage: Initialize storage backend
    Storage->>Storage: Connect to Redis/Memory
    
    GCS->>GCS: InitGcsNodeManager()
    GCS->>GCS: InitGcsResourceManager()
    GCS->>GCS: InitGcsJobManager()
    GCS->>GCS: InitGcsActorManager()
    GCS->>GCS: InitGcsPlacementGroupManager()
    GCS->>GCS: InitGcsWorkerManager()
    GCS->>GCS: InitGcsTaskManager()
    
    GCS->>GCS: InitKVManager()
    GCS->>GCS: InitPubSubHandler()
    GCS->>GCS: InitRuntimeEnvManager()
    
    GCS->>Managers: Install event listeners
    GCS->>Main: Start RPC server
    
    Note over Main,Managers: Ready to handle requests
        </div>
    </div>
</div>
1</p>

<h2>Communication and RPC</h2>

<p>The GCS server provides gRPC-based APIs for all cluster components to interact with global state.</p>

<h3>RPC Service Architecture</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Main as Main Process
    participant GCS as GCS Server
    participant Storage as Table Storage
    participant Managers as Component Managers
    
    Note over Main,Managers: GCS Server Startup Flow
    
    Main->>GCS: Create GcsServer(config)
    GCS->>Storage: Initialize storage backend
    Storage->>Storage: Connect to Redis/Memory
    
    GCS->>GCS: InitGcsNodeManager()
    GCS->>GCS: InitGcsResourceManager()
    GCS->>GCS: InitGcsJobManager()
    GCS->>GCS: InitGcsActorManager()
    GCS->>GCS: InitGcsPlacementGroupManager()
    GCS->>GCS: InitGcsWorkerManager()
    GCS->>GCS: InitGcsTaskManager()
    
    GCS->>GCS: InitKVManager()
    GCS->>GCS: InitPubSubHandler()
    GCS->>GCS: InitRuntimeEnvManager()
    
    GCS->>Managers: Install event listeners
    GCS->>Main: Start RPC server
    
    Note over Main,Managers: Ready to handle requests
        </div>
    </div>
</div>
2</p>

<h3>Key RPC Interfaces</h3>

<p><strong>Node Management RPCs:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From gcs_service.proto
service NodeInfoGcsService {
  rpc RegisterNode(RegisterNodeRequest) returns (RegisterNodeReply);
  rpc UnregisterNode(UnregisterNodeRequest) returns (UnregisterNodeReply);
  rpc GetAllNodeInfo(GetAllNodeInfoRequest) returns (GetAllNodeInfoReply);
  rpc CheckAlive(CheckAliveRequest) returns (CheckAliveReply);
  rpc DrainNode(DrainNodeRequest) returns (DrainNodeReply);
}</code></pre>
</div>
</p>

<p><strong>Actor Management RPCs:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">service ActorInfoGcsService {
  rpc CreateActor(CreateActorRequest) returns (CreateActorReply);
  rpc GetActorInfo(GetActorInfoRequest) returns (GetActorInfoReply);
  rpc KillActorViaGcs(KillActorViaGcsRequest) returns (KillActorViaGcsReply);
  rpc ListNamedActors(ListNamedActorsRequest) returns (ListNamedActorsReply);
}</code></pre>
</div>
</p>

<h3>Performance Optimization</h3>

<p><strong>RPC Performance Characteristics:</strong></p>

<p>| Operation Type | Typical Latency | Throughput | Optimization |</p>
<p>|---------------|-----------------|------------|--------------|</p>
<p>| Node registration | 1-5ms | 1K ops/s | Batched updates |</p>
<p>| Actor creation | 5-20ms | 500 ops/s | Async processing |</p>
<p>| Resource queries | < 1ms | 10K ops/s | Local caching |</p>
<p>| Job submission | 2-10ms | 1K ops/s | Pipeline processing |</p>

<h2>Fault Tolerance and Recovery</h2>

<p>The GCS implements comprehensive fault tolerance mechanisms to ensure cluster resilience.</p>

<h3>Recovery Architecture</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Main as Main Process
    participant GCS as GCS Server
    participant Storage as Table Storage
    participant Managers as Component Managers
    
    Note over Main,Managers: GCS Server Startup Flow
    
    Main->>GCS: Create GcsServer(config)
    GCS->>Storage: Initialize storage backend
    Storage->>Storage: Connect to Redis/Memory
    
    GCS->>GCS: InitGcsNodeManager()
    GCS->>GCS: InitGcsResourceManager()
    GCS->>GCS: InitGcsJobManager()
    GCS->>GCS: InitGcsActorManager()
    GCS->>GCS: InitGcsPlacementGroupManager()
    GCS->>GCS: InitGcsWorkerManager()
    GCS->>GCS: InitGcsTaskManager()
    
    GCS->>GCS: InitKVManager()
    GCS->>GCS: InitPubSubHandler()
    GCS->>GCS: InitRuntimeEnvManager()
    
    GCS->>Managers: Install event listeners
    GCS->>Main: Start RPC server
    
    Note over Main,Managers: Ready to handle requests
        </div>
    </div>
</div>
3</p>

<h3>GCS Server Recovery Process</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Main as Main Process
    participant GCS as GCS Server
    participant Storage as Table Storage
    participant Managers as Component Managers
    
    Note over Main,Managers: GCS Server Startup Flow
    
    Main->>GCS: Create GcsServer(config)
    GCS->>Storage: Initialize storage backend
    Storage->>Storage: Connect to Redis/Memory
    
    GCS->>GCS: InitGcsNodeManager()
    GCS->>GCS: InitGcsResourceManager()
    GCS->>GCS: InitGcsJobManager()
    GCS->>GCS: InitGcsActorManager()
    GCS->>GCS: InitGcsPlacementGroupManager()
    GCS->>GCS: InitGcsWorkerManager()
    GCS->>GCS: InitGcsTaskManager()
    
    GCS->>GCS: InitKVManager()
    GCS->>GCS: InitPubSubHandler()
    GCS->>GCS: InitRuntimeEnvManager()
    
    GCS->>Managers: Install event listeners
    GCS->>Main: Start RPC server
    
    Note over Main,Managers: Ready to handle requests
        </div>
    </div>
</div>
4</p>

<h3>Recovery Scenarios</h3>

<p><strong>1. GCS Server Crash:</strong></p>
<ul>
<li>Persistent storage preserves critical state</li>
<li>New GCS instance loads saved data</li>
<li>Nodes re-register and update status</li>
<li>Clients reconnect automatically</li>
</ul>

<p><strong>2. Storage Backend Failure:</strong></p>
<ul>
<li>GCS switches to backup storage</li>
<li>In-memory state provides temporary continuity</li>
<li>Storage recovery restores full persistence</li>
</ul>

<p><strong>3. Network Partition:</strong></p>
<ul>
<li>GCS maintains authoritative state</li>
<li>Nodes operate in degraded mode</li>
<li>State synchronization on partition heal</li>
</ul>

<h2>Performance Characteristics</h2>

<h3>Scalability Metrics</h3>

<p><strong>GCS Server Performance:</strong></p>

<p>| Metric | Small Cluster (10 nodes) | Medium Cluster (100 nodes) | Large Cluster (1000 nodes) |</p>
<p>|--------|---------------------------|-----------------------------|-----------------------------|</p>
<p>| Node registration throughput | 100 ops/s | 500 ops/s | 1K ops/s |</p>
<p>| Actor creation latency | 5ms | 10ms | 20ms |</p>
<p>| Resource query latency | 0.5ms | 1ms | 2ms |</p>
<p>| Memory usage | 100MB | 500MB | 2GB |</p>
<p>| Storage size | 10MB | 100MB | 1GB |</p>

<h3>Optimization Strategies</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Main as Main Process
    participant GCS as GCS Server
    participant Storage as Table Storage
    participant Managers as Component Managers
    
    Note over Main,Managers: GCS Server Startup Flow
    
    Main->>GCS: Create GcsServer(config)
    GCS->>Storage: Initialize storage backend
    Storage->>Storage: Connect to Redis/Memory
    
    GCS->>GCS: InitGcsNodeManager()
    GCS->>GCS: InitGcsResourceManager()
    GCS->>GCS: InitGcsJobManager()
    GCS->>GCS: InitGcsActorManager()
    GCS->>GCS: InitGcsPlacementGroupManager()
    GCS->>GCS: InitGcsWorkerManager()
    GCS->>GCS: InitGcsTaskManager()
    
    GCS->>GCS: InitKVManager()
    GCS->>GCS: InitPubSubHandler()
    GCS->>GCS: InitRuntimeEnvManager()
    
    GCS->>Managers: Install event listeners
    GCS->>Main: Start RPC server
    
    Note over Main,Managers: Ready to handle requests
        </div>
    </div>
</div>
5</p>

<h2>Implementation Details</h2>

<h3>Core Code Structure</h3>

<p><strong>GCS Server Main Loop:</strong></p>

<p>From <code>src/ray/gcs/gcs_server/gcs_server_main.cc:45-190</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">int main(int argc, char *argv[]) {
  // Parse command line arguments
  gflags::ParseCommandLineFlags(&argc, &argv, true);
  
  // Configure logging and stream redirection
  InitShutdownRAII ray_log_shutdown_raii(/*...*/);
  
  // Initialize configuration
  RayConfig::instance().initialize(config_list);
  
  // Create main IO service
  instrumented_io_context main_service(/*enable_lag_probe=*/true);
  
  // Initialize metrics collection
  ray::stats::Init(global_tags, metrics_agent_port, WorkerID::Nil());
  
  // Create and configure GCS server
  ray::gcs::GcsServerConfig gcs_server_config;
  ray::gcs::GcsServer gcs_server(gcs_server_config, main_service);
  
  // Set up signal handlers for graceful shutdown
  boost::asio::signal_set signals(main_service);
  signals.async_wait(shutdown_handler);
  
  // Start the server and run main loop
  gcs_server.Start();
  main_service.run();
}</code></pre>
</div>
</p>

<p><strong>Component Initialization Pattern:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsServer {
  void DoStart(const GcsInitData &gcs_init_data) {
    // Initialize storage backend first
    gcs_table_storage_ = CreateStorage();
    
    // Initialize core managers
    InitGcsNodeManager(gcs_init_data);
    InitGcsResourceManager(gcs_init_data);
    InitGcsJobManager(gcs_init_data);
    InitGcsActorManager(gcs_init_data);
    InitGcsPlacementGroupManager(gcs_init_data);
    
    // Initialize supporting services
    InitKVManager();
    InitPubSubHandler();
    InitRuntimeEnvManager();
    
    // Install cross-component event listeners
    InstallEventListeners();
    
    // Start RPC server
    rpc_server_.Run();
  }
};</code></pre>
</div>
</p>

<h3>Critical Code Paths</h3>

<p><strong>Node Registration Handler:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From gcs.proto - rpc::GcsNodeInfo
message GcsNodeInfo {
  bytes node_id = 1;                    // Unique node identifier
  string node_manager_address = 2;      // Node IP address
  int32 node_manager_port = 3;         // Node manager port
  int32 object_manager_port = 4;       // Object manager port
  string node_name = 5;                // Human-readable name
  map<string, double> resources_total = 6;  // Total node resources
  GcsNodeState state = 7;              // Current node state
  NodeDeathInfo death_info = 8;        // Death information if dead
  int64 start_time_ms = 9;            // Node startup timestamp
}

enum GcsNodeState {
  ALIVE = 0;      // Node operational
  DEAD = 1;       // Node failed/removed
  DRAINING = 2;   // Node shutting down gracefully
}</code></pre>
</div>
0</p>

<h3>Error Handling Patterns</h3>

<p><strong>Graceful Degradation:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From gcs.proto - rpc::GcsNodeInfo
message GcsNodeInfo {
  bytes node_id = 1;                    // Unique node identifier
  string node_manager_address = 2;      // Node IP address
  int32 node_manager_port = 3;         // Node manager port
  int32 object_manager_port = 4;       // Object manager port
  string node_name = 5;                // Human-readable name
  map<string, double> resources_total = 6;  // Total node resources
  GcsNodeState state = 7;              // Current node state
  NodeDeathInfo death_info = 8;        // Death information if dead
  int64 start_time_ms = 9;            // Node startup timestamp
}

enum GcsNodeState {
  ALIVE = 0;      // Node operational
  DEAD = 1;       // Node failed/removed
  DRAINING = 2;   // Node shutting down gracefully
}</code></pre>
</div>
1</p>

<h2>Code Modification Guidelines</h2>

<h3>Adding New GCS Components</h3>

<p><strong>1. Manager Component Pattern:</strong></p>

<p>To add a new manager (e.g., GcsCustomManager):</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From gcs.proto - rpc::GcsNodeInfo
message GcsNodeInfo {
  bytes node_id = 1;                    // Unique node identifier
  string node_manager_address = 2;      // Node IP address
  int32 node_manager_port = 3;         // Node manager port
  int32 object_manager_port = 4;       // Object manager port
  string node_name = 5;                // Human-readable name
  map<string, double> resources_total = 6;  // Total node resources
  GcsNodeState state = 7;              // Current node state
  NodeDeathInfo death_info = 8;        // Death information if dead
  int64 start_time_ms = 9;            // Node startup timestamp
}

enum GcsNodeState {
  ALIVE = 0;      // Node operational
  DEAD = 1;       // Node failed/removed
  DRAINING = 2;   // Node shutting down gracefully
}</code></pre>
</div>
2</p>

<p><strong>2. Adding New RPC Services:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From gcs.proto - rpc::GcsNodeInfo
message GcsNodeInfo {
  bytes node_id = 1;                    // Unique node identifier
  string node_manager_address = 2;      // Node IP address
  int32 node_manager_port = 3;         // Node manager port
  int32 object_manager_port = 4;       // Object manager port
  string node_name = 5;                // Human-readable name
  map<string, double> resources_total = 6;  // Total node resources
  GcsNodeState state = 7;              // Current node state
  NodeDeathInfo death_info = 8;        // Death information if dead
  int64 start_time_ms = 9;            // Node startup timestamp
}

enum GcsNodeState {
  ALIVE = 0;      // Node operational
  DEAD = 1;       // Node failed/removed
  DRAINING = 2;   // Node shutting down gracefully
}</code></pre>
</div>
3</p>

<p><strong>3. State Persistence Integration:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From gcs.proto - rpc::GcsNodeInfo
message GcsNodeInfo {
  bytes node_id = 1;                    // Unique node identifier
  string node_manager_address = 2;      // Node IP address
  int32 node_manager_port = 3;         // Node manager port
  int32 object_manager_port = 4;       // Object manager port
  string node_name = 5;                // Human-readable name
  map<string, double> resources_total = 6;  // Total node resources
  GcsNodeState state = 7;              // Current node state
  NodeDeathInfo death_info = 8;        // Death information if dead
  int64 start_time_ms = 9;            // Node startup timestamp
}

enum GcsNodeState {
  ALIVE = 0;      // Node operational
  DEAD = 1;       // Node failed/removed
  DRAINING = 2;   // Node shutting down gracefully
}</code></pre>
</div>
4</p>

<h3>Testing and Validation</h3>

<p><strong>Unit Testing Pattern:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From gcs.proto - rpc::GcsNodeInfo
message GcsNodeInfo {
  bytes node_id = 1;                    // Unique node identifier
  string node_manager_address = 2;      // Node IP address
  int32 node_manager_port = 3;         // Node manager port
  int32 object_manager_port = 4;       // Object manager port
  string node_name = 5;                // Human-readable name
  map<string, double> resources_total = 6;  // Total node resources
  GcsNodeState state = 7;              // Current node state
  NodeDeathInfo death_info = 8;        // Death information if dead
  int64 start_time_ms = 9;            // Node startup timestamp
}

enum GcsNodeState {
  ALIVE = 0;      // Node operational
  DEAD = 1;       // Node failed/removed
  DRAINING = 2;   // Node shutting down gracefully
}</code></pre>
</div>
5</p>

<p><strong>Integration Testing:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From gcs.proto - rpc::GcsNodeInfo
message GcsNodeInfo {
  bytes node_id = 1;                    // Unique node identifier
  string node_manager_address = 2;      // Node IP address
  int32 node_manager_port = 3;         // Node manager port
  int32 object_manager_port = 4;       // Object manager port
  string node_name = 5;                // Human-readable name
  map<string, double> resources_total = 6;  // Total node resources
  GcsNodeState state = 7;              // Current node state
  NodeDeathInfo death_info = 8;        // Death information if dead
  int64 start_time_ms = 9;            // Node startup timestamp
}

enum GcsNodeState {
  ALIVE = 0;      // Node operational
  DEAD = 1;       // Node failed/removed
  DRAINING = 2;   // Node shutting down gracefully
}</code></pre>
</div>
6</p>

<p><strong>Performance Testing:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From gcs.proto - rpc::GcsNodeInfo
message GcsNodeInfo {
  bytes node_id = 1;                    // Unique node identifier
  string node_manager_address = 2;      // Node IP address
  int32 node_manager_port = 3;         // Node manager port
  int32 object_manager_port = 4;       // Object manager port
  string node_name = 5;                // Human-readable name
  map<string, double> resources_total = 6;  // Total node resources
  GcsNodeState state = 7;              // Current node state
  NodeDeathInfo death_info = 8;        // Death information if dead
  int64 start_time_ms = 9;            // Node startup timestamp
}

enum GcsNodeState {
  ALIVE = 0;      // Node operational
  DEAD = 1;       // Node failed/removed
  DRAINING = 2;   // Node shutting down gracefully
}</code></pre>
</div>
7</p>

<p>---</p>

<p><em>This comprehensive guide is based on Ray's GCS server source code, particularly files in <code>src/ray/gcs/gcs_server/</code>. For the most current implementation details, refer to the source files and protobuf definitions in the Ray repository.</em></p>

        </div>
            
        <div class="chapter" id="chapter-7">
            <h1 class="chapter-title">Chapter 7: Part II: Core Ray Services</h1>
            <h1>Part II: Core Ray Services</h1>


<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
0</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
1</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
2</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
3</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
4</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
5</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
6</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
7</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
8</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
9</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
0</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
1</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
2</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
3</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
4</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
5</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
6</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
7</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
8</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
9</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
0</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
1</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
2</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
3</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
4</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
5</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
6</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
7</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
8</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
9</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
0</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
1</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
2</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
3</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
4</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
5</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
6</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
7</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
8</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
9</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
0</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
1</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
2</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
3</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
4</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
5</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
6</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
7</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
8</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
9</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
0</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
1</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
2</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
3</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
4</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
5</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
6</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
7</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
8</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          Ray Cluster                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</code></pre>
</div>
9</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
0</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
1</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
2</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
3</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
4</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
5</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
6</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
7</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>

<h2>Introduction</h2>

<p>The <strong>Raylet</strong> is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<ul>
<li><strong>Task scheduling and execution</strong> within a node</li>
<li><strong>Resource management</strong> (CPU, GPU, memory)</li>
<li><strong>Object management</strong> and storage coordination</li>
<li><strong>Worker process lifecycle</strong> management</li>
<li><strong>Communication coordination</strong> between workers and the global control store (GCS)</li>
</ul>

<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>

<h2>Raylet Architecture Overview</h2>

<p><details></p>
<p><summary>Click to expand: High-level Architecture Diagram</summary></p>

<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
8</p>
<p></details></p>

<h3>Core Components</h3>

<p>The raylet consists of several interconnected components:</p>

<p><function_calls></p>
<p><invoke name="create_diagram"></p>
<p><parameter name="content">graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --> B[Node Manager]</p>
<p>A --> C[Object Manager]</p>

<p>B --> D[Local Task Manager]</p>
<p>B --> E[Cluster Task Manager]</p>
<p>B --> F[Worker Pool]</p>
<p>B --> G[Resource Manager]</p>

<p>D --> H[Dependency Manager]</p>
<p>D --> I[Local Object Manager]</p>

<p>E --> J[Cluster Resource Scheduler]</p>

<p>F --> K[Worker Processes]</p>
<p>F --> L[I/O Workers]</p>

<p>C --> M[Plasma Store]</p>
<p>C --> N[Object Directory]</p>

<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>

<p>B --> O</p>
<p>B --> P</p>
<p>B --> Q</p>
<p>end</p>
<p></code_block_to_apply_changes_from></p>
<p></edit_instructions></p>


<p>Assistant:<rewritten_file></p>
<p>
<div class="codehilite">
<pre><code class="">## Table of Contents
1. [Introduction](#introduction)
2. [Raylet Architecture Overview](#raylet-architecture-overview)
3. [Raylet Lifecycle](#raylet-lifecycle)
4. [Communication Mechanisms](#communication-mechanisms)
5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)
6. [Worker Management](#worker-management)
7. [Object Management](#object-management)
8. [Resource Management](#resource-management)
9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)
10. [Performance Optimization](#performance-optimization)
11. [Code References and Implementation Details](#code-references-and-implementation-details)

## Introduction

The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:
- **Task scheduling and execution** within a node
- **Resource management** (CPU, GPU, memory)
- **Object management** and storage coordination
- **Worker process lifecycle** management
- **Communication coordination** between workers and the global control store (GCS)

This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.

## Raylet Architecture Overview

<details>
<summary>Click to expand: High-level Architecture Diagram</summary></code></pre>
</div>
9</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>
<div class="codehilite">
<pre><code class=""></details>

### Core Components

The raylet consists of several interconnected components:

<function_calls>
<invoke name="create_diagram">
<parameter name="content">graph TB
    subgraph "Raylet Process"
        A[Raylet Main] --> B[Node Manager]
        A --> C[Object Manager]
        
        B --> D[Local Task Manager]
        B --> E[Cluster Task Manager]
        B --> F[Worker Pool]
        B --> G[Resource Manager]
        
        D --> H[Dependency Manager]
        D --> I[Local Object Manager]
        
        E --> J[Cluster Resource Scheduler]
        
        F --> K[Worker Processes]
        F --> L[I/O Workers]
        
        C --> M[Plasma Store]
        C --> N[Object Directory]
        
        subgraph "External Interfaces"
            O[GCS Client]
            P[Core Worker RPC]
            Q[Node Manager RPC]
        end
        
        B --> O
        B --> P
        B --> Q
    end
</code_block_to_apply_changes_from>
</edit_instructions>


Assistant:<rewritten_file></code></pre>
</div>
0</p>

<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance</p>
        </div>
            
        <div class="chapter" id="chapter-8">
            <h1 class="chapter-title">Chapter 8: Part II: Core Ray Services</h1>
            <h1>Part II: Core Ray Services</h1>


<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Architecture Overview](#architecture-overview)</p>
<p>3. [Local Storage: Plasma Store](#local-storage-plasma-store)</p>
<p>4. [Distributed Management: Object Manager](#distributed-management-object-manager)</p>
<p>5. [Global Coordination: Object Directory](#global-coordination-object-directory)</p>
<p>6. [Object Lifecycle Management](#object-lifecycle-management)</p>
<p>7. [Memory Management and Spilling](#memory-management-and-spilling)</p>
<p>8. [Performance Characteristics](#performance-characteristics)</p>
<p>9. [Implementation Details](#implementation-details)</p>
<p>10. [Code Modification Guidelines](#code-modification-guidelines)</p>

<h2>Introduction</h2>

<p>Ray's distributed object store is a sophisticated system that provides efficient storage, retrieval, and movement of large data objects across a distributed cluster. The system consists of three main components:</p>

<p>1. <strong>Plasma Store</strong>: High-performance local object storage using shared memory</p>
<p>2. <strong>Object Manager</strong>: Distributed object transfer and coordination</p>
<p>3. <strong>Object Directory</strong>: Global metadata tracking via GCS (Global Control Service)</p>

<p>The object store is designed to handle massive datasets efficiently while providing transparent access patterns for Ray applications.</p>

<h2>Architecture Overview</h2>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Ray Cluster"
        subgraph "Node 1"
            subgraph "Raylet 1"
                LOM1["Local Object Manager"]
                OM1["Object Manager"]
            end
            PS1["Plasma Store"]
            Workers1["Workers"]
        end
        
        subgraph "Node 2"
            subgraph "Raylet 2"
                LOM2["Local Object Manager"]
                OM2["Object Manager"]
            end
            PS2["Plasma Store"]
            Workers2["Workers"]
        end
        
        subgraph "Global Coordination"
            GCS["Global Control Service"]
            OD["Object Directory"]
            Storage["External Storage<br/>(S3, NFS, etc.)"]
        end
    end
    
    Workers1 <-->|"Put/Get Objects"| PS1
    Workers2 <-->|"Put/Get Objects"| PS2
    
    LOM1 <-->|"Local Management"| PS1
    LOM2 <-->|"Local Management"| PS2
    
    OM1 <-->|"Inter-Node Transfer"| OM2
    
    LOM1 <-->|"Spill/Restore"| Storage
    LOM2 <-->|"Spill/Restore"| Storage
    
    OM1 <-->|"Location Metadata"| OD
    OM2 <-->|"Location Metadata"| OD
    OD <-->|"Global State"| GCS
    
    style PS1 fill:#e1f5fe
    style PS2 fill:#e1f5fe
    style GCS fill:#f3e5f5
    style Storage fill:#e8f5e8
        </div>
    </div>
</div>
</p>

<h3>Key Design Principles</h3>

<p>1. <strong>Zero-Copy Access</strong>: Objects stored in shared memory for direct access</p>
<p>2. <strong>Distributed Transparency</strong>: Objects appear local regardless of actual location</p>
<p>3. <strong>Automatic Spilling</strong>: Graceful handling of memory pressure</p>
<p>4. <strong>Fault Tolerance</strong>: Reconstruction and replication capabilities</p>
<p>5. <strong>Performance Optimization</strong>: Chunked transfers and bandwidth management</p>

<h2>Local Storage: Plasma Store</h2>

<p>The Plasma Store provides high-performance local object storage using memory-mapped shared memory.</p>

<h3>Plasma Architecture</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Plasma Store Process"
        subgraph "Memory Management"
            SharedMem["Shared Memory<br/>mmap regions"]
            Allocator["Plasma Allocator<br/>Block-based allocation"]
            Metadata["Object Metadata<br/>Headers & offsets"]
        end
        
        subgraph "Object Storage"
            Objects["Stored Objects<br/>Data + Metadata"]
            FallbackFS["Fallback Storage<br/>Filesystem"]
        end
    end
    
    subgraph "Client Processes"
        Worker1["Worker Process 1"]
        Worker2["Worker Process 2"]
        Raylet["Raylet Process"]
    end
    
    SharedMem --> Objects
    Allocator --> SharedMem
    Metadata --> Objects
    Objects -.->|"Memory Pressure"| FallbackFS
    
    Worker1 <-->|"UDS Protocol"| SharedMem
    Worker2 <-->|"UDS Protocol"| SharedMem
    Raylet <-->|"Management"| Metadata
    
    style SharedMem fill:#e1f5fe
    style Objects fill:#f3e5f5
    style FallbackFS fill:#fff3e0
        </div>
    </div>
</div>
</p>

<h3>Object Storage Structure</h3>

<p>From <code>src/ray/object_manager/plasma/plasma.h:35-70</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">struct PlasmaObject {
  MEMFD_TYPE store_fd;          // Memory-mapped file descriptor
  ptrdiff_t header_offset;      // Object header location
  ptrdiff_t data_offset;        // Object data location  
  ptrdiff_t metadata_offset;    // Object metadata location
  int64_t data_size;           // Size of object data
  int64_t metadata_size;       // Size of object metadata
  int64_t allocated_size;      // Total allocated space
  int device_num;              // Device identifier
  int64_t mmap_size;          // Memory-mapped region size
  bool fallback_allocated;     // Whether using fallback storage
  bool is_experimental_mutable_object; // Mutable object flag
};</code></pre>
</div>
</p>

<h3>Memory Allocation Strategy</h3>

<p><strong>Block-Based Allocation:</strong></p>
<ul>
<li>Objects allocated in 64-byte aligned blocks (`kBlockSize = 64`)</li>
<li>Minimizes fragmentation through power-of-2 sizing</li>
<li>Supports both main memory and fallback filesystem storage</li>
</ul>

<p><strong>Memory Layout:</strong></p>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Object Memory Layout"
        Header["Object Header<br/>(metadata)"]
        Data["Object Data<br/>(payload)"]
        Metadata["Object Metadata<br/>(user metadata)"]
        Padding["Alignment Padding<br/>(64-byte aligned)"]
    end
    
    Header --> Data
    Data --> Metadata
    Metadata --> Padding
    
    style Header fill:#e1f5fe
    style Data fill:#f3e5f5
    style Metadata fill:#e8f5e8
    style Padding fill:#fff3e0
        </div>
    </div>
</div>
</p>

<h2>Distributed Management: Object Manager</h2>

<p>The Object Manager handles inter-node object transfers and distributed coordination.</p>

<h3>Object Manager Architecture</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Object Manager Components"
        subgraph "Transfer Management"
            PullMgr["Pull Manager<br/>Request objects from remote nodes"]
            PushMgr["Push Manager<br/>Send objects to remote nodes"]
            ChunkReader["Chunk Object Reader<br/>Read objects in chunks"]
        end
        
        subgraph "Network Layer"
            RPCServer["RPC Server<br/>Handle remote requests"]
            RPCClient["RPC Client Pool<br/>Send requests to peers"]
            BufferPool["Object Buffer Pool<br/>Manage transfer buffers"]
        end
        
        subgraph "Local Integration"
            LocalStore["Local Plasma Store"]
            Directory["Object Directory<br/>Location tracking"]
            Spilling["Spill Manager<br/>External storage"]
        end
    end
    
    PullMgr <--> RPCClient
    PushMgr <--> RPCServer
    ChunkReader <--> LocalStore
    
    RPCServer <--> BufferPool
    RPCClient <--> BufferPool
    
    PullMgr <--> Directory
    PushMgr <--> Directory
    
    LocalStore <--> Spilling
    
    style PullMgr fill:#e1f5fe
    style PushMgr fill:#f3e5f5
    style LocalStore fill:#e8f5e8
    style Directory fill:#fff3e0
        </div>
    </div>
</div>
</p>

<h3>Object Transfer Protocol</h3>

<p>Ray uses a sophisticated chunked transfer protocol for large objects:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Node1 as Node 1 (Requester)
    participant Node2 as Node 2 (Provider)
    participant Dir as Object Directory
    
    Note over Node1,Node2: Object Transfer Flow
    
    Node1->>Dir: Subscribe to object location
    Dir->>Node1: Object located at Node 2
    
    Node1->>Node2: Pull Request<br/>{object_id, chunk_size}
    Node2->>Node2: Check local availability
    
    alt Object Available Locally
        loop For Each Chunk
            Node2->>Node1: Push Chunk<br/>{chunk_index, data, metadata}
            Node1->>Node1: Write chunk to local store
        end
        Node1->>Node2: Push Complete ACK
    else Object Not Available
        Node2->>Node1: Pull Error<br/>{object_not_found}
        Node1->>Dir: Request object reconstruction
    end
        </div>
    </div>
</div>
</p>

<h3>Configuration and Performance Tuning</h3>

<p>From <code>src/ray/object_manager/object_manager.h:40-75</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">struct ObjectManagerConfig {
  std::string object_manager_address;    // Network address
  int object_manager_port;               // Listening port
  unsigned int timer_freq_ms;            // Timer frequency
  unsigned int pull_timeout_ms;          // Pull request timeout
  uint64_t object_chunk_size;           // Chunk size for transfers
  uint64_t max_bytes_in_flight;         // Max concurrent transfer bytes
  std::string store_socket_name;         // Plasma store socket
  int push_timeout_ms;                   // Push timeout
  int rpc_service_threads_number;        // RPC thread pool size
  int64_t object_store_memory;          // Total memory allocation
  std::string plasma_directory;          // Shared memory directory
  std::string fallback_directory;        // Fallback storage directory
  bool huge_pages;                       // Enable huge page support
};</code></pre>
</div>
</p>

<p><strong>Key Performance Parameters:</strong></p>

<p>| Parameter | Default | Impact |</p>
<p>|-----------|---------|---------|</p>
<p>| <code>object_chunk_size</code> | 1MB | Transfer granularity, affects latency/throughput |</p>
<p>| <code>max_bytes_in_flight</code> | 256MB | Max concurrent transfer bandwidth |</p>
<p>| <code>pull_timeout_ms</code> | 10s | Request timeout, affects fault tolerance |</p>
<p>| <code>rpc_service_threads_number</code> | min(max(2, cpu/4), 8) | Concurrency level |</p>

<h2>Global Coordination: Object Directory</h2>

<p>The Object Directory provides cluster-wide object location tracking and metadata management.</p>

<h3>Object Directory Design</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Object Directory Service"
        subgraph "Location Tracking"
            LocationMap["Object ‚Üí Node Mapping<br/>In-memory cache"]
            Subscriptions["Location Subscriptions<br/>Callback registry"]
            Updates["Location Updates<br/>Event stream"]
        end
        
        subgraph "GCS Integration"
            GCSClient["GCS Client<br/>Global coordination"]
            Pubsub["Pub/Sub System<br/>Event distribution"]
            Persistence["Persistent Storage<br/>Metadata backup"]
        end
        
        subgraph "Spill Coordination"
            SpillTracking["Spill URL Tracking<br/>External storage URLs"]
            RestoreQueue["Restore Requests<br/>Pending restorations"]
        end
    end
    
    LocationMap <--> Subscriptions
    Subscriptions <--> Updates
    
    Updates <--> GCSClient
    GCSClient <--> Pubsub
    GCSClient <--> Persistence
    
    SpillTracking <--> GCSClient
    RestoreQueue <--> Updates
    
    style LocationMap fill:#e1f5fe
    style GCSClient fill:#f3e5f5
    style SpillTracking fill:#e8f5e8
        </div>
    </div>
</div>
</p>

<h3>Object Location Subscription Model</h3>

<p>From <code>src/ray/object_manager/object_directory.h:33-70</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">using OnLocationsFound = std::function<void(
    const ObjectID &object_id,
    const std::unordered_set<NodeID> &node_locations,
    const std::string &spilled_url,
    const NodeID &spilled_node_id,
    bool pending_creation,
    size_t object_size)>;

class IObjectDirectory {
  virtual Status SubscribeObjectLocations(
      const UniqueID &callback_id,
      const ObjectID &object_id,
      const rpc::Address &owner_address,
      const OnLocationsFound &callback) = 0;
      
  virtual void ReportObjectAdded(
      const ObjectID &object_id,
      const NodeID &node_id,
      const ObjectInfo &object_info) = 0;
      
  virtual void ReportObjectSpilled(
      const ObjectID &object_id,
      const NodeID &node_id,
      const rpc::Address &owner_address,
      const std::string &spilled_url,
      const ObjectID &generator_id,
      bool spilled_to_local_storage) = 0;
};</code></pre>
</div>
</p>

<p><strong>Location Update Flow:</strong></p>
<p>1. <strong>Object Creation</strong>: Node reports object addition to directory</p>
<p>2. <strong>Subscription</strong>: Interested nodes subscribe to object locations</p>
<p>3. <strong>Notification</strong>: Directory notifies subscribers of location changes</p>
<p>4. <strong>Transfer</strong>: Subscribers initiate object transfers as needed</p>

<h2>Object Lifecycle Management</h2>

<p>Ray objects go through a well-defined lifecycle from creation to deletion.</p>

<h3>Object Lifecycle States</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
stateDiagram-v2
    [*] --> Creating: Task execution
    Creating --> Local: Object created locally
    
    Local --> InMemory: Stored in Plasma
    Local --> Spilled: Memory pressure
    
    InMemory --> Pinned: Referenced by tasks
    InMemory --> Unpinned: No active references
    
    Pinned --> Unpinned: References released
    Unpinned --> Evicted: Memory pressure
    Unpinned --> Transferred: Remote request
    
    Spilled --> Restoring: Access request
    Restoring --> InMemory: Restoration complete
    
    Evicted --> Reconstructing: Needed again
    Reconstructing --> Local: Reconstruction complete
    
    Transferred --> Remote: Copied to remote node
    
    Remote --> [*]: Deleted from original
    Spilled --> [*]: Deleted after timeout
    Evicted --> [*]: Deleted after timeout
        </div>
    </div>
</div>
</p>

<h3>Object Pinning and Reference Counting</h3>

<p>From <code>src/ray/raylet/local_object_manager.h:67-75</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">void PinObjectsAndWaitForFree(
    const std::vector<ObjectID> &object_ids,
    std::vector<std::unique_ptr<RayObject>> &&objects,
    const rpc::Address &owner_address,
    const ObjectID &generator_id = ObjectID::Nil());

struct LocalObjectInfo {
  rpc::Address owner_address;      // Object owner for reference counting
  bool is_freed = false;          // Whether object can be freed
  std::optional<ObjectID> generator_id;  // For dynamically created objects
  size_t object_size;             // Object size for memory tracking
};</code></pre>
</div>
</p>

<p><strong>Reference Counting Protocol:</strong></p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Worker as Worker Process
    participant LOM as Local Object Manager
    participant Owner as Object Owner
    participant Plasma as Plasma Store
    
    Note over Worker,Plasma: Object Pinning Flow
    
    Worker->>LOM: PinObjects(object_ids, owner_address)
    LOM->>Plasma: Pin objects in store
    LOM->>Owner: WaitForObjectEviction(object_ids)
    
    Note over Worker,Plasma: Object Release Flow
    
    Owner->>LOM: EvictionReply(can_evict=true)
    LOM->>Plasma: Unpin objects
    Plasma->>Plasma: Mark objects evictable
    
    alt Memory Pressure
        Plasma->>LOM: RequestEviction(object_ids)
        LOM->>LOM: Initiate spilling process
    end
        </div>
    </div>
</div>
</p>

<h2>Memory Management and Spilling</h2>

<p>Ray implements sophisticated memory management with automatic spilling to external storage.</p>

<h3>Memory Management Architecture</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Memory Management System"
        subgraph "Memory Monitoring"
            MemTracker["Memory Usage Tracker<br/>Real-time monitoring"]
            Thresholds["Eviction Thresholds<br/>High/low watermarks"]
            Policies["Eviction Policies<br/>LRU, size-based"]
        end
        
        subgraph "Spilling System"
            SpillQueue["Spill Queue<br/>Objects to spill"]
            IOWorkers["IO Worker Pool<br/>Async spill operations"]
            Storage["External Storage<br/>S3, NFS, local disk"]
        end
        
        subgraph "Restoration System"
            RestoreQueue["Restore Queue<br/>Objects to restore"]
            URLTracker["URL Tracking<br/>Spilled object locations"]
            FusedRestore["Fused Restoration<br/>Batch operations"]
        end
    end
    
    MemTracker --> Thresholds
    Thresholds --> Policies
    Policies --> SpillQueue
    
    SpillQueue --> IOWorkers
    IOWorkers --> Storage
    IOWorkers --> URLTracker
    
    RestoreQueue --> IOWorkers
    URLTracker --> FusedRestore
    FusedRestore --> IOWorkers
    
    style MemTracker fill:#e1f5fe
    style IOWorkers fill:#f3e5f5
    style Storage fill:#e8f5e8
    style FusedRestore fill:#fff3e0
        </div>
    </div>
</div>
</p>

<h3>Spilling Algorithm</h3>

<p>From <code>src/ray/raylet/local_object_manager.h:206-228</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// Spill objects asynchronously when space is needed
bool TryToSpillObjects();

// Internal spilling implementation with batching
void SpillObjectsInternal(
    const std::vector<ObjectID> &objects_ids,
    std::function<void(const ray::Status &)> callback);

// Handle spilling completion and update metadata
void OnObjectSpilled(
    const std::vector<ObjectID> &object_ids,
    const rpc::SpillObjectsReply &worker_reply);</code></pre>
</div>
</p>

<p><strong>Spilling Decision Algorithm:</strong></p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
flowchart TD
    Start([Memory Pressure Detected]) --> CheckThreshold{Memory > High Watermark?}
    
    CheckThreshold -->|Yes| SelectObjects[Select Objects to Spill<br/>LRU + Size Criteria]
    CheckThreshold -->|No| End([No Action Needed])
    
    SelectObjects --> CheckEvictable{Objects Evictable?}
    CheckEvictable -->|Yes| InitiateSpill[Start Spill Process<br/>Batch Operations]
    CheckEvictable -->|No| ForceEvict[Force Eviction<br/>If Memory Critical]
    
    InitiateSpill --> SpillToStorage[Transfer to External Storage<br/>Parallel IO Workers]
    ForceEvict --> SpillToStorage
    
    SpillToStorage --> UpdateMetadata[Update Object Directory<br/>Record Spill URLs]
    UpdateMetadata --> FreeMemory[Free Local Memory<br/>Update Usage Tracking]
    FreeMemory --> End
    
    style CheckThreshold fill:#e1f5fe
    style InitiateSpill fill:#f3e5f5
    style SpillToStorage fill:#e8f5e8
    style UpdateMetadata fill:#fff3e0
        </div>
    </div>
</div>
</p>

<h3>Restoration and Fused Operations</h3>

<p><strong>Fused Restoration</strong> combines multiple small objects into single operations for efficiency:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// Maximum number of objects to fuse in single operation
int64_t max_fused_object_count_;

// Restore spilled object from external storage
void AsyncRestoreSpilledObject(
    const ObjectID &object_id,
    int64_t object_size,
    const std::string &object_url,
    std::function<void(const ray::Status &)> callback);</code></pre>
</div>
</p>

<h2>Performance Characteristics</h2>

<h3>Throughput and Latency Analysis</h3>

<p><strong>Local Operations:</strong></p>

<p>| Operation | Latency | Throughput | Notes |</p>
<p>|-----------|---------|------------|-------|</p>
<p>| Local object access | < 1Œºs | ~50 GB/s | Direct shared memory access |</p>
<p>| Object creation | 1-10Œºs | ~10 GB/s | Memory allocation + metadata |</p>
<p>| Object deletion | < 1Œºs | ~20 GB/s | Reference counting + cleanup |</p>

<p><strong>Distributed Operations:</strong></p>

<p>| Operation | Latency | Throughput | Notes |</p>
<p>|-----------|---------|------------|-------|</p>
<p>| Remote object pull | 1-10ms + transfer_time | ~1-5 GB/s per node | Network + chunking overhead |</p>
<p>| Object location lookup | 0.1-1ms | ~10K ops/s | Object directory query |</p>
<p>| Spilling to S3 | 10-100ms + transfer_time | ~100-500 MB/s | Network + storage latency |</p>

<p><strong>Memory Management:</strong></p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Plasma Store Process"
        subgraph "Memory Management"
            SharedMem["Shared Memory<br/>mmap regions"]
            Allocator["Plasma Allocator<br/>Block-based allocation"]
            Metadata["Object Metadata<br/>Headers & offsets"]
        end
        
        subgraph "Object Storage"
            Objects["Stored Objects<br/>Data + Metadata"]
            FallbackFS["Fallback Storage<br/>Filesystem"]
        end
    end
    
    subgraph "Client Processes"
        Worker1["Worker Process 1"]
        Worker2["Worker Process 2"]
        Raylet["Raylet Process"]
    end
    
    SharedMem --> Objects
    Allocator --> SharedMem
    Metadata --> Objects
    Objects -.->|"Memory Pressure"| FallbackFS
    
    Worker1 <-->|"UDS Protocol"| SharedMem
    Worker2 <-->|"UDS Protocol"| SharedMem
    Raylet <-->|"Management"| Metadata
    
    style SharedMem fill:#e1f5fe
    style Objects fill:#f3e5f5
    style FallbackFS fill:#fff3e0
        </div>
    </div>
</div>
0</p>

<h2>Implementation Details</h2>

<h3>Critical Code Paths</h3>

<p><strong>Object Manager Core Loop</strong> (<code>src/ray/object_manager/object_manager.cc</code>):</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ObjectManager : public ObjectManagerInterface {
  // Handle pull request from remote nodes
  void HandlePull(rpc::PullRequest request,
                  rpc::PullReply *reply,
                  rpc::SendReplyCallback send_reply_callback) override;
  
  // Handle push from remote nodes  
  void HandlePush(rpc::PushRequest request,
                  rpc::PushReply *reply,
                  rpc::SendReplyCallback send_reply_callback) override;
  
  // Pull objects from remote nodes
  uint64_t Pull(const std::vector<rpc::ObjectReference> &object_refs,
                BundlePriority prio,
                const TaskMetricsKey &task_key) override;
};</code></pre>
</div>
</p>

<p><strong>Local Object Manager Operations</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class LocalObjectManager {
  // Pin objects and wait for owner to free them
  void PinObjectsAndWaitForFree(
      const std::vector<ObjectID> &object_ids,
      std::vector<std::unique_ptr<RayObject>> &&objects,
      const rpc::Address &owner_address,
      const ObjectID &generator_id);
  
  // Spill objects to external storage
  void SpillObjectUptoMaxThroughput();
  
  // Restore objects from external storage
  void AsyncRestoreSpilledObject(
      const ObjectID &object_id,
      int64_t object_size, 
      const std::string &object_url,
      std::function<void(const ray::Status &)> callback);
};</code></pre>
</div>
</p>

<h3>Error Handling and Recovery</h3>

<p><strong>Fault Tolerance Mechanisms:</strong></p>

<p>1. <strong>Object Reconstruction</strong>: If objects are lost, Ray can reconstruct them by re-executing the tasks that created them</p>
<p>2. <strong>Replication</strong>: Critical objects can be replicated across multiple nodes</p>
<p>3. <strong>Spill Redundancy</strong>: Objects spilled to external storage maintain multiple copies</p>
<p>4. <strong>Network Resilience</strong>: Failed transfers are automatically retried with exponential backoff</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Plasma Store Process"
        subgraph "Memory Management"
            SharedMem["Shared Memory<br/>mmap regions"]
            Allocator["Plasma Allocator<br/>Block-based allocation"]
            Metadata["Object Metadata<br/>Headers & offsets"]
        end
        
        subgraph "Object Storage"
            Objects["Stored Objects<br/>Data + Metadata"]
            FallbackFS["Fallback Storage<br/>Filesystem"]
        end
    end
    
    subgraph "Client Processes"
        Worker1["Worker Process 1"]
        Worker2["Worker Process 2"]
        Raylet["Raylet Process"]
    end
    
    SharedMem --> Objects
    Allocator --> SharedMem
    Metadata --> Objects
    Objects -.->|"Memory Pressure"| FallbackFS
    
    Worker1 <-->|"UDS Protocol"| SharedMem
    Worker2 <-->|"UDS Protocol"| SharedMem
    Raylet <-->|"Management"| Metadata
    
    style SharedMem fill:#e1f5fe
    style Objects fill:#f3e5f5
    style FallbackFS fill:#fff3e0
        </div>
    </div>
</div>
1</p>

<h2>Code Modification Guidelines</h2>

<h3>Adding New Object Store Features</h3>

<p><strong>1. Local Storage Modifications:</strong></p>

<p>To modify Plasma store behavior, focus on these key files:</p>
<ul>
<li>`src/ray/object_manager/plasma/plasma.cc` - Core storage logic</li>
<li>`src/ray/object_manager/plasma/plasma_allocator.cc` - Memory allocation</li>
<li>`src/ray/raylet/local_object_manager.cc` - Raylet integration</li>
</ul>

<p><strong>2. Distributed Transfer Modifications:</strong></p>

<p>For object transfer improvements:</p>
<ul>
<li>`src/ray/object_manager/object_manager.cc` - Main transfer logic</li>
<li>`src/ray/object_manager/pull_manager.cc` - Pull request handling</li>
<li>`src/ray/object_manager/push_manager.cc` - Push request handling</li>
</ul>

<p><strong>3. Spilling and External Storage:</strong></p>

<p>For spilling enhancements:</p>
<ul>
<li>`src/ray/raylet/local_object_manager.cc` - Spilling coordination</li>
<li>External storage interfaces in worker processes</li>
</ul>

<h3>Example: Adding a New Spilling Strategy</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">// In LocalObjectManager class
bool TryToSpillObjectsCustomStrategy() {
  // 1. Implement custom object selection logic
  std::vector<ObjectID> objects_to_spill = SelectObjectsCustomCriteria();
  
  // 2. Check if objects meet spilling requirements
  if (objects_to_spill.empty() || 
      total_size < min_spilling_size_) {
    return false;
  }
  
  // 3. Initiate spilling with custom parameters
  SpillObjectsInternal(objects_to_spill, 
                      [this](const ray::Status &status) {
                        // Custom completion handling
                      });
  return true;
}</code></pre>
</div>
</p>

<h3>Testing and Validation</h3>

<p><strong>Key Testing Areas:</strong></p>

<p>1. <strong>Unit Tests</strong>: Individual component functionality</p>
<p>2. <strong>Integration Tests</strong>: Cross-component interactions</p>
<p>3. <strong>Performance Tests</strong>: Throughput and latency benchmarks</p>
<p>4. <strong>Fault Injection</strong>: Network failures, storage failures, node crashes</p>
<p>5. <strong>Scale Tests</strong>: Large object handling, many-node clusters</p>

<p><strong>Performance Validation Commands:</strong></p>

<p>
<div class="codehilite">
<pre><code class="bash">ray start --head --object-store-memory=8000000000
python -c "
import ray
import numpy as np
ray.init()
obj = ray.put(np.random.rand(100000000))  # ~800MB object
result = ray.get(obj)
"

ray status --verbose</code></pre>
</div>
</p>

<p>---</p>

<p><em>This guide is based on Ray's source code, particularly the object manager, plasma store, and local object manager implementations. For the most current details, refer to the source files in <code>src/ray/object_manager/</code> and <code>src/ray/raylet/</code>.</em></p>

        </div>
            
        <div class="chapter" id="chapter-9">
            <h1 class="chapter-title">Chapter 9: Part III: Advanced Ray Systems</h1>
            <h1>Part III: Advanced Ray Systems</h1>

<h2>Table of Contents</h2>

<p>1. [Introduction](#introduction)</p>
<p>2. [Scheduling Architecture Overview](#scheduling-architecture-overview)</p>
<p>3. [Core Scheduling Components](#core-scheduling-components)</p>
<p>4. [Resource Management and Allocation](#resource-management-and-allocation)</p>
<p>5. [Task Scheduling Algorithms](#task-scheduling-algorithms)</p>
<p>6. [Actor Placement and Scheduling](#actor-placement-and-scheduling)</p>
<p>7. [Placement Group Scheduling](#placement-group-scheduling)</p>
<p>8. [Scheduling Strategies](#scheduling-strategies)</p>
<p>9. [Node Affinity and Label-Based Scheduling](#node-affinity-and-label-based-scheduling)</p>
<p>10. [Locality-Aware Scheduling](#locality-aware-scheduling)</p>
<p>11. [Cluster Resource Scheduling](#cluster-resource-scheduling)</p>
<p>12. [Autoscaler Integration](#autoscaler-integration)</p>
<p>13. [Performance Characteristics](#performance-characteristics)</p>
<p>14. [Configuration and Tuning](#configuration-and-tuning)</p>
<p>15. [Implementation Deep Dive](#implementation-deep-dive)</p>
<p>16. [Testing and Verification](#testing-and-verification)</p>
<p>17. [Best Practices](#best-practices)</p>
<p>18. [Troubleshooting](#troubleshooting)</p>

<h2>Introduction</h2>

<p>Ray's distributed scheduling system is a sophisticated multi-layered scheduler designed to efficiently allocate resources and place tasks/actors across a distributed cluster. This chapter dives deep into the scheduling implementation, covering complex scheduling scenarios including resource constraints, placement groups, locality preferences, and autoscaling decisions while maintaining high performance and fault tolerance.</p>

<h3>What is Ray?</h3>

<p>Ray is an open-source unified framework for scaling AI workloads. It provides:</p>
<ul>
<li><strong>Distributed Computing</strong>: Scale Python workloads across multiple machines</li>
<li><strong>Unified API</strong>: Single interface for tasks, actors, and data processing</li>
<li><strong>Fault Tolerance</strong>: Built-in error handling and recovery mechanisms</li>
<li><strong>Resource Management</strong>: Efficient allocation of CPU, GPU, and memory resources</li>
<li><strong>Ecosystem</strong>: Libraries for ML (Ray Train), reinforcement learning (Ray RLlib), hyperparameter tuning (Ray Tune), and more</li>
</ul>

<h3>Key Features</h3>

<ul>
<li><strong>Multi-level Scheduling</strong>: Task-level, actor-level, and placement group scheduling</li>
<li><strong>Resource-Aware</strong>: CPU, GPU, memory, and custom resource scheduling</li>
<li><strong>Placement Strategies</strong>: PACK, SPREAD, STRICT_PACK, STRICT_SPREAD</li>
<li><strong>Locality Optimization</strong>: Data locality-aware task placement</li>
<li><strong>Dynamic Scaling</strong>: Integration with autoscaler for cluster growth/shrinkage</li>
<li><strong>Label-Based Scheduling</strong>: Node affinity and label constraints</li>
<li><strong>Performance Optimization</strong>: Efficient algorithms for large-scale clusters</li>
</ul>

<h3>Scheduling Hierarchy</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[User Workload] --> B[Core Worker]
    B --> C[Lease Policy]
    C --> D[Raylet Node Manager]
    D --> E[Cluster Task Manager]
    E --> F[Cluster Resource Scheduler]
    F --> G[Scheduling Policies]
    G --> H[Local Task Manager]
    H --> I[Worker Pool]
    
    J[GCS Server] --> K[GCS Actor Scheduler]
    J --> L[GCS Placement Group Scheduler]
    
    K --> F
    L --> F
    
    M[Autoscaler] --> N[Resource Demand Scheduler]
    N --> O[Node Provider]
        </div>
    </div>
</div>
</p>

<h2>Scheduling Architecture Overview</h2>

<h3>Multi-Level Scheduling Architecture</h3>

<p>Ray implements a hierarchical scheduling architecture with multiple decision points:</p>

<h4>1. Client-Side Scheduling</h4>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    A[ray.remote Call] --> B[Core Worker]
    B --> C[Locality-Aware Lease Policy]
    C --> D[Best Node Selection]
    D --> E[Raylet RPC]
        </div>
    </div>
</div>
</p>

<p><strong>Location</strong>: <code>src/ray/core_worker/lease_policy.cc</code></p>

<p>The client-side scheduling makes initial placement decisions based on:</p>
<ul>
<li>Data locality (object location)</li>
<li>Scheduling strategies (spread, node affinity)</li>
<li>Resource requirements</li>
</ul>

<h4>2. Raylet-Level Scheduling</h4>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[Raylet Receives Task] --> B[Cluster Task Manager]
    B --> C[Resource Availability Check]
    C --> D{Resources Available?}
    D -->|Yes| E[Local Task Manager]
    D -->|No| F[Spillback Decision]
    F --> G[Remote Node Selection]
    G --> H[Forward to Remote Raylet]
    E --> I[Worker Assignment]
        </div>
    </div>
</div>
</p>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/cluster_task_manager.cc</code></p>

<h4>3. GCS-Level Scheduling</h4>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[GCS Scheduling Request] --> B{Task Type}
    B -->|Actor Creation| C[GCS Actor Scheduler]
    B -->|Placement Group| D[GCS Placement Group Scheduler]
    C --> E[Cluster Resource Scheduler]
    D --> E
    E --> F[Node Selection]
    F --> G[Resource Reservation]
        </div>
    </div>
</div>
</p>

<p><strong>Location</strong>: <code>src/ray/gcs/gcs_server/gcs_actor_scheduler.cc</code></p>

<h3>Core Scheduling Flow</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant CW as Core Worker
    participant LP as Lease Policy
    participant RM as Raylet Manager
    participant CTM as Cluster Task Manager
    participant CRS as Cluster Resource Scheduler
    participant LTM as Local Task Manager
    participant WP as Worker Pool

    CW->>LP: GetBestNodeForTask()
    LP->>LP: Analyze locality & strategy
    LP->>RM: RequestWorkerLease()
    RM->>CTM: QueueAndScheduleTask()
    CTM->>CRS: GetBestSchedulableNode()
    CRS->>CRS: Apply scheduling policy
    CRS-->>CTM: Selected node
    CTM->>LTM: QueueAndScheduleTask() [if local]
    LTM->>WP: PopWorker()
    WP-->>LTM: Worker instance
    LTM-->>CTM: Task dispatched
        </div>
    </div>
</div>
</p>

<h2>Core Scheduling Components</h2>

<h3>ClusterResourceScheduler</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/cluster_resource_scheduler.h</code></p>

<p>The central coordinator for cluster-wide resource scheduling decisions.</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterResourceScheduler {
  // Core scheduling method
  scheduling::NodeID GetBestSchedulableNode(
      const ResourceRequest &resource_request,
      const rpc::SchedulingStrategy &scheduling_strategy,
      bool actor_creation,
      bool force_spillback,
      const std::string &preferred_node_id,
      int64_t *total_violations,
      bool *is_infeasible);
      
  // Bundle scheduling for placement groups
  SchedulingResult Schedule(
      const std::vector<const ResourceRequest *> &resource_request_list,
      SchedulingOptions options);
}</code></pre>
</div>
</p>

<p><strong>Key Responsibilities</strong>:</p>
<ul>
<li>Node feasibility checking</li>
<li>Resource availability tracking</li>
<li>Scheduling strategy implementation</li>
<li>Placement group bundle scheduling</li>
</ul>

<h3>ClusterTaskManager</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/cluster_task_manager.h</code></p>

<p>Manages task queuing and scheduling at the cluster level.</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
</p>

<p><strong>Scheduling Queues</strong>:</p>
<ul>
<li>`tasks_to_schedule_`: Tasks waiting for resources</li>
<li>`infeasible_tasks_`: Tasks that cannot be scheduled</li>
</ul>

<h3>LocalTaskManager</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/local_task_manager.h</code></p>

<p>Handles local task execution and worker management.</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
</p>

<p><strong>Fairness Policy</strong>: Implements CPU-fair scheduling to prevent resource starvation:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
</p>

<h3>Scheduling Policies</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/policy/</code></p>

<p>Ray implements multiple scheduling policies:</p>

<h4>HybridSchedulingPolicy</h4>
<ul>
<li>Default scheduling strategy</li>
<li>Balances locality and load distribution</li>
<li>Configurable spread threshold</li>
</ul>

<h4>SpreadSchedulingPolicy</h4>
<ul>
<li>Distributes tasks across nodes</li>
<li>Minimizes resource contention</li>
<li>Used for embarrassingly parallel workloads</li>
</ul>

<h4>NodeAffinitySchedulingPolicy</h4>
<ul>
<li>Hard/soft node constraints</li>
<li>Supports spillback on unavailability</li>
<li>Critical for stateful workloads</li>
</ul>

<h4>NodeLabelSchedulingPolicy</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
</p>

<h3>Scheduling Context and Options</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/policy/scheduling_options.h</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
</p>

<h2>Resource Management and Allocation</h2>

<h3>Resource Model</h3>

<p>Ray uses a multi-dimensional resource model:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
</p>

<h3>Resource Request Structure</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
</p>

<h3>NodeResources</h3>

<p><strong>Location</strong>: <code>src/ray/common/scheduling/cluster_resource_data.h</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">struct NodeResources {
  NodeResourceSet total;      // Total node capacity
  NodeResourceSet available; // Currently available
  NodeResourceSet normal_task_resources; // Reserved for tasks
  absl::flat_hash_map<std::string, std::string> labels; // Node labels
  bool object_pulls_queued;   // Object store status
  
  bool IsAvailable(const ResourceRequest &resource_request) const;
  bool IsFeasible(const ResourceRequest &resource_request) const;
  bool HasRequiredLabels(const LabelSelector &label_selector) const;
  float CalculateCriticalResourceUtilization() const;
};</code></pre>
</div>
</p>

<h3>Resource Allocation Algorithm</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">bool ClusterResourceScheduler::IsSchedulable(
    const ResourceRequest &resource_request,
    scheduling::NodeID node_id) const {
  
  return cluster_resource_manager_->HasAvailableResources(
             node_id,
             resource_request,
             /*ignore_object_store_memory_requirement*/ 
             node_id == local_node_id_) &&
         NodeAvailable(node_id);
}</code></pre>
</div>
</p>

<h3>Dynamic Resource Management</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
0</p>

<h3>Resource Binpacking</h3>

<p>Ray implements sophisticated binpacking for resource allocation:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[Resource Request] --> B[Sort by Resource Requirements]
    B --> C[Find Best Fit Node]
    C --> D{Resources Available?}
    D -->|Yes| E[Allocate Resources]
    D -->|No| F[Try Next Node]
    F --> G{More Nodes?}
    G -->|Yes| C
    G -->|No| H[Request Infeasible]
    E --> I[Update Node Resources]
        </div>
    </div>
</div>
</p>

<h2>Task Scheduling Algorithms</h2>

<h3>Hybrid Scheduling Algorithm</h3>

<p><strong>Default Strategy</strong>: Balances locality and load distribution</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
1</p>

<p><strong>Algorithm Steps</strong>:</p>
<p>1. <strong>Score Calculation</strong>: Based on resource utilization</p>
<p>2. <strong>Top-K Selection</strong>: Choose from best k nodes (default: 20% of cluster)</p>
<p>3. <strong>Random Selection</strong>: Within top-k for load balancing</p>

<p><strong>Scoring Function</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
2</p>

<h3>Spread Scheduling Algorithm</h3>

<p><strong>Purpose</strong>: Distribute tasks across maximum number of nodes</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
3</p>

<p><strong>Implementation</strong>:</p>
<ul>
<li>Prioritizes nodes with lowest task count</li>
<li>Avoids resource hotspots</li>
<li>Maximizes fault tolerance</li>
</ul>

<h3>Node Affinity Scheduling</h3>

<p><strong>Hard Affinity</strong>: Must run on specific node</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
4</p>

<p><strong>Soft Affinity</strong>: Prefer specific node but allow spillback</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
5</p>

<h3>Fair Scheduling</h3>

<p><strong>CPU Fair Scheduling</strong>: Prevents starvation across scheduling classes</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
6</p>

<h2>Actor Placement and Scheduling</h2>

<h3>Actor Scheduling Architecture</h3>

<p><strong>Location</strong>: <code>src/ray/gcs/gcs_server/gcs_actor_scheduler.cc</code></p>

<p>Ray provides two actor scheduling modes:</p>

<h4>1. GCS-Based Actor Scheduling</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
7</p>

<h4>2. Raylet-Based Actor Scheduling</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
8</p>

<h3>Actor Resource Requirements</h3>

<p><strong>Placement vs Execution Resources</strong>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class ClusterTaskManager {
  void QueueAndScheduleTask(
      RayTask task,
      bool grant_or_reject,
      bool is_selected_based_on_locality,
      rpc::RequestWorkerLeaseReply *reply,
      rpc::SendReplyCallback send_reply_callback);
      
  void ScheduleAndDispatchTasks();
}</code></pre>
</div>
9</p>

<p><strong>Actor Creation Example</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
0</p>

<h3>Actor Lifecycle and Scheduling</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[Actor Creation Request] --> B[GCS Actor Scheduler]
    B --> C{Scheduling Mode}
    C -->|GCS Scheduling| D[Cluster Task Manager]
    C -->|Raylet Scheduling| E[Select Forwarding Node]
    D --> F[Resource Allocation]
    E --> G[Direct Worker Lease]
    F --> H[Worker Assignment]
    G --> H
    H --> I[Actor Initialization]
    I --> J[Ready for Method Calls]
        </div>
    </div>
</div>
</p>

<h3>Actor Scheduling Considerations</h3>

<p><strong>Resource Lifetime</strong>: Actors hold resources for their entire lifetime</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
1</p>

<p><strong>Scheduling Class</strong>: Actors use placement resources for scheduling decisions</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
2</p>

<h2>Placement Group Scheduling</h2>

<h3>Placement Group Architecture</h3>

<p><strong>Location</strong>: <code>src/ray/gcs/gcs_server/gcs_placement_group_scheduler.cc</code></p>

<p>Placement groups enable gang scheduling of related resources across multiple nodes.</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
3</p>

<h3>Bundle Specification</h3>

<p><strong>Location</strong>: <code>src/ray/common/bundle_spec.h</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
4</p>

<h3>Placement Strategies</h3>

<h4>PACK Strategy</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
5</p>
<ul>
<li><strong>Goal</strong>: Minimize number of nodes used</li>
<li><strong>Use Case</strong>: Maximize locality, minimize network overhead</li>
<li><strong>Algorithm</strong>: First-fit decreasing binpacking</li>
</ul>

<h4>SPREAD Strategy</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
6</p>
<ul>
<li><strong>Goal</strong>: Distribute bundles across nodes</li>
<li><strong>Use Case</strong>: Fault tolerance, load distribution</li>
<li><strong>Algorithm</strong>: Round-robin placement with load balancing</li>
</ul>

<h4>STRICT_PACK Strategy</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
7</p>
<ul>
<li><strong>Goal</strong>: All bundles on single node (if possible)</li>
<li><strong>Use Case</strong>: Shared memory, minimal latency</li>
<li><strong>Algorithm</strong>: Single-node placement with fallback</li>
</ul>

<h4>STRICT_SPREAD Strategy</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
8</p>
<ul>
<li><strong>Goal</strong>: Each bundle on different node</li>
<li><strong>Use Case</strong>: Maximum fault tolerance</li>
<li><strong>Algorithm</strong>: One bundle per node constraint</li>
</ul>

<h3>Bundle Scheduling Algorithm</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[Placement Group Request] --> B[Parse Bundles]
    B --> C[Sort by Resource Requirements]
    C --> D[Apply Placement Strategy]
    D --> E{Strategy Type}
    E -->|PACK| F[First-Fit Decreasing]
    E -->|SPREAD| G[Round-Robin Distribution]
    E -->|STRICT_PACK| H[Single Node Placement]
    E -->|STRICT_SPREAD| I[One Bundle Per Node]
    F --> J[Resource Reservation]
    G --> J
    H --> J
    I --> J
    J --> K[Bundle Commitment]
        </div>
    </div>
</div>
</p>

<h3>Bundle Resource Formatting</h3>

<p>Ray formats placement group resources with special naming:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class LocalTaskManager {
  void QueueAndScheduleTask(std::shared_ptr<internal::Work> work);
  void ScheduleAndDispatchTasks();
  bool TrySpillback(const std::shared_ptr<internal::Work> &work,
                    bool &is_infeasible);
}</code></pre>
</div>
9</p>

<h3>CPU Fraction Limits</h3>

<p><strong>Purpose</strong>: Prevent placement groups from monopolizing nodes</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
0</p>

<h3>Placement Group Lifecycle</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant User
    participant GCS as GCS PG Scheduler
    participant CRS as Cluster Resource Scheduler
    participant Raylet
    participant Worker

    User->>GCS: ray.util.placement_group()
    GCS->>GCS: Parse bundles & strategy
    GCS->>CRS: Schedule(bundle_list, options)
    CRS->>CRS: Apply placement strategy
    CRS-->>GCS: Selected nodes
    GCS->>Raylet: PrepareBundleResources()
    Raylet-->>GCS: Resources reserved
    GCS->>Raylet: CommitBundleResources()
    Raylet-->>GCS: Resources committed
    GCS-->>User: Placement group ready
    
    User->>Worker: Task with PG scheduling strategy
    Worker->>Raylet: Use PG bundle resources
        </div>
    </div>
</div>
</p>

<h2>Scheduling Strategies</h2>

<h3>Strategy Types and Implementation</h3>

<p>Ray supports multiple scheduling strategies through the <code>rpc::SchedulingStrategy</code> protocol buffer:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
1</p>

<h3>DEFAULT Strategy</h3>

<p><strong>Implementation</strong>: Hybrid policy with configurable parameters</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
2</p>

<p><strong>Algorithm</strong>:</p>
<p>1. Calculate node scores based on resource utilization</p>
<p>2. Select top-k nodes with lowest scores</p>
<p>3. Randomly choose from top-k for load balancing</p>

<h3>SPREAD Strategy</h3>

<p><strong>Purpose</strong>: Maximize distribution across nodes</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
3</p>

<p><strong>Implementation Details</strong>:</p>
<ul>
<li>Prioritizes nodes with fewer running tasks</li>
<li>Considers resource utilization as secondary factor</li>
<li>Useful for embarrassingly parallel workloads</li>
</ul>

<h3>Node Affinity Strategy</h3>

<p><strong>Hard Affinity</strong>: Must run on specific node</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
4</p>

<p><strong>Soft Affinity</strong>: Prefer specific node with fallback</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
5</p>

<h3>Placement Group Strategy</h3>

<p><strong>Bundle-Specific Scheduling</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
6</p>

<h2>Node Affinity and Label-Based Scheduling</h2>

<h3>Node Label Scheduling Policy</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/policy/node_label_scheduling_policy.cc</code></p>

<p>Ray supports sophisticated label-based scheduling for fine-grained node selection:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
7</p>

<h3>Label Matching Implementation</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
8</p>

<h3>Label Selector Usage</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/raylet/local_task_manager.cc
if (total_cpu_requests_ > total_cpus) {
  RAY_LOG(DEBUG) << "Applying fairness policy. Total CPU requests ("
                 << total_cpu_requests_ << ") exceed total CPUs (" 
                 << total_cpus << ")";
  // Apply fair dispatching logic
}</code></pre>
</div>
9</p>

<h3>Node Label Management</h3>

<p><strong>Static Labels</strong>: Set during node startup</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
0</p>

<p><strong>Dynamic Labels</strong>: Updated at runtime</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
1</p>

<h2>Locality-Aware Scheduling</h2>

<h3>Locality-Aware Lease Policy</h3>

<p><strong>Location</strong>: <code>src/ray/core_worker/lease_policy.cc</code></p>

<p>Ray implements data locality-aware scheduling to minimize data movement:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
2</p>

<h3>Locality Calculation</h3>

<p><strong>Criteria</strong>: Node with most object bytes local</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
3</p>

<h3>Locality vs Strategy Priority</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    A[Task Submission] --> B{Explicit Strategy?}
    B -->|Yes| C[Use Explicit Strategy]
    B -->|No| D[Check Data Locality]
    D --> E{Objects Local?}
    E -->|Yes| F[Select Node with Most Data]
    E -->|No| G[Use Default Strategy]
    C --> H[Schedule Task]
    F --> H
    G --> H
        </div>
    </div>
</div>
</p>

<h3>Locality Testing</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
4</p>

<h2>Cluster Resource Scheduling</h2>

<h3>Cluster Resource Manager</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/cluster_resource_manager.h</code></p>

<p>Maintains global view of cluster resources:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
5</p>

<h3>Resource Synchronization</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    A[ray.remote Call] --> B[Core Worker]
    B --> C[Locality-Aware Lease Policy]
    C --> D[Best Node Selection]
    D --> E[Raylet RPC]
        </div>
    </div>
</div>
0</p>

<h3>Resource Reporting</h3>

<p><strong>Location</strong>: <code>src/ray/raylet/scheduling/scheduler_resource_reporter.cc</code></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
6</p>

<h2>Autoscaler Integration</h2>

<h3>Resource Demand Scheduler</h3>

<p><strong>Location</strong>: <code>python/ray/autoscaler/v2/scheduler.py</code></p>

<p>The autoscaler uses sophisticated scheduling algorithms to determine cluster scaling decisions:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
7</p>

<h3>Binpacking Algorithm</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
8</p>

<h3>Placement Group Autoscaling</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
  scheduling::NodeID Schedule(const ResourceRequest &resource_request,
                              SchedulingOptions options) override;
private:
  bool IsNodeMatchLabelExpression(const Node &node,
                                  const rpc::LabelMatchExpression &expression);
};</code></pre>
</div>
9</p>

<h3>Autoscaler Configuration</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
0</p>

<h2>Performance Characteristics</h2>

<h3>Scheduling Latency</h3>

<p><strong>Typical Latencies</strong>:</p>
<ul>
<li>Local scheduling: 1-5ms</li>
<li>Remote scheduling: 10-50ms</li>
<li>Placement group creation: 100-1000ms</li>
<li>Autoscaler response: 30-300s</li>
</ul>

<h3>Scalability Metrics</h3>

<p><strong>Cluster Size</strong>: Ray scheduling tested up to 1000+ nodes</p>

<p><strong>Task Throughput</strong>:</p>
<ul>
<li>Simple tasks: 100K+ tasks/second</li>
<li>Complex scheduling: 10K+ tasks/second</li>
<li>Placement groups: 100+ groups/second</li>
</ul>

<h3>Memory Usage</h3>

<p><strong>Scheduler Memory Overhead</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
1</p>

<p><strong>Task Queue Memory</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
2</p>

<h3>Performance Optimization</h3>

<p><strong>Top-K Selection</strong>: Reduces scheduling complexity from O(N) to O(K)</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
3</p>

<p><strong>Caching</strong>: Resource views cached to avoid repeated calculations</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
4</p>

<h2>Configuration and Tuning</h2>

<h3>Environment Variables</h3>

<p><strong>Core Scheduling</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
5</p>

<p><strong>Resource Management</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
6</p>

<p><strong>Placement Groups</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
7</p>

<h3>Runtime Configuration</h3>

<p><strong>Cluster Resource Constraints</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
8</p>

<p><strong>Node Type Configuration</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">struct SchedulingOptions {
  SchedulingType scheduling_type;
  float spread_threshold;
  bool avoid_local_node;
  bool require_node_available;
  bool avoid_gpu_nodes;
  double max_cpu_fraction_per_node; // For placement groups
  
  static SchedulingOptions Hybrid(bool avoid_local_node,
                                  bool require_node_available,
                                  const std::string &preferred_node_id);
                                  
  static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);
  static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);
};</code></pre>
</div>
9</p>

<h3>Performance Tuning</h3>

<p><strong>For High Throughput</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
0</p>

<p><strong>For Low Latency</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
1</p>

<p><strong>For Large Clusters</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
2</p>

<h2>Best Practices</h2>

<h3>Task Scheduling</h3>

<p><strong>1. Use Appropriate Scheduling Strategies</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
3</p>

<p><strong>2. Resource Specification</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
4</p>

<h3>Actor Placement</h3>

<p><strong>1. Consider Resource Lifetime</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
5</p>

<p><strong>2. Use Placement Groups for Related Actors</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
6</p>

<h3>Placement Group Design</h3>

<p><strong>1. Choose Appropriate Strategies</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
7</p>

<p><strong>2. Bundle Size Optimization</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
8</p>

<h3>Autoscaler Optimization</h3>

<p><strong>1. Configure Appropriate Limits</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Resource types from src/ray/common/scheduling/scheduling_ids.h
enum PredefinedResources {
  CPU = 0,
  MEM = 1,
  GPU = 2,
  OBJECT_STORE_MEM = 3,
  // Custom resources start from 4
};</code></pre>
</div>
9</p>

<p><strong>2. Use Resource Constraints</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
0</p>

<h2>Troubleshooting</h2>

<h3>Common Scheduling Issues</h3>

<p><strong>1. Tasks Stuck in Pending State</strong>:</p>

<p><em>Symptoms</em>: Tasks remain in PENDING_SCHEDULING state</p>
<p><em>Causes</em>:</p>
<ul>
<li>Insufficient cluster resources</li>
<li>Infeasible resource requirements</li>
<li>Node affinity to unavailable nodes</li>
</ul>

<p><em>Debugging</em>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
1</p>

<p><strong>2. Poor Load Balancing</strong>:</p>

<p><em>Symptoms</em>: Some nodes overloaded while others idle</p>
<p><em>Causes</em>:</p>
<ul>
<li>Inappropriate scheduling strategy</li>
<li>Data locality overriding load balancing</li>
<li>Sticky worker assignment</li>
</ul>

<p><em>Solutions</em>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
2</p>

<p><strong>3. Placement Group Creation Failures</strong>:</p>

<p><em>Symptoms</em>: Placement groups fail to create or timeout</p>
<p><em>Causes</em>:</p>
<ul>
<li>Insufficient cluster capacity</li>
<li>Conflicting resource constraints</li>
<li>Network partitions</li>
</ul>

<p><em>Debugging</em>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
3</p>

<h3>Performance Issues</h3>

<p><strong>1. High Scheduling Latency</strong>:</p>

<p><em>Symptoms</em>: Long delays between task submission and execution</p>
<p><em>Causes</em>:</p>
<ul>
<li>Large cluster with inefficient node selection</li>
<li>Complex placement constraints</li>
<li>Resource fragmentation</li>
</ul>

<p><em>Solutions</em>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
4</p>

<p><strong>2. Memory Issues in Scheduler</strong>:</p>

<p><em>Symptoms</em>: Raylet OOM, high memory usage in scheduling components</p>
<p><em>Causes</em>:</p>
<ul>
<li>Large number of queued tasks</li>
<li>Memory leaks in scheduling data structures</li>
<li>Excessive resource tracking overhead</li>
</ul>

<p><em>Solutions</em>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
5</p>

<h3>Debugging Tools</h3>

<p><strong>1. Ray Status Commands</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
6</p>

<p><strong>2. Programmatic Debugging</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
7</p>

<p><strong>3. Logging Configuration</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
8</p>

<h3>Monitoring and Observability</h3>

<p><strong>1. Metrics Collection</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="cpp">class ResourceRequest {
  ResourceSet resource_set_;           // Required resources
  LabelSelector label_selector_;       // Node label requirements
  bool requires_object_store_memory_;  // Memory constraint flag
  
  bool IsEmpty() const;
  const ResourceSet &GetResourceSet() const;
  bool RequiresObjectStoreMemory() const;
};</code></pre>
</div>
9</p>

<p><strong>2. Dashboard Integration</strong>:</p>
<ul>
<li>Use Ray Dashboard for real-time cluster monitoring</li>
<li>Monitor resource utilization trends</li>
<li>Track placement group creation success rates</li>
<li>Observe task scheduling patterns</li>
</ul>

<p>This comprehensive guide covers Ray's distributed scheduling system from architecture to implementation details, providing developers and operators with the knowledge needed to effectively use and optimize Ray's scheduling capabilities in production environments.</p>
        </div>
            
        <div class="chapter" id="chapter-10">
            <h1 class="chapter-title">Chapter 10: Part III: Advanced Ray Systems</h1>
            <h1>Part III: Advanced Ray Systems</h1>


<h2>Table of Contents</h2>

<p>1. [Introduction](#introduction)</p>
<p>2. [Autoscaling Architecture Overview](#autoscaling-architecture-overview)</p>
<p>3. [Core Autoscaling Components](#core-autoscaling-components)</p>
<p>4. [Resource Demand Detection](#resource-demand-detection)</p>
<p>5. [Node Lifecycle Management](#node-lifecycle-management)</p>
<p>6. [Scheduling and Binpacking Algorithms](#scheduling-and-binpacking-algorithms)</p>
<p>7. [Cloud Provider Integration](#cloud-provider-integration)</p>
<p>8. [Autoscaler Policies and Strategies](#autoscaler-policies-and-strategies)</p>
<p>9. [Load Metrics and Monitoring](#load-metrics-and-monitoring)</p>
<p>10. [Placement Group Autoscaling](#placement-group-autoscaling)</p>
<p>11. [Resource Constraints and Limits](#resource-constraints-and-limits)</p>
<p>12. [Multi-Cloud and Hybrid Deployments](#multi-cloud-and-hybrid-deployments)</p>
<p>13. [Performance Optimization](#performance-optimization)</p>
<p>14. [Configuration and Tuning](#configuration-and-tuning)</p>
<p>15. [Production Deployment](#production-deployment)</p>
<p>16. [Troubleshooting and Debugging](#troubleshooting-and-debugging)</p>
<p>17. [Best Practices](#best-practices)</p>
<p>18. [Advanced Topics](#advanced-topics)</p>

<h2>Introduction</h2>

<p>Ray's autoscaling system is like having a smart assistant that watches your computing workload and automatically adjusts your cluster size. When you have more work to do, it adds more machines. When things quiet down, it removes unused machines to save money. Think of it as an intelligent resource manager that ensures you always have just the right amount of computing power for your needs.</p>

<h3>What Makes Ray Autoscaling Special?</h3>

<p><strong>Smart Decision Making</strong>: Unlike simple autoscalers that just count CPU usage, Ray's autoscaler understands the specific resources your tasks need - CPUs, GPUs, memory, and custom resources. It can predict exactly what type of machines you need before you run out of capacity.</p>

<p><strong>Lightning Fast</strong>: The autoscaler can make scaling decisions in seconds, not minutes. It doesn't wait for machines to become overloaded - it anticipates demand and scales proactively.</p>

<p><strong>Cost Efficient</strong>: By understanding your workload patterns, it minimizes cloud costs by spinning up the cheapest combination of machines that can handle your work.</p>

<p><strong>Multi-Cloud Ready</strong>: Works seamlessly across AWS, GCP, Azure, Kubernetes, and even your local data center.</p>

<h3>Core Features</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    A["üéØ Smart Resource Detection"] --> B["‚ö° Fast Scaling Decisions"]
    B --> C["üí∞ Cost Optimization"]
    C --> D["‚òÅÔ∏è Multi-Cloud Support"]
    D --> E["üîß Easy Configuration"]
    
    style A fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style B fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style C fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style D fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style E fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<ul>
<li><strong>Resource-Aware Scaling</strong>: Understands your exact compute needs (CPU, GPU, memory)</li>
<li><strong>Placement Group Support</strong>: Handles complex multi-node workloads that need specific arrangements</li>
<li><strong>Intelligent Binpacking</strong>: Finds the most cost-effective way to fit your workload</li>
<li><strong>Preemptible Instance Support</strong>: Uses cheaper spot/preemptible instances when appropriate</li>
<li><strong>Custom Resource Types</strong>: Supports specialized hardware like TPUs, FPGAs, or custom accelerators</li>
</ul>

<h2>Autoscaling Architecture Overview</h2>

<p>Think of Ray's autoscaling system as a well-orchestrated team where each component has a specific job, but they all work together seamlessly.</p>

<h3>The Big Picture: How It All Works Together</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üìä Monitoring Layer"
        LM[Load Metrics<br/>üìà Watches cluster usage]
        RD[Resource Demand<br/>üéØ Detects what's needed]
    end
    
    subgraph "üß† Intelligence Layer"
        AS[Autoscaler Core<br/>ü§ñ Makes scaling decisions]
        RS[Resource Scheduler<br/>‚öñÔ∏è Plans optimal cluster shape]
    end
    
    subgraph "üîß Execution Layer"
        IM[Instance Manager<br/>üèóÔ∏è Manages node lifecycle]
        NP[Node Providers<br/>‚òÅÔ∏è Talks to cloud APIs]
    end
    
    subgraph "‚òÅÔ∏è Cloud Infrastructure"
        AWS[AWS EC2<br/>üü† Amazon Cloud]
        GCP[GCP Compute<br/>üîµ Google Cloud]
        AZURE[Azure VMs<br/>üü£ Microsoft Cloud]
        K8S[Kubernetes<br/>‚öôÔ∏è Container Platform]
    end
    
    LM --> AS
    RD --> AS
    AS --> RS
    RS --> IM
    IM --> NP
    NP --> AWS
    NP --> GCP
    NP --> AZURE
    NP --> K8S
    
    style LM fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style RD fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style AS fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style RS fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style IM fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
    style NP fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    style AWS fill:#ff6d00,stroke:#e65100,stroke-width:2px,color:#fff
    style GCP fill:#2196f3,stroke:#0d47a1,stroke-width:2px,color:#fff
    style AZURE fill:#9c27b0,stroke:#4a148c,stroke-width:2px,color:#fff
    style K8S fill:#4caf50,stroke:#1b5e20,stroke-width:2px,color:#fff
        </div>
    </div>
</div>
</p>

<h3>What Happens During Autoscaling (In Plain English)</h3>

<p>1. <strong>üëÄ Watching Phase</strong>: The system continuously monitors your cluster, tracking how many tasks are waiting, what resources they need, and how busy each machine is.</p>

<p>2. <strong>ü§î Thinking Phase</strong>: When it notices unmet demand, the autoscaler calculates the optimal mix of machines to add, considering costs, availability, and your constraints.</p>

<p>3. <strong>üöÄ Acting Phase</strong>: It launches new machines through cloud APIs, installs Ray software, and integrates them into your cluster.</p>

<p>4. <strong>üßπ Cleanup Phase</strong>: When machines sit idle too long, it safely removes them to save costs.</p>

<h3>Multi-Level Decision Making</h3>

<p>Ray's autoscaler operates at multiple levels to make optimal decisions:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    subgraph "üéØ Application Level"
        TASKS[Tasks & Actors<br/>üìã Your actual workload]
        PG[Placement Groups<br/>üèóÔ∏è Complex arrangements]
    end
    
    subgraph "‚öñÔ∏è Resource Level"
        CPU[CPU Requirements<br/>üîß Processing power]
        GPU[GPU Requirements<br/>üéÆ Graphics/ML acceleration]
        MEM[Memory Requirements<br/>üíæ RAM needs]
        CUSTOM[Custom Resources<br/>üî¨ Special hardware]
    end
    
    subgraph "üèóÔ∏è Infrastructure Level"
        NODES[Node Types<br/>üñ•Ô∏è Machine configurations]
        REGIONS[Availability Zones<br/>üåç Geographic distribution]
        COSTS[Cost Optimization<br/>üí∞ Budget efficiency]
    end
    
    TASKS --> CPU
    TASKS --> GPU
    TASKS --> MEM
    PG --> NODES
    CPU --> NODES
    GPU --> NODES
    MEM --> NODES
    CUSTOM --> NODES
    NODES --> REGIONS
    NODES --> COSTS
    
    style TASKS fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style PG fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style CPU fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style GPU fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style MEM fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
    style CUSTOM fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style NODES fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style REGIONS fill:#fff8e1,stroke:#f57c00,stroke-width:2px,color:#000
    style COSTS fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h2>Core Autoscaling Components</h2>

<p>Let's dive into the key players that make Ray's autoscaling system work. Think of these as different departments in a company, each with specific responsibilities.</p>

<h3>1. StandardAutoscaler - The Main Controller</h3>

<p><strong>Location</strong>: <code>python/ray/autoscaler/_private/autoscaler.py</code></p>

<p>This is the "CEO" of the autoscaling system - it coordinates everything and makes the final decisions.</p>

<p>
<div class="codehilite">
<pre><code class="python">class StandardAutoscaler:
    def __init__(self, config_reader, load_metrics, gcs_client, ...):
        # The brain of the operation
        self.provider = self._get_node_provider(provider_config, cluster_name)
        self.resource_demand_scheduler = ResourceDemandScheduler(...)
        self.load_metrics = load_metrics
        
        # Key configuration settings
        self.max_workers = config.get("max_workers", 0)
        self.upscaling_speed = config.get("upscaling_speed", 1.0)
        self.idle_timeout_minutes = config.get("idle_timeout_minutes", 5)</code></pre>
</div>
</p>

<p><strong>What It Does (In Simple Terms)</strong>:</p>
<ul>
<li>Wakes up every few seconds to check if the cluster needs changes</li>
<li>Decides when to add new machines (scale up)</li>
<li>Decides when to remove idle machines (scale down)</li>
<li>Ensures the cluster never exceeds your budget or size limits</li>
</ul>

<p><strong>Key Responsibilities</strong>:</p>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    A["üîç Monitor Demand"] --> B["üìä Analyze Resources"]
    B --> C["üéØ Make Decisions"]
    C --> D["üöÄ Execute Changes"]
    D --> E["üìù Update Status"]
    E --> A
    
    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style B fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style C fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style D fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style E fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h3>2. ResourceDemandScheduler - The Smart Planner</h3>

<p><strong>Location</strong>: <code>python/ray/autoscaler/_private/resource_demand_scheduler.py</code></p>

<p>This component is like a smart logistics coordinator that figures out the most efficient way to arrange your computing resources.</p>

<p>
<div class="codehilite">
<pre><code class="python">class ResourceDemandScheduler:
    def get_nodes_to_launch(self, 
                           resource_demands,           # What you need
                           unused_resources_by_ip,     # What's available
                           pending_placement_groups,   # Complex arrangements
                           max_resources_by_ip):       # Machine capacities
        
        # Step 1: Understand current cluster state
        node_resources, node_type_counts = self.calculate_node_resources(...)
        
        # Step 2: Respect minimum worker requirements
        adjusted_min_workers = self._add_min_workers_nodes(...)
        
        # Step 3: Handle placement groups (complex workloads)
        spread_pg_nodes = self.reserve_and_allocate_spread(...)
        
        # Step 4: Use "bin packing" to find optimal machine mix
        nodes_to_add, unfulfilled = get_nodes_for(...)
        
        return total_nodes_to_add, final_unfulfilled</code></pre>
</div>
</p>

<p><strong>The Bin Packing Magic</strong>: Think of this like playing Tetris with cloud machines. You have different shaped "resource blocks" (your tasks) and different sized "containers" (machine types). The scheduler finds the combination that wastes the least space and costs the least money.</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    subgraph "üß© Resource Demands"
        T1["Task A<br/>2 CPU, 1 GPU<br/>üîßüéÆ"]
        T2["Task B<br/>4 CPU, 0 GPU<br/>üîßüîßüîßüîß"]
        T3["Task C<br/>1 CPU, 2 GPU<br/>üîßüéÆüéÆ"]
    end
    
    subgraph "üèóÔ∏è Available Machine Types"
        M1["Small Instance<br/>4 CPU, 0 GPU<br/>$0.10/hour<br/>üí∞"]
        M2["GPU Instance<br/>8 CPU, 4 GPU<br/>$2.40/hour<br/>üí∞üí∞üí∞"]
        M3["Balanced Instance<br/>16 CPU, 2 GPU<br/>$1.20/hour<br/>üí∞üí∞"]
    end
    
    subgraph "üéØ Optimal Allocation"
        SOLUTION["1x GPU Instance<br/>Fits all tasks<br/>Total: $2.40/hour<br/>‚úÖ Cost Efficient"]
    end
    
    T1 --> SOLUTION
    T2 --> SOLUTION
    T3 --> SOLUTION
    M2 --> SOLUTION
    
    style T1 fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style T2 fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    style T3 fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style M1 fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style M2 fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
    style M3 fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style SOLUTION fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#000
        </div>
    </div>
</div>
</p>

<h3>3. LoadMetrics - The Cluster Monitor</h3>

<p><strong>Location</strong>: <code>python/ray/autoscaler/_private/load_metrics.py</code></p>

<p>This is like having a health monitor attached to your cluster that constantly reports vital signs.</p>

<p>
<div class="codehilite">
<pre><code class="python">class LoadMetrics:
    def __init__(self):
        # Tracks what resources each machine has
        self.static_resources_by_ip = {}      # Total capacity
        self.dynamic_resources_by_ip = {}     # Currently available
        
        # Tracks what work is waiting
        self.pending_resource_requests = []   # Individual tasks
        self.pending_placement_groups = []    # Complex arrangements
        
        # Tracks cluster health
        self.last_heartbeat_time_by_ip = {}   # When we last heard from nodes
        self.last_heartbeat_failed = {}       # Which nodes are unresponsive</code></pre>
</div>
</p>

<p><strong>What It Monitors</strong>:</p>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üìä Cluster Vital Signs"
        CPU_USAGE["CPU Usage<br/>üîß How busy processors are"]
        GPU_USAGE["GPU Usage<br/>üéÆ Graphics card utilization"]
        MEMORY_USAGE["Memory Usage<br/>üíæ RAM consumption"]
        DISK_USAGE["Disk Usage<br/>üíø Storage utilization"]
    end
    
    subgraph "üìã Workload Queue"
        PENDING_TASKS["Pending Tasks<br/>‚è≥ Work waiting to start"]
        PLACEMENT_GROUPS["Placement Groups<br/>üèóÔ∏è Complex arrangements"]
        RESOURCE_REQUESTS["Resource Requests<br/>üéØ Specific demands"]
    end
    
    subgraph "üíì Node Health"
        HEARTBEATS["Node Heartbeats<br/>üíó Alive/Dead status"]
        RESPONSE_TIME["Response Times<br/>‚ö° Performance metrics"]
        ERROR_RATES["Error Rates<br/>üö® Failure indicators"]
    end
    
    CPU_USAGE --> DECISION["ü§ñ Scaling Decision"]
    GPU_USAGE --> DECISION
    MEMORY_USAGE --> DECISION
    PENDING_TASKS --> DECISION
    PLACEMENT_GROUPS --> DECISION
    HEARTBEATS --> DECISION
    
    style CPU_USAGE fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style GPU_USAGE fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style MEMORY_USAGE fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style DISK_USAGE fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style PENDING_TASKS fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
    style PLACEMENT_GROUPS fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    style RESOURCE_REQUESTS fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    style HEARTBEATS fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style RESPONSE_TIME fill:#fff8e1,stroke:#ef6c00,stroke-width:2px,color:#000
    style ERROR_RATES fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#000
    style DECISION fill:#e0f2f1,stroke:#00695c,stroke-width:3px,color:#000
        </div>
    </div>
</div>
</p>

<h3>4. Node Providers - The Cloud Connectors</h3>

<p><strong>Location</strong>: <code>python/ray/autoscaler/_private/providers.py</code></p>

<p>These are like specialized translators that know how to talk to different cloud providers. Each provider speaks its own "language" (API), but Ray abstracts this complexity.</p>

<p>
<div class="codehilite">
<pre><code class="python">class AWSNodeProvider(NodeProvider):
    def create_node(self, node_config, tags, count):
        # Launches EC2 instances using AWS API
        response = self.ec2.run_instances(
            ImageId=node_config["ImageId"],
            InstanceType=node_config["InstanceType"],
            MinCount=count, MaxCount=count,
            SubnetId=node_config["SubnetId"]
        )
        return [instance.id for instance in response["Instances"]]

class GCPNodeProvider(NodeProvider):
    def create_node(self, node_config, tags, count):
        # Launches Compute Engine instances using GCP API
        operation = self.compute.instances().insert(
            project=self.project_id,
            zone=self.zone,
            body=instance_config
        ).execute()
        return operation["targetId"]</code></pre>
</div>
</p>

<p><strong>Supported Cloud Providers</strong>:</p>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "‚òÅÔ∏è Major Cloud Providers"
        AWS["üü† Amazon Web Services<br/>EC2, Spot Instances"]
        GCP["üîµ Google Cloud Platform<br/>Compute Engine, Preemptible"]
        AZURE["üü£ Microsoft Azure<br/>Virtual Machines, Spot VMs"]
    end
    
    subgraph "üèóÔ∏è Container Platforms"
        K8S["‚öôÔ∏è Kubernetes<br/>Any K8s cluster"]
        KUBERAY["üöÄ KubeRay Operator<br/>K8s-native Ray"]
    end
    
    subgraph "üè† On-Premise & Hybrid"
        LOCAL["üè† Local Provider<br/>Your own machines"]
        VSPHERE["üîß VMware vSphere<br/>Private cloud"]
        EXTERNAL["üîå External Provider<br/>Custom integrations"]
    end
    
    RAY_AUTOSCALER["ü§ñ Ray Autoscaler<br/>Universal Interface"] --> AWS
    RAY_AUTOSCALER --> GCP
    RAY_AUTOSCALER --> AZURE
    RAY_AUTOSCALER --> K8S
    RAY_AUTOSCALER --> KUBERAY
    RAY_AUTOSCALER --> LOCAL
    RAY_AUTOSCALER --> VSPHERE
    RAY_AUTOSCALER --> EXTERNAL
    
    style RAY_AUTOSCALER fill:#e0f2f1,stroke:#00695c,stroke-width:3px,color:#000
    style AWS fill:#ff6d00,stroke:#e65100,stroke-width:2px,color:#fff
    style GCP fill:#2196f3,stroke:#0d47a1,stroke-width:2px,color:#fff
    style AZURE fill:#9c27b0,stroke:#4a148c,stroke-width:2px,color:#fff
    style K8S fill:#4caf50,stroke:#1b5e20,stroke-width:2px,color:#fff
    style KUBERAY fill:#00bcd4,stroke:#006064,stroke-width:2px,color:#fff
    style LOCAL fill:#795548,stroke:#3e2723,stroke-width:2px,color:#fff
    style VSPHERE fill:#607d8b,stroke:#263238,stroke-width:2px,color:#fff
    style EXTERNAL fill:#ff9800,stroke:#e65100,stroke-width:2px,color:#fff
        </div>
    </div>
</div>
</p>

<h3>5. GCS Autoscaler State Manager - The Central Coordinator</h3>

<p><strong>Location</strong>: <code>src/ray/gcs/gcs_server/gcs_autoscaler_state_manager.cc</code></p>

<p>This component runs inside Ray's Global Control Service (GCS) and acts as the central hub for all autoscaling information.</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsAutoscalerStateManager {
    void UpdateResourceLoadAndUsage(rpc::ResourcesData data) {
        // Receives resource reports from all nodes
        NodeID node_id = NodeID::FromBinary(data.node_id());
        node_resource_info_[node_id] = std::move(data);
    }
    
    void GetPendingResourceRequests(rpc::autoscaler::ClusterResourceState *state) {
        // Aggregates demand from all nodes
        auto aggregate_load = GetAggregatedResourceLoad();
        for (const auto &[shape, demand] : aggregate_load) {
            if (demand.num_ready_requests_queued() > 0) {
                // Add to autoscaling demand
                auto pending_req = state->add_pending_resource_requests();
                pending_req->set_count(demand.num_ready_requests_queued());
            }
        }
    }
};</code></pre>
</div>
</p>

<p><strong>Role in the System</strong>:</p>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üè≠ Individual Raylets"
        R1["Raylet 1<br/>üìä Reports: 4 CPU, 2 pending tasks"]
        R2["Raylet 2<br/>üìä Reports: 8 CPU, 1 GPU, 0 pending"]
        R3["Raylet 3<br/>üìä Reports: 2 CPU, 5 pending tasks"]
    end
    
    subgraph "üèõÔ∏è Global Control Service (GCS)"
        GCS_ASM["GCS Autoscaler State Manager<br/>üß† Central Intelligence"]
    end
    
    subgraph "ü§ñ Autoscaler"
        AUTOSCALER["StandardAutoscaler<br/>üéØ Decision Maker"]
    end
    
    R1 --> GCS_ASM
    R2 --> GCS_ASM
    R3 --> GCS_ASM
    GCS_ASM --> AUTOSCALER
    
    GCS_ASM -.-> AGG_STATE["üìà Aggregated State<br/>Total: 14 CPU, 1 GPU<br/>Pending: 7 tasks"]
    
    style R1 fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style R2 fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style R3 fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style GCS_ASM fill:#fce4ec,stroke:#c2185b,stroke-width:3px,color:#000
    style AUTOSCALER fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
    style AGG_STATE fill:#e0f2f1,stroke:#00695c,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h2>Resource Demand Detection</h2>

<p>Understanding how Ray detects and measures resource demand is crucial because this drives all autoscaling decisions. Think of it like a restaurant that needs to predict how many customers will arrive and what they'll order.</p>

<h3>How Ray Sees Resource Demand</h3>

<p>Ray tracks demand at multiple levels, each providing different insights:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üéØ Immediate Demand (Next Few Seconds)"
        QUEUED_TASKS["Queued Tasks<br/>üìã Tasks ready to run<br/>‚è±Ô∏è Need resources NOW"]
        ACTOR_CREATION["Actor Creation<br/>üé≠ Long-running processes<br/>üè† Need permanent homes"]
    end
    
    subgraph "üìä Aggregate Demand (Next Few Minutes)"
        PLACEMENT_GROUPS["Placement Groups<br/>üèóÔ∏è Complex multi-node workloads<br/>üéØ Need coordinated resources"]
        RESOURCE_REQUESTS["Resource Requests<br/>üé™ User predictions<br/>üìà Expected future load"]
    end
    
    subgraph "üîÆ Predictive Demand (Next Hour+)"
        AUTOSCALING_HINTS["Autoscaling Hints<br/>üß† ML-based predictions<br/>üìä Historical patterns"]
        MIN_WORKERS["Min Workers Config<br/>‚ö° Always-on capacity<br/>üõ°Ô∏è Performance guarantee"]
    end
    
    QUEUED_TASKS --> DECISION["ü§ñ Scaling Decision<br/>üéØ Add N nodes of type X"]
    ACTOR_CREATION --> DECISION
    PLACEMENT_GROUPS --> DECISION
    RESOURCE_REQUESTS --> DECISION
    AUTOSCALING_HINTS --> DECISION
    MIN_WORKERS --> DECISION
    
    style QUEUED_TASKS fill:#ffcdd2,stroke:#d32f2f,stroke-width:2px,color:#000
    style ACTOR_CREATION fill:#ffcdd2,stroke:#d32f2f,stroke-width:2px,color:#000
    style PLACEMENT_GROUPS fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style RESOURCE_REQUESTS fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style AUTOSCALING_HINTS fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style MIN_WORKERS fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    style DECISION fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#000
        </div>
    </div>
</div>
</p>

<h3>Resource Demand Aggregation Process</h3>

<p>Here's how Ray collects and processes demand information:</p>

<p>
<div class="codehilite">
<pre><code class="python">class LoadMetrics:
    def summary(self) -> LoadMetricsSummary:
        # Step 1: Collect demand from each node's queued tasks
        aggregate_load = {}
        for node_ip, resource_data in self.resource_usage_by_ip.items():
            for resource_shape, demand in resource_data.items():
                total_demand = (demand.num_ready_requests_queued() + 
                               demand.num_infeasible_requests_queued() +
                               demand.backlog_size())
                if total_demand > 0:
                    aggregate_load[resource_shape] = total_demand
        
        # Step 2: Add placement group demands
        pg_demands = self._get_placement_group_demands()
        
        # Step 3: Add explicit resource requests
        explicit_requests = self.resource_requests or []
        
        return LoadMetricsSummary(
            resource_demand=aggregate_load,
            pg_demand=pg_demands,
            request_demand=explicit_requests
        )</code></pre>
</div>
</p>

<h3>Types of Resource Shapes</h3>

<p>Ray thinks about resources in "shapes" - specific combinations of resources that tasks need:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "üîß Simple Shapes"
        CPU_ONLY["CPU Only<br/>{'CPU': 2}<br/>üîßüîß Web servers, APIs"]
        MEMORY_HEAVY["Memory Heavy<br/>{'CPU': 1, 'memory': 16GB}<br/>üîßüíæ Data processing"]
    end
    
    subgraph "üéÆ GPU Shapes"
        GPU_TRAINING["GPU Training<br/>{'CPU': 8, 'GPU': 4}<br/>üîßüîßüéÆüéÆ ML training"]
        GPU_INFERENCE["GPU Inference<br/>{'CPU': 2, 'GPU': 1}<br/>üîßüéÆ Model serving"]
    end
    
    subgraph "üî¨ Custom Shapes"
        TPU_SHAPE["TPU Workload<br/>{'CPU': 4, 'TPU': 8}<br/>üîßüß† Specialized ML"]
        MIXED_SHAPE["Mixed Resources<br/>{'CPU': 4, 'GPU': 2, 'FPGA': 1}<br/>üîßüéÆ‚ö° Complex compute"]
    end
    
    style CPU_ONLY fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style MEMORY_HEAVY fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style GPU_TRAINING fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style GPU_INFERENCE fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style TPU_SHAPE fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
    style MIXED_SHAPE fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
        </div>
    </div>
</div>
</p>

<h3>Real-Time Demand Tracking</h3>

<p>The GCS continuously receives updates from all cluster nodes about their resource usage and pending work:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From src/ray/gcs/gcs_server/gcs_autoscaler_state_manager.cc
void GcsAutoscalerStateManager::UpdateResourceLoadAndUsage(rpc::ResourcesData data) {
    NodeID node_id = NodeID::FromBinary(data.node_id());
    
    // Update this node's resource information
    auto &node_info = node_resource_info_[node_id];
    node_info.second = std::move(data);
    node_info.first = absl::Now();  // Last update time
    
    // The data includes:
    // - Total resources on this node
    // - Currently available resources  
    // - Resource demands by shape (queued tasks)
    // - Object store memory usage
    // - Placement group demands
}</code></pre>
</div>
</p>

<h3>Demand Processing Pipeline</h3>

<p>Here's the complete flow of how demand information travels through the system:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "üìä Monitoring Layer"
        LM[Load Metrics<br/>üìà Watches cluster usage]
        RD[Resource Demand<br/>üéØ Detects what's needed]
    end
    
    subgraph "üß† Intelligence Layer"
        AS[Autoscaler Core<br/>ü§ñ Makes scaling decisions]
        RS[Resource Scheduler<br/>‚öñÔ∏è Plans optimal cluster shape]
    end
    
    subgraph "üîß Execution Layer"
        IM[Instance Manager<br/>üèóÔ∏è Manages node lifecycle]
        NP[Node Providers<br/>‚òÅÔ∏è Talks to cloud APIs]
    end
    
    subgraph "‚òÅÔ∏è Cloud Infrastructure"
        AWS[AWS EC2<br/>üü† Amazon Cloud]
        GCP[GCP Compute<br/>üîµ Google Cloud]
        AZURE[Azure VMs<br/>üü£ Microsoft Cloud]
        K8S[Kubernetes<br/>‚öôÔ∏è Container Platform]
    end
    
    LM --> AS
    RD --> AS
    AS --> RS
    RS --> IM
    IM --> NP
    NP --> AWS
    NP --> GCP
    NP --> AZURE
    NP --> K8S
    
    style LM fill:#e3f2fd,stroke:#1976d2,stroke-width:2px,color:#000
    style RD fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000
    style AS fill:#fff3e0,stroke:#f57c00,stroke-width:2px,color:#000
    style RS fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style IM fill:#e8eaf6,stroke:#3f51b5,stroke-width:2px,color:#000
    style NP fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    style AWS fill:#ff6d00,stroke:#e65100,stroke-width:2px,color:#fff
    style GCP fill:#2196f3,stroke:#0d47a1,stroke-width:2px,color:#fff
    style AZURE fill:#9c27b0,stroke:#4a148c,stroke-width:2px,color:#fff
    style K8S fill:#4caf50,stroke:#1b5e20,stroke-width:2px,color:#fff
        </div>
    </div>
</div>
0</p>

<h3>Intelligent Demand Prediction</h3>

<p>Ray doesn't just react to current demand - it predicts future needs:</p>

<p>
<div class="codehilite">
<pre><code class="python">def _should_scale_up_preemptively(self, load_metrics):
    # Look at demand growth rate
    current_demand = len(load_metrics.pending_tasks)
    demand_growth_rate = (current_demand - self.last_demand) / self.update_interval
    
    # If demand is growing quickly, scale up before we run out
    if demand_growth_rate > self.preemptive_threshold:
        return True
        
    # Look at placement group patterns
    pending_pgs = load_metrics.pending_placement_groups
    if len(pending_pgs) > 0:
        # Placement groups often come in batches
        return True
        
    return False</code></pre>
</div>
</p>
        </div>
            
        <div class="chapter" id="chapter-11">
            <h1 class="chapter-title">Chapter 11: Part III: Advanced Ray Systems</h1>
            <h1>Part III: Advanced Ray Systems</h1>


<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Architecture Overview](#architecture-overview)</p>
<p>3. [Core HA Components](#core-ha-components)</p>
<p>4. [GCS Fault Tolerance](#gcs-fault-tolerance)</p>
<p>5. [Node Failure Handling](#node-failure-handling)</p>
<p>6. [Actor Fault Tolerance](#actor-fault-tolerance)</p>
<p>7. [Object Fault Tolerance](#object-fault-tolerance)</p>
<p>8. [Network Partition Recovery](#network-partition-recovery)</p>
<p>9. [Health Monitoring](#health-monitoring)</p>
<p>10. [Recovery Mechanisms](#recovery-mechanisms)</p>
<p>11. [Performance Impact](#performance-impact)</p>
<p>12. [Implementation Details](#implementation-details)</p>
<p>13. [Configuration Guidelines](#configuration-guidelines)</p>

<h2>Introduction</h2>

<p>Ray's High Availability (HA) system provides <strong>comprehensive fault tolerance</strong> across all layers of the distributed system. It ensures that Ray clusters can survive and recover from various types of failures including node crashes, network partitions, process failures, and storage outages. The HA system is designed to minimize downtime and maintain service continuity while preserving data consistency and system reliability.</p>

<h3>Key Principles</h3>

<p>1. <strong>Layered Fault Tolerance</strong>: Different components have specialized recovery mechanisms</p>
<p>2. <strong>Automatic Recovery</strong>: Most failures are handled automatically without manual intervention</p>
<p>3. <strong>Graceful Degradation</strong>: System continues operating with reduced capacity during failures</p>
<p>4. <strong>State Preservation</strong>: Critical state is persisted to enable recovery after failures</p>
<p>5. <strong>Minimal Performance Impact</strong>: HA mechanisms are optimized for production workloads</p>

<h3>Failure Types Handled</h3>

<ul>
<li><strong>Head Node Failures</strong>: GCS server crashes, head node hardware failures</li>
<li><strong>Worker Node Failures</strong>: Raylet crashes, worker node hardware failures</li>
<li><strong>Process Failures</strong>: Actor crashes, task failures, worker process exits</li>
<li><strong>Network Partitions</strong>: Network splits, connectivity issues</li>
<li><strong>Storage Failures</strong>: Redis outages, disk failures, I/O errors</li>
<li><strong>Resource Exhaustion</strong>: Memory pressure, CPU saturation, disk space</li>
</ul>

<h2>Architecture Overview</h2>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Ray High Availability Architecture"
        subgraph "Fault Tolerance Layers"
            subgraph "Application Layer"
                ActorFT["Actor Fault Tolerance<br/>Automatic restarts"]
                TaskRetry["Task Retry Logic<br/>Failed task recovery"]
                ObjectReconstruction["Object Reconstruction<br/>Lineage-based recovery"]
            end
            
            subgraph "System Layer"
                NodeFailure["Node Failure Detection<br/>Health monitoring"]
                GCSFT["GCS Fault Tolerance<br/>Head node recovery"]
                NetworkResilience["Network Resilience<br/>Partition tolerance"]
            end
            
            subgraph "Storage Layer"
                PersistentStorage["Persistent Storage<br/>Redis/External DB"]
                Replication["Data Replication<br/>Multi-copy storage"]
                BackupRestore["Backup & Restore<br/>State snapshots"]
            end
        end
        
        subgraph "Monitoring & Detection"
            HealthChecks["Health Check Manager<br/>Proactive monitoring"]
            FailureDetector["Failure Detector<br/>Timeout-based detection"]
            MetricsMonitoring["Metrics Monitoring<br/>Performance tracking"]
        end
        
        subgraph "Recovery Coordination"
            RecoveryManager["Recovery Manager<br/>Orchestration logic"]
            StateRestore["State Restoration<br/>Data recovery"]
            ServiceRestart["Service Restart<br/>Process revival"]
        end
    end
    
    ActorFT --> NodeFailure
    TaskRetry --> GCSFT
    ObjectReconstruction --> PersistentStorage
    
    HealthChecks --> FailureDetector
    FailureDetector --> RecoveryManager
    MetricsMonitoring --> RecoveryManager
    
    RecoveryManager --> StateRestore
    RecoveryManager --> ServiceRestart
    
    PersistentStorage --> StateRestore
    Replication --> BackupRestore
    
    style ActorFT fill:#e1f5fe
    style GCSFT fill:#f3e5f5
    style PersistentStorage fill:#e8f5e8
    style HealthChecks fill:#fff3e0
        </div>
    </div>
</div>
</p>

<h3>HA Design Philosophy</h3>

<p><strong>Failure Isolation</strong>: Failures in one component don't cascade to others</p>
<p><strong>Fast Recovery</strong>: Minimize time between failure detection and recovery completion</p>
<p><strong>Consistency Preservation</strong>: Maintain data consistency during recovery operations</p>
<p><strong>Observability</strong>: Comprehensive monitoring and alerting for failure scenarios</p>

<h2>Core HA Components</h2>

<p>The Ray HA system consists of several interconnected components working together to provide comprehensive fault tolerance.</p>

<h3>Component Interaction Model</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Monitor as Health Monitor
    participant Detector as Failure Detector  
    participant GCS as GCS Server
    participant Recovery as Recovery Manager
    participant Storage as Persistent Storage
    
    Note over Monitor,Storage: Normal Operation
    
    Monitor->>Detector: Health check failure
    Detector->>GCS: Report node failure
    GCS->>Recovery: Trigger recovery process
    
    Recovery->>Storage: Load persistent state
    Storage-->>Recovery: Return saved state
    Recovery->>GCS: Restore service state
    
    GCS->>Monitor: Resume health monitoring
    
    Note over Monitor,Storage: Service Restored
        </div>
    </div>
</div>
</p>

<h3>HA Component Responsibilities</h3>

<p>| Component | Primary Function | Failure Types Handled | Recovery Method |</p>
<p>|-----------|------------------|----------------------|-----------------|</p>
<p>| GCS Health Manager | Node health monitoring | Process crashes, network issues | Proactive health checks |</p>
<p>| Actor Manager | Actor lifecycle | Actor process failures | Automatic restart with state |</p>
<p>| Object Manager | Object availability | Data loss, node failures | Lineage reconstruction |</p>
<p>| Node Manager | Cluster membership | Node crashes, departures | Membership updates |</p>
<p>| Storage Manager | State persistence | Storage failures | Backup/restore operations |</p>

<h2>GCS Fault Tolerance</h2>

<p>The Global Control Service (GCS) is the central coordination point, making its fault tolerance critical for cluster survival.</p>

<h3>GCS HA Architecture</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "GCS High Availability"
        subgraph "Active GCS"
            GCSProcess["GCS Server Process<br/>Active coordination"]
            InMemoryState["In-Memory State<br/>Hot data"]
            RPCHandlers["RPC Handlers<br/>Client requests"]
        end
        
        subgraph "Persistent Layer"
            RedisCluster["Redis Cluster<br/>HA storage backend"]
            StateSnapshots["State Snapshots<br/>Periodic saves"]
            WALogs["Write-Ahead Logs<br/>Operation history"]
        end
        
        subgraph "Recovery System"
            FailureDetection["Failure Detection<br/>Process monitoring"]
            StateReconstruction["State Reconstruction<br/>Data restoration"]
            ClientReconnection["Client Reconnection<br/>Session recovery"]
        end
    end
    
    GCSProcess <--> RedisCluster
    InMemoryState --> StateSnapshots
    RPCHandlers --> WALogs
    
    FailureDetection --> StateReconstruction
    StateReconstruction <--> RedisCluster
    StateReconstruction --> ClientReconnection
    
    style GCSProcess fill:#e1f5fe
    style RedisCluster fill:#f3e5f5
    style FailureDetection fill:#e8f5e8
        </div>
    </div>
</div>
</p>

<h3>GCS Recovery Process</h3>

<p>From <code>python/ray/tests/test_gcs_fault_tolerance.py:45-100</code>:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Client as Ray Client
    participant GCS as GCS Server
    participant Redis as Redis Storage
    participant Monitor as Process Monitor
    participant NewGCS as New GCS Instance
    
    Note over Client,NewGCS: GCS Failure Scenario
    
    Client->>GCS: Normal operations
    GCS->>Redis: Persist state changes
    
    Note over GCS: GCS Process Dies
    
    Monitor->>Monitor: Detect GCS failure
    Monitor->>NewGCS: Start new GCS instance
    
    NewGCS->>Redis: Load persistent state
    Redis-->>NewGCS: Return saved data
    
    NewGCS->>NewGCS: Reconstruct in-memory state
    NewGCS->>Client: Notify service restored
    
    Client->>NewGCS: Resume operations
    
    Note over Client,NewGCS: Service Fully Restored
        </div>
    </div>
</div>
</p>

<p><strong>GCS Recovery Configuration:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From test configuration
struct GCSRecoveryConfig {
  int64_t gcs_rpc_server_reconnect_timeout_s = 60;  // Reconnection timeout
  int64_t gcs_server_request_timeout_seconds = 10;  // Request timeout
  int64_t redis_db_connect_retries = 50;            // Redis retry attempts
  bool enable_external_redis = true;                // Use persistent Redis
};</code></pre>
</div>
</p>

<h3>Critical State Preserved</h3>

<p>1. <strong>Node Registry</strong>: All active and failed nodes</p>
<p>2. <strong>Actor Information</strong>: Actor metadata and placement</p>
<p>3. <strong>Job State</strong>: Running and completed jobs</p>
<p>4. <strong>Resource Allocation</strong>: Cluster resource assignments</p>
<p>5. <strong>Placement Groups</strong>: Group configurations and status</p>

<h2>Node Failure Handling</h2>

<p>Ray implements sophisticated node failure detection and recovery mechanisms to maintain cluster health.</p>

<h3>Node State Transitions</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
stateDiagram-v2
    [*] --> Healthy: Node registration
    Healthy --> Suspected: Health check failures
    Suspected --> Healthy: Health restored
    Suspected --> Failed: Failure threshold exceeded
    
    Failed --> Removed: Cleanup completion
    Removed --> [*]: Node fully cleaned up
    
    Healthy --> Draining: Graceful shutdown
    Draining --> Removed: Drain completed
    
    note right of Suspected
        Temporary connectivity issues
        or high load conditions
    end note
    
    note right of Failed
        Node unreachable beyond
        recovery threshold
    end note
    
    note right of Draining
        Voluntary node removal
        with task migration
    end note
        </div>
    </div>
</div>
</p>

<h3>Health Check Protocol</h3>

<p>From <code>src/ray/gcs/gcs_server/gcs_health_check_manager.h:40-60</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsHealthCheckManager {
  // Health check configuration
  int64_t initial_delay_ms_;    // Delay before first check
  int64_t timeout_ms_;         // Timeout per health check
  int64_t period_ms_;          // Interval between checks  
  int64_t failure_threshold_;  // Failures before marking dead
  
  // Health check process
  void StartHealthCheck() {
    // Send gRPC health check to node
    stub_->Check(request_, &response_, [this](Status status) {
      if (status.ok()) {
        health_check_remaining_ = failure_threshold_;  // Reset counter
        ScheduleNextCheck();
      } else {
        health_check_remaining_--;
        if (health_check_remaining_ <= 0) {
          manager_->FailNode(node_id_);  // Mark node as failed
        } else {
          ScheduleNextCheck();  // Retry after delay
        }
      }
    });
  }
};</code></pre>
</div>
</p>

<h3>Node Failure Impact and Recovery</h3>

<p><strong>Immediate Effects:</strong></p>
<ul>
<li>All running tasks on the node are terminated</li>
<li>Actors hosted on the node become unavailable</li>
<li>Objects stored locally are marked as lost</li>
<li>Resource allocations are freed</li>
</ul>

<p><strong>Recovery Actions:</strong></p>
<ul>
<li>Failed tasks are automatically retried on healthy nodes</li>
<li>Actors with `max_restarts > 0` are restarted elsewhere</li>
<li>Lost objects are reconstructed via lineage if possible</li>
<li>Resource scheduling excludes the failed node</li>
</ul>

<h2>Actor Fault Tolerance</h2>

<p>Ray actors can automatically recover from failures through configurable restart policies and state management.</p>

<h3>Actor Restart Mechanisms</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Actor Fault Tolerance System"
        subgraph "Failure Detection"
            ProcessMonitor["Process Monitor<br/>Actor process health"]
            HeartbeatCheck["Heartbeat Check<br/>Periodic liveness"]
            TaskTimeout["Task Timeout<br/>Execution monitoring"]
        end
        
        subgraph "Restart Logic"
            RestartPolicy["Restart Policy<br/>max_restarts config"]
            StateRecovery["State Recovery<br/>Constructor re-execution"]
            ResourceAllocation["Resource Allocation<br/>New node placement"]
        end
        
        subgraph "Execution Semantics"
            AtMostOnce["At-Most-Once<br/>Default execution"]
            AtLeastOnce["At-Least-Once<br/>Retry enabled"]
            TaskReplay["Task Replay<br/>Failed task retry"]
        end
    end
    
    ProcessMonitor --> RestartPolicy
    HeartbeatCheck --> StateRecovery
    TaskTimeout --> ResourceAllocation
    
    RestartPolicy --> AtMostOnce
    StateRecovery --> AtLeastOnce
    ResourceAllocation --> TaskReplay
    
    style ProcessMonitor fill:#e1f5fe
    style RestartPolicy fill:#f3e5f5
    style AtMostOnce fill:#e8f5e8
        </div>
    </div>
</div>
</p>

<h3>Actor Restart Configuration</h3>

<p>From <code>doc/source/ray-core/doc_code/actor_restart.py:8-15</code>:</p>

<p>
<div class="codehilite">
<pre><code class="python">@ray.remote(max_restarts=4, max_task_retries=-1)
class FaultTolerantActor:
    def __init__(self):
        self.counter = 0
        # Actor state is reconstructed by re-running constructor
    
    def increment_and_possibly_fail(self):
        if self.counter == 10:
            os._exit(0)  # Simulate actor failure
        self.counter += 1
        return self.counter</code></pre>
</div>
</p>

<p><strong>Restart Policy Parameters:</strong></p>

<p>| Parameter | Default | Description | Effect |</p>
<p>|-----------|---------|-------------|---------|</p>
<p>| <code>max_restarts</code> | 0 | Maximum actor restarts | Controls restart attempts |</p>
<p>| <code>max_task_retries</code> | 0 | Task retry attempts | Enables at-least-once semantics |</p>
<p>| <code>max_pending_calls</code> | -1 | Queue size limit | Prevents memory overflow |</p>

<h3>Actor Lifecycle During Failures</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Client as Ray Client
    participant ActorMgr as Actor Manager
    participant Node1 as Original Node
    participant Node2 as Recovery Node
    participant Actor as Actor Instance
    
    Note over Client,Actor: Normal Operation
    
    Client->>Actor: Method call
    Actor->>Client: Return result
    
    Note over Actor: Actor Process Dies
    
    Node1->>ActorMgr: Report actor failure
    ActorMgr->>ActorMgr: Check restart policy
    ActorMgr->>Node2: Schedule actor restart
    
    Node2->>Actor: Re-run constructor
    Actor->>Node2: Actor ready
    Node2->>ActorMgr: Report restart success
    
    ActorMgr->>Client: Redirect future calls
    Client->>Actor: Resume method calls
    
    Note over Client,Actor: Actor Recovered
        </div>
    </div>
</div>
</p>

<h2>Object Fault Tolerance</h2>

<p>Ray provides automatic object recovery through lineage reconstruction and data replication.</p>

<h3>Object Recovery Architecture</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Object Fault Tolerance"
        subgraph "Failure Detection"
            ObjectLoss["Object Loss Detection<br/>Missing from store"]
            OwnerAlive["Owner Liveness Check<br/>Creator still alive"]
            LocationQuery["Location Query<br/>Find other copies"]
        end
        
        subgraph "Recovery Methods"
            CopyRecovery["Copy Recovery<br/>From other nodes"]
            LineageReconstruction["Lineage Reconstruction<br/>Re-execute task"]
            SpillRecovery["Spill Recovery<br/>From external storage"]
        end
        
        subgraph "Reconstruction Process"
            TaskResubmit["Task Resubmission<br/>Original computation"]
            DependencyRecovery["Dependency Recovery<br/>Recursive reconstruction"]
            ResultStorage["Result Storage<br/>New object creation"]
        end
    end
    
    ObjectLoss --> CopyRecovery
    OwnerAlive --> LineageReconstruction
    LocationQuery --> SpillRecovery
    
    CopyRecovery --> TaskResubmit
    LineageReconstruction --> DependencyRecovery
    SpillRecovery --> ResultStorage
    
    style ObjectLoss fill:#e1f5fe
    style CopyRecovery fill:#f3e5f5
    style TaskResubmit fill:#e8f5e8
        </div>
    </div>
</div>
</p>

<h3>Object Recovery Algorithm</h3>

<p>From <code>src/ray/core_worker/object_recovery_manager.h:70-90</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">// Object recovery algorithm steps:
bool RecoverObject(const ObjectID &object_id) {
  // 1. Check object ownership and missing status
  if (!IsObjectMissing(object_id) || !IsObjectOwned(object_id)) {
    return false;  // Cannot recover
  }
  
  // 2. Look for existing copies on other nodes
  auto locations = GetObjectLocations(object_id);
  if (!locations.empty()) {
    return PinObjectFromLocation(object_id, locations);
  }
  
  // 3. Attempt lineage reconstruction
  auto task_spec = GetCreationTaskSpec(object_id);
  if (task_spec.has_value()) {
    return ResubmitTask(task_spec.value());
  }
  
  return false;  // Object not recoverable
}</code></pre>
</div>
</p>

<h3>Object Recovery Limitations</h3>

<p><strong>Recoverable Objects:</strong></p>
<ul>
<li>Objects created by deterministic tasks</li>
<li>Objects with living owners</li>
<li>Objects with available lineage information</li>
</ul>

<p><strong>Non-Recoverable Objects:</strong></p>
<ul>
<li>Objects created by `ray.put()` (no lineage)</li>
<li>Objects with dead owners</li>
<li>Objects from non-deterministic tasks</li>
<li>Objects exceeding retry limits</li>
</ul>

<h2>Health Monitoring</h2>

<p>Ray implements comprehensive health monitoring across all cluster components.</p>

<h3>Multi-Layer Health Monitoring</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Health Monitoring Architecture"
        subgraph "Component Level"
            ProcessHealth["Process Health<br/>CPU, memory, status"]
            ServiceHealth["Service Health<br/>RPC responsiveness"]
            ResourceHealth["Resource Health<br/>Utilization monitoring"]
        end
        
        subgraph "Node Level"
            NodeHeartbeat["Node Heartbeat<br/>Periodic liveness"]
            DiskSpace["Disk Space<br/>Storage availability"]
            NetworkConnectivity["Network Connectivity<br/>Communication status"]
        end
        
        subgraph "Cluster Level"
            ClusterTopology["Cluster Topology<br/>Node membership"]
            ServiceMesh["Service Mesh<br/>Inter-service health"]
            OverallHealth["Overall Health<br/>Aggregate status"]
        end
    end
    
    ProcessHealth --> NodeHeartbeat
    ServiceHealth --> DiskSpace
    ResourceHealth --> NetworkConnectivity
    
    NodeHeartbeat --> ClusterTopology
    DiskSpace --> ServiceMesh
    NetworkConnectivity --> OverallHealth
    
    style ProcessHealth fill:#e1f5fe
    style NodeHeartbeat fill:#f3e5f5
    style ClusterTopology fill:#e8f5e8
        </div>
    </div>
</div>
</p>

<h3>Health Check Implementation</h3>

<p><strong>GCS Health Check Manager Configuration:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// Health check parameters
struct HealthCheckConfig {
  int64_t initial_delay_ms = 5000;        // Delay before first check
  int64_t timeout_ms = 10000;             // Timeout per check
  int64_t period_ms = 30000;              // Check interval
  int64_t failure_threshold = 3;          // Failures before marking dead
};

// Health check process
class HealthCheckContext {
  void StartHealthCheck() {
    auto deadline = std::chrono::steady_clock::now() + 
                   std::chrono::milliseconds(timeout_ms_);
    
    stub_->async()->Check(&context_, &request_, &response_, 
                         [this](grpc::Status status) {
      if (status.ok()) {
        ResetFailureCount();
        ScheduleNextCheck();
      } else {
        IncrementFailureCount();
        if (failure_count_ >= failure_threshold_) {
          ReportNodeFailure();
        } else {
          ScheduleNextCheck();
        }
      }
    });
  }
};</code></pre>
</div>
</p>

<h2>Recovery Mechanisms</h2>

<p>Ray implements several coordinated recovery mechanisms to handle different failure scenarios.</p>

<h3>Recovery Strategy Selection</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
flowchart TD
    FailureDetected["Failure Detected"]
    
    FailureDetected --> NodeFailure{"Node Failure?"}
    FailureDetected --> ActorFailure{"Actor Failure?"}
    FailureDetected --> ObjectLoss{"Object Loss?"}
    FailureDetected --> NetworkPartition{"Network Partition?"}
    
    NodeFailure -->|Yes| NodeRecovery["Node Recovery Process"]
    ActorFailure -->|Yes| ActorRestart["Actor Restart Process"]
    ObjectLoss -->|Yes| ObjectReconstruction["Object Reconstruction"]
    NetworkPartition -->|Yes| PartitionHandling["Partition Handling"]
    
    NodeRecovery --> TaskMigration["Migrate Running Tasks"]
    NodeRecovery --> ResourceReallocation["Reallocate Resources"]
    NodeRecovery --> ClusterRebalance["Rebalance Cluster"]
    
    ActorRestart --> CheckRestartPolicy["Check Restart Policy"]
    CheckRestartPolicy --> RestartActor["Restart on New Node"]
    CheckRestartPolicy --> FailPermanently["Fail Permanently"]
    
    ObjectReconstruction --> FindCopies["Find Existing Copies"]
    FindCopies --> ReconstructFromLineage["Reconstruct from Lineage"]
    FindCopies --> RecoverFromSpill["Recover from Spill"]
    
    style FailureDetected fill:#ff9999
    style NodeRecovery fill:#99ccff
    style ActorRestart fill:#99ff99
    style ObjectReconstruction fill:#ffcc99
        </div>
    </div>
</div>
</p>

<h3>Recovery Coordination Protocol</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Monitor as Health Monitor
    participant Detector as Failure Detector  
    participant GCS as GCS Server
    participant Recovery as Recovery Manager
    participant Storage as Persistent Storage
    
    Note over Monitor,Storage: Normal Operation
    
    Monitor->>Detector: Health check failure
    Detector->>GCS: Report node failure
    GCS->>Recovery: Trigger recovery process
    
    Recovery->>Storage: Load persistent state
    Storage-->>Recovery: Return saved state
    Recovery->>GCS: Restore service state
    
    GCS->>Monitor: Resume health monitoring
    
    Note over Monitor,Storage: Service Restored
        </div>
    </div>
</div>
0</p>

<h3>Performance Impact Analysis</h3>

<p><strong>Recovery Time Objectives:</strong></p>

<p>| Component | Detection Time | Recovery Time | Availability Target |</p>
<p>|-----------|---------------|---------------|-------------------|</p>
<p>| Node failure | 30-90 seconds | 2-5 minutes | 99.9% |</p>
<p>| Actor failure | 1-10 seconds | 5-30 seconds | 99.95% |</p>
<p>| Object loss | Near-instant | 10-60 seconds | 99.99% |</p>
<p>| GCS failure | 10-30 seconds | 30-120 seconds | 99.9% |</p>

<p><strong>Throughput Impact During Recovery:</strong></p>

<ul>
<li><strong>Node Failure</strong>: 10-30% throughput reduction during task migration</li>
<li><strong>Actor Restart</strong>: Minimal impact on other actors</li>
<li><strong>Object Reconstruction</strong>: Temporary latency increase for dependent tasks</li>
<li><strong>Network Partition</strong>: Proportional to partition size</li>
</ul>

<h2>Implementation Details</h2>

<h3>Critical Recovery Code Paths</h3>

<p><strong>Node Failure Handler:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// From GcsNodeManager::OnNodeFailure
void GcsNodeManager::OnNodeFailure(const NodeID &node_id,
                                  const StatusCallback &callback) {
  auto node = GetAliveNode(node_id);
  if (!node) return;  // Node already marked dead
  
  // Remove from alive nodes and mark as dead
  auto death_info = InferDeathInfo(node_id);
  auto dead_node = RemoveNode(node_id, death_info);
  
  // Notify all listeners (resource manager, actor manager, etc.)
  for (auto &listener : node_removed_listeners_) {
    listener(dead_node);
  }
  
  // Persist state change
  RAY_CHECK_OK(gcs_table_storage_->NodeTable().Put(
      node_id, *dead_node, callback));
}</code></pre>
</div>
</p>

<p><strong>Actor Restart Logic:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">// Actor restart decision process
bool ShouldRestartActor(const ActorID &actor_id) {
  auto actor_info = GetActorInfo(actor_id);
  if (!actor_info) return false;
  
  int current_restarts = actor_info->num_restarts();
  int max_restarts = actor_info->max_restarts();
  
  // Check restart policy
  if (max_restarts == 0) return false;           // No restarts allowed
  if (max_restarts == -1) return true;           // Infinite restarts
  return current_restarts < max_restarts;        // Within limit
}</code></pre>
</div>
</p>

<h3>Error Handling Patterns</h3>

<p><strong>Graceful Degradation Example:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">Status HandleObjectRecovery(const ObjectID &object_id) {
  // Try multiple recovery strategies in order
  if (auto status = TryPinFromOtherNodes(object_id); status.ok()) {
    return status;
  }
  
  if (auto status = TryLineageReconstruction(object_id); status.ok()) {
    return status;
  }
  
  if (auto status = TrySpillRecovery(object_id); status.ok()) {
    return status;
  }
  
  // All recovery methods failed
  return Status::ObjectLost("Object cannot be recovered");
}</code></pre>
</div>
</p>

<h2>Configuration Guidelines</h2>

<h3>Ray Cluster Configuration</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">// From ray/core/src/ray/ray_config.h
struct RayConfig {
  int64_t gcs_rpc_server_reconnect_timeout_s = 60;  // Reconnection timeout
  int64_t gcs_server_request_timeout_seconds = 10;  // Request timeout
  int64_t redis_db_connect_retries = 50;            // Redis retry attempts
  bool enable_external_redis = true;                // Use persistent Redis
};</code></pre>
</div>
</p>

<h3>Health Monitoring Configuration</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">// From ray/core/src/ray/ray_config.h
struct HealthCheckConfig {
  int64_t initial_delay_ms = 5000;        // Delay before first check
  int64_t timeout_ms = 10000;             // Timeout per check
  int64_t period_ms = 30000;              // Check interval
  int64_t failure_threshold = 3;          // Failures before marking dead
};</code></pre>
</div>
</p>

<h3>Recovery Configuration</h3>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsHealthCheckManager {
  // Health check configuration
  int64_t initial_delay_ms_;    // Delay before first check
  int64_t timeout_ms_;         // Timeout per health check
  int64_t period_ms_;          // Interval between checks  
  int64_t failure_threshold_;  // Failures before marking dead
  
  // Health check process
  void StartHealthCheck() {
    // Send gRPC health check to node
    stub_->Check(request_, &response_, [this](Status status) {
      if (status.ok()) {
        health_check_remaining_ = failure_threshold_;  // Reset counter
        ScheduleNextCheck();
      } else {
        health_check_remaining_--;
        if (health_check_remaining_ <= 0) {
          manager_->FailNode(node_id_);  // Mark node as failed
        } else {
          ScheduleNextCheck();  // Retry after delay
        }
      }
    });
  }
};</code></pre>
</div>
0</p>

<h2>Network Partition Recovery</h2>

<p>Ray handles network partitions through timeout-based detection and coordinated recovery.</p>

<h3>Partition Detection and Isolation</h3>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant Monitor as Health Monitor
    participant Detector as Failure Detector  
    participant GCS as GCS Server
    participant Recovery as Recovery Manager
    participant Storage as Persistent Storage
    
    Note over Monitor,Storage: Normal Operation
    
    Monitor->>Detector: Health check failure
    Detector->>GCS: Report node failure
    GCS->>Recovery: Trigger recovery process
    
    Recovery->>Storage: Load persistent state
    Storage-->>Recovery: Return saved state
    Recovery->>GCS: Restore service state
    
    GCS->>Monitor: Resume health monitoring
    
    Note over Monitor,Storage: Service Restored
        </div>
    </div>
</div>
1</p>

<h3>Split-Brain Prevention</h3>

<p><strong>Quorum-Based Decision Making:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsHealthCheckManager {
  // Health check configuration
  int64_t initial_delay_ms_;    // Delay before first check
  int64_t timeout_ms_;         // Timeout per health check
  int64_t period_ms_;          // Interval between checks  
  int64_t failure_threshold_;  // Failures before marking dead
  
  // Health check process
  void StartHealthCheck() {
    // Send gRPC health check to node
    stub_->Check(request_, &response_, [this](Status status) {
      if (status.ok()) {
        health_check_remaining_ = failure_threshold_;  // Reset counter
        ScheduleNextCheck();
      } else {
        health_check_remaining_--;
        if (health_check_remaining_ <= 0) {
          manager_->FailNode(node_id_);  // Mark node as failed
        } else {
          ScheduleNextCheck();  // Retry after delay
        }
      }
    });
  }
};</code></pre>
</div>
1</p>

<h2>Production Deployment Best Practices</h2>

<h3>Redis High Availability Setup</h3>

<p><strong>Redis Cluster Configuration:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsHealthCheckManager {
  // Health check configuration
  int64_t initial_delay_ms_;    // Delay before first check
  int64_t timeout_ms_;         // Timeout per health check
  int64_t period_ms_;          // Interval between checks  
  int64_t failure_threshold_;  // Failures before marking dead
  
  // Health check process
  void StartHealthCheck() {
    // Send gRPC health check to node
    stub_->Check(request_, &response_, [this](Status status) {
      if (status.ok()) {
        health_check_remaining_ = failure_threshold_;  // Reset counter
        ScheduleNextCheck();
      } else {
        health_check_remaining_--;
        if (health_check_remaining_ <= 0) {
          manager_->FailNode(node_id_);  // Mark node as failed
        } else {
          ScheduleNextCheck();  // Retry after delay
        }
      }
    });
  }
};</code></pre>
</div>
2</p>

<h3>KubeRay HA Configuration</h3>

<p><strong>RayService with GCS Fault Tolerance:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsHealthCheckManager {
  // Health check configuration
  int64_t initial_delay_ms_;    // Delay before first check
  int64_t timeout_ms_;         // Timeout per health check
  int64_t period_ms_;          // Interval between checks  
  int64_t failure_threshold_;  // Failures before marking dead
  
  // Health check process
  void StartHealthCheck() {
    // Send gRPC health check to node
    stub_->Check(request_, &response_, [this](Status status) {
      if (status.ok()) {
        health_check_remaining_ = failure_threshold_;  // Reset counter
        ScheduleNextCheck();
      } else {
        health_check_remaining_--;
        if (health_check_remaining_ <= 0) {
          manager_->FailNode(node_id_);  // Mark node as failed
        } else {
          ScheduleNextCheck();  // Retry after delay
        }
      }
    });
  }
};</code></pre>
</div>
3</p>

<h3>Health Check Configuration</h3>

<p><strong>Comprehensive Health Monitoring:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsHealthCheckManager {
  // Health check configuration
  int64_t initial_delay_ms_;    // Delay before first check
  int64_t timeout_ms_;         // Timeout per health check
  int64_t period_ms_;          // Interval between checks  
  int64_t failure_threshold_;  // Failures before marking dead
  
  // Health check process
  void StartHealthCheck() {
    // Send gRPC health check to node
    stub_->Check(request_, &response_, [this](Status status) {
      if (status.ok()) {
        health_check_remaining_ = failure_threshold_;  // Reset counter
        ScheduleNextCheck();
      } else {
        health_check_remaining_--;
        if (health_check_remaining_ <= 0) {
          manager_->FailNode(node_id_);  // Mark node as failed
        } else {
          ScheduleNextCheck();  // Retry after delay
        }
      }
    });
  }
};</code></pre>
</div>
4</p>

<h2>Testing and Validation</h2>

<h3>Chaos Engineering for HA Testing</h3>

<p><strong>Node Failure Simulation:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsHealthCheckManager {
  // Health check configuration
  int64_t initial_delay_ms_;    // Delay before first check
  int64_t timeout_ms_;         // Timeout per health check
  int64_t period_ms_;          // Interval between checks  
  int64_t failure_threshold_;  // Failures before marking dead
  
  // Health check process
  void StartHealthCheck() {
    // Send gRPC health check to node
    stub_->Check(request_, &response_, [this](Status status) {
      if (status.ok()) {
        health_check_remaining_ = failure_threshold_;  // Reset counter
        ScheduleNextCheck();
      } else {
        health_check_remaining_--;
        if (health_check_remaining_ <= 0) {
          manager_->FailNode(node_id_);  // Mark node as failed
        } else {
          ScheduleNextCheck();  // Retry after delay
        }
      }
    });
  }
};</code></pre>
</div>
5</p>

<p><strong>HA Test Suite:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsHealthCheckManager {
  // Health check configuration
  int64_t initial_delay_ms_;    // Delay before first check
  int64_t timeout_ms_;         // Timeout per health check
  int64_t period_ms_;          // Interval between checks  
  int64_t failure_threshold_;  // Failures before marking dead
  
  // Health check process
  void StartHealthCheck() {
    // Send gRPC health check to node
    stub_->Check(request_, &response_, [this](Status status) {
      if (status.ok()) {
        health_check_remaining_ = failure_threshold_;  // Reset counter
        ScheduleNextCheck();
      } else {
        health_check_remaining_--;
        if (health_check_remaining_ <= 0) {
          manager_->FailNode(node_id_);  // Mark node as failed
        } else {
          ScheduleNextCheck();  // Retry after delay
        }
      }
    });
  }
};</code></pre>
</div>
6</p>

<h3>Performance Benchmarking</h3>

<p><strong>HA Overhead Measurement:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsHealthCheckManager {
  // Health check configuration
  int64_t initial_delay_ms_;    // Delay before first check
  int64_t timeout_ms_;         // Timeout per health check
  int64_t period_ms_;          // Interval between checks  
  int64_t failure_threshold_;  // Failures before marking dead
  
  // Health check process
  void StartHealthCheck() {
    // Send gRPC health check to node
    stub_->Check(request_, &response_, [this](Status status) {
      if (status.ok()) {
        health_check_remaining_ = failure_threshold_;  // Reset counter
        ScheduleNextCheck();
      } else {
        health_check_remaining_--;
        if (health_check_remaining_ <= 0) {
          manager_->FailNode(node_id_);  // Mark node as failed
        } else {
          ScheduleNextCheck();  // Retry after delay
        }
      }
    });
  }
};</code></pre>
</div>
7</p>

<h2>Best Practices and Recommendations</h2>

<h3>Production Deployment Checklist</h3>

<p><strong>Infrastructure Setup:</strong></p>
<ul>
<li>[ ] Deploy Redis cluster with replication and persistence</li>
<li>[ ] Configure external storage for object spilling</li>
<li>[ ] Set up monitoring and alerting systems</li>
<li>[ ] Implement automated backup procedures</li>
<li>[ ] Configure network policies and firewalls</li>
</ul>

<p><strong>Ray Configuration:</strong></p>
<ul>
<li>[ ] Enable GCS fault tolerance with external Redis</li>
<li>[ ] Configure appropriate health check intervals</li>
<li>[ ] Set reasonable retry limits for tasks and actors</li>
<li>[ ] Tune memory and resource allocation</li>
<li>[ ] Enable comprehensive logging and metrics</li>
</ul>

<p><strong>Application Design:</strong></p>
<ul>
<li>[ ] Design actors with restart capabilities</li>
<li>[ ] Implement idempotent task functions</li>
<li>[ ] Avoid storing critical state only in memory</li>
<li>[ ] Use placement groups for co-location requirements</li>
<li>[ ] Handle exceptions and failures gracefully</li>
</ul>

<h3>Common Pitfalls and Solutions</h3>

<p>| Problem | Cause | Solution |</p>
<p>|---------|--------|----------|</p>
<p>| Split-brain scenarios | Network partitions | Use quorum-based decisions |</p>
<p>| Data loss after failures | No persistent storage | Enable external Redis |</p>
<p>| Long recovery times | Aggressive health checks | Tune timeout parameters |</p>
<p>| Resource leaks | Failed cleanup | Implement proper error handling |</p>
<p>| Cascading failures | Tight coupling | Design for failure isolation |</p>

<h3>Monitoring and Alerting</h3>

<p><strong>Key Metrics to Monitor:</strong></p>

<p>
<div class="codehilite">
<pre><code class="cpp">class GcsHealthCheckManager {
  // Health check configuration
  int64_t initial_delay_ms_;    // Delay before first check
  int64_t timeout_ms_;         // Timeout per health check
  int64_t period_ms_;          // Interval between checks  
  int64_t failure_threshold_;  // Failures before marking dead
  
  // Health check process
  void StartHealthCheck() {
    // Send gRPC health check to node
    stub_->Check(request_, &response_, [this](Status status) {
      if (status.ok()) {
        health_check_remaining_ = failure_threshold_;  // Reset counter
        ScheduleNextCheck();
      } else {
        health_check_remaining_--;
        if (health_check_remaining_ <= 0) {
          manager_->FailNode(node_id_);  // Mark node as failed
        } else {
          ScheduleNextCheck();  // Retry after delay
        }
      }
    });
  }
};</code></pre>
</div>
8</p>

<p>---</p>

<p><em>This comprehensive guide covers Ray's High Availability features, implementation details, and production deployment best practices. For the most current implementation details, refer to the source files in the Ray repository, particularly <code>src/ray/gcs/gcs_server/</code>, <code>src/ray/core_worker/</code>, and the fault tolerance documentation in <code>doc/source/ray-core/fault_tolerance/</code>.</em></p>

        </div>
            
        <div class="chapter" id="chapter-12">
            <h1 class="chapter-title">Chapter 12: Part IV: System Internals</h1>
            <h1>Part IV: System Internals</h1>


<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Protocol Architecture Overview](#protocol-architecture-overview)</p>
<p>3. [Wire Protocol Format](#wire-protocol-format)</p>
<p>4. [Why Not gRPC Over UDS?](#why-not-grpc-over-uds)</p>
<p>5. [Message Types and Structure](#message-types-and-structure)</p>
<p>6. [Connection Establishment](#connection-establishment)</p>
<p>7. [Communication Patterns](#communication-patterns)</p>
<p>8. [Performance Characteristics](#performance-characteristics)</p>
<p>9. [Comparison with Other Systems](#comparison-with-other-systems)</p>
<p>10. [Implementation Details](#implementation-details)</p>
<p>11. [Advantages and Trade-offs](#advantages-and-trade-offs)</p>
<p>12. [Conclusion](#conclusion)</p>

<h2>Introduction</h2>

<p>Ray uses a <strong>custom binary protocol over Unix Domain Sockets (UDS)</strong> for high-frequency, low-latency communication between workers and the local raylet. This is fundamentally different from the gRPC-over-TCP approach used for inter-node communication.</p>

<h3>Why a Custom Protocol?</h3>

<p>Ray's design prioritizes <strong>performance for the critical path</strong> - the frequent interactions between workers and their local raylet. These include:</p>
<ul>
<li>Task submission and completion notifications</li>
<li>Object dependency resolution</li>
<li>Worker lifecycle events</li>
<li>Resource allocation requests</li>
</ul>

<p>The custom protocol achieves <strong>microsecond-level latency</strong> compared to gRPC's millisecond overhead for these frequent, simple operations.</p>

<h2>Protocol Architecture Overview</h2>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Single Ray Node"
        subgraph "Application Layer"
            Worker1["Python Worker"]
            Worker2["Java Worker"] 
            Driver["Ray Driver"]
        end
        
        subgraph "Ray Core"
            Raylet["Raylet Process"]
            ObjectStore["Plasma Object Store"]
        end
        
        subgraph "Transport Layer"
            UDS1["UDS Connection 1"]
            UDS2["UDS Connection 2"]
            UDS3["UDS Connection 3"]
            PlasmaUDS["Plasma UDS"]
        end
    end
    
    Worker1 -.->|"Custom Protocol<br/>FlatBuffers + UDS"| UDS1
    Worker2 -.->|"Custom Protocol<br/>FlatBuffers + UDS"| UDS2
    Driver -.->|"Custom Protocol<br/>FlatBuffers + UDS"| UDS3
    
    UDS1 --> Raylet
    UDS2 --> Raylet
    UDS3 --> Raylet
    
    Worker1 -.->|"Plasma Protocol<br/>FlatBuffers + UDS"| PlasmaUDS
    Worker2 -.->|"Plasma Protocol<br/>FlatBuffers + UDS"| PlasmaUDS
    PlasmaUDS --> ObjectStore
    
    Raylet <--> ObjectStore
        </div>
    </div>
</div>
</p>

<h3>Key Components</h3>

<p>1. <strong>Unix Domain Sockets</strong>: IPC transport mechanism</p>
<p>2. <strong>FlatBuffers</strong>: Zero-copy serialization format</p>
<p>3. <strong>Custom Message Protocol</strong>: Ray-specific message framing</p>
<p>4. <strong>Connection Management</strong>: Per-worker persistent connections</p>

<h2>Wire Protocol Format</h2>

<p>Ray's wire protocol is elegantly simple, optimized for both performance and correctness:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Ray Message Frame"
        Cookie["Ray Cookie<br/>(8 bytes)<br/>Protocol ID"]
        Type["Message Type<br/>(8 bytes)<br/>FlatBuffer enum"]
        Length["Payload Length<br/>(8 bytes)<br/>Body size"]
        Payload["FlatBuffer Payload<br/>(variable)<br/>Serialized data"]
    end
    
    Cookie --> Type
    Type --> Length  
    Length --> Payload
    
    style Cookie fill:#e1f5fe
    style Type fill:#f3e5f5
    style Length fill:#e8f5e8
    style Payload fill:#fff3e0
        </div>
    </div>
</div>
</p>

<h3>Message Header Structure</h3>

<p>From <code>src/ray/common/client_connection.cc:217-250</code>:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">Status ServerConnection::WriteMessage(int64_t type, int64_t length, const uint8_t *message) {
  auto write_cookie = RayConfig::instance().ray_cookie();
  return WriteBuffer({
      boost::asio::buffer(&write_cookie, sizeof(write_cookie)),    // 8 bytes
      boost::asio::buffer(&type, sizeof(type)),                   // 8 bytes  
      boost::asio::buffer(&length, sizeof(length)),               // 8 bytes
      boost::asio::buffer(message, length),                       // variable
  });
}</code></pre>
</div>
</p>

<p><strong>Header Breakdown:</strong></p>
<ul>
<li><strong>Ray Cookie (8 bytes)</strong>: Protocol identifier and version check</li>
<li><strong>Message Type (8 bytes)</strong>: Identifies the FlatBuffer schema to use</li>
<li><strong>Payload Length (8 bytes)</strong>: Size of the FlatBuffer payload</li>
<li><strong>Payload (variable)</strong>: The actual FlatBuffer-serialized message</li>
</ul>

<h2>Why Not gRPC Over UDS?</h2>

<p>You correctly noted that gRPC can run over Unix Domain Sockets. Here's why Ray chose a custom approach:</p>

<h3>1. **Performance Requirements**</h3>

<p><strong>Ray's Latency Requirements:</strong></p>
<ul>
<li>Task submission: < 10 microseconds</li>
<li>Object dependency checks: < 5 microseconds</li>
<li>Worker lifecycle events: < 1 microsecond</li>
</ul>

<p><strong>gRPC Overhead (even over UDS):</strong></p>
<ul>
<li>HTTP/2 framing: ~20-50 microseconds</li>
<li>Protobuf serialization: ~10-30 microseconds</li>
<li>Connection state management: ~5-15 microseconds</li>
<li><strong>Total gRPC overhead: 35-95 microseconds</strong></li>
</ul>

<h3>2. **Message Pattern Optimization**</h3>

<p>Ray's communication patterns are very specific:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    subgraph "Ray's Message Patterns"
        Simple["90% Simple Notifications<br/>- ActorReady<br/>- TaskDone<br/>- Unblocked"]
        Medium["8% Medium Messages<br/>- TaskSubmission<br/>- ObjectRequest"]
        Complex["2% Complex Messages<br/>- Registration<br/>- Configuration"]
    end
    
    style Simple fill:#c8e6c9
    style Medium fill:#fff9c4
    style Complex fill:#ffcdd2
        </div>
    </div>
</div>
</p>

<p><strong>Ray's optimization:</strong></p>
<ul>
<li>90% of messages are tiny (< 50 bytes)</li>
<li>These only need 24-byte headers + minimal payload</li>
<li>No need for HTTP/2 features (multiplexing, flow control, etc.)</li>
</ul>

<h3>3. **Custom Requirements**</h3>

<p>Ray needs specific features that gRPC doesn't optimize for:</p>

<p><strong>Synchronous Object Dependencies:</strong></p>
<ul>
<li>Worker blocks until objects are available</li>
<li>Need immediate notification when dependencies resolve</li>
<li>gRPC's async model adds unnecessary complexity</li>
</ul>

<p><strong>Zero-Copy Object Access:</strong></p>
<ul>
<li>FlatBuffers allow direct buffer access</li>
<li>No need to deserialize into objects</li>
<li>Critical for high-frequency, small messages</li>
</ul>

<p><strong>Predictable Performance:</strong></p>
<ul>
<li>Custom protocol has deterministic behavior</li>
<li>No hidden complexity from HTTP/2 state machine</li>
<li>Easier to profile and optimize</li>
</ul>

<h2>Message Types and Structure</h2>

<p>Ray defines comprehensive message types from <code>src/ray/raylet/format/node_manager.fbs</code>:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TD
    subgraph "Worker ‚Üí Raylet Messages"
        WT1["RegisterClientRequest<br/>Worker registration"]
        WT2["SubmitTask<br/>Task submission"]  
        WT3["ActorCreationTaskDone<br/>Actor ready"]
        WT4["NotifyUnblocked<br/>Dependency resolved"]
        WT5["DisconnectClientRequest<br/>Worker shutdown"]
        WT6["FetchOrReconstruct<br/>Object request"]
        WT7["AnnounceWorkerPort<br/>gRPC port announcement"]
    end
    
    subgraph "Raylet ‚Üí Worker Messages"
        RT1["RegisterClientReply<br/>Registration response"]
        RT2["ExecuteTask<br/>Task assignment"]
        RT3["WaitReply<br/>Object availability"]
        RT4["DisconnectClientReply<br/>Shutdown acknowledgment"]
        RT5["AnnounceWorkerPortReply<br/>Port announcement ACK"]
    end
    
    WT1 -.-> RT1
    WT5 -.-> RT4
    WT7 -.-> RT5
    WT6 -.-> RT3
        </div>
    </div>
</div>
</p>

<h3>Core Message Categories</h3>

<p><strong>1. Connection Lifecycle</strong></p>
<ul>
<li>`RegisterClientRequest/Reply`: Worker registration and capabilities</li>
<li>`DisconnectClientRequest/Reply`: Graceful worker shutdown</li>
<li>`AnnounceWorkerPort/Reply`: gRPC port setup for remote communication</li>
</ul>

<p><strong>2. Task Management</strong></p>
<ul>
<li>`SubmitTask`: Submit task for execution</li>
<li>`ExecuteTask`: Assign task to worker</li>
<li>`ActorCreationTaskDone`: Actor initialization complete</li>
</ul>

<p><strong>3. Object Dependency Management</strong></p>
<ul>
<li>`FetchOrReconstruct`: Request object availability</li>
<li>`WaitRequest/Reply`: Wait for object dependencies</li>
<li>`NotifyUnblocked`: Signal dependency resolution</li>
</ul>

<h2>Connection Establishment</h2>

<p>The connection establishment follows a specific handshake protocol:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant W as Worker Process
    participant R as Raylet
    participant UDS as Unix Domain Socket
    participant P as Plasma Store
    
    Note over W,R: 1. Socket Connection Phase
    W->>UDS: Connect to raylet socket
    UDS-->>W: Connection established
    
    Note over W,R: 2. Worker Registration Phase  
    W->>R: RegisterClientRequest<br/>{worker_type, worker_id, language, ip, pid}
    R->>R: Validate and allocate resources
    R-->>W: RegisterClientReply<br/>{success, assigned_port, raylet_id}
    
    Note over W,R: 3. Port Announcement Phase
    W->>R: AnnounceWorkerPort<br/>{grpc_port}
    R->>R: Register worker for remote access
    R-->>W: AnnounceWorkerPortReply<br/>{success}
    
    Note over W,R: 4. Plasma Connection Phase
    W->>P: Connect to plasma store
    P-->>W: Plasma connection ready
    
    Note over W,R: 5. Ready State
    rect rgb(200, 255, 200)
        Note over W,R: Worker ready to receive tasks
    end
        </div>
    </div>
</div>
</p>

<h3>Registration Details</h3>

<p>From the FlatBuffer schema:</p>

<p>
<div class="codehilite">
<pre><code class="flatbuffers">table RegisterClientRequest {
  worker_type: int;           // Worker, Driver, etc.
  worker_id: string;          // Unique worker identifier  
  worker_pid: long;           // Process ID
  startup_token: long;        // Security token
  job_id: string;            // Job association
  runtime_env_hash: int;     // Environment fingerprint
  language: int;             // Python, Java, C++, etc.
  ip_address: string;        // Network address
  port: int;                 // gRPC listening port
  serialized_job_config: string; // Job configuration
}</code></pre>
</div>
</p>

<h2>Communication Patterns</h2>

<p>Ray uses different communication patterns optimized for specific use cases:</p>

<h3>1. Fire-and-Forget Pattern</h3>

<p>For non-critical notifications that don't require responses:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant W as Worker
    participant R as Raylet
    
    W->>R: ActorCreationTaskDone
    Note over W,R: No response expected
    W->>R: NotifyUnblocked
    Note over W,R: No response expected
        </div>
    </div>
</div>
</p>

<p><strong>Implementation:</strong></p>
<p>
<div class="codehilite">
<pre><code class="cpp">Status RayletClient::ActorCreationTaskDone() {
  return conn_->WriteMessage(MessageType::ActorCreationTaskDone);
}</code></pre>
</div>
</p>

<h3>2. Request-Reply Pattern</h3>

<p>For operations requiring confirmation or data return:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant W as Worker
    participant R as Raylet
    
    W->>R: WaitRequest<br/>{object_ids, timeout}
    R->>R: Check object availability
    R-->>W: WaitReply<br/>{ready_objects, remaining_objects}
        </div>
    </div>
</div>
</p>

<h3>3. Asynchronous Notification Pattern</h3>

<p>For events that may arrive at any time:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
sequenceDiagram
    participant R as Raylet
    participant W as Worker
    
    Note over R: Task becomes ready
    R->>W: ExecuteTask<br/>{task_specification}
    W->>W: Execute task
    W->>R: Task completion notification
        </div>
    </div>
</div>
</p>

<h2>Performance Characteristics</h2>

<h3>Latency Analysis</h3>

<p>Ray's custom protocol achieves significant performance advantages:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph TB
    subgraph "Latency Comparison (microseconds)"
        Custom["Ray Custom Protocol<br/>üü¢ 1-10 Œºs<br/>- Zero serialization overhead<br/>- Direct UDS access<br/>- Minimal protocol stack"]
        
        GRPC["gRPC over UDS<br/>üü° 50-200 Œºs<br/>- HTTP/2 overhead<br/>- Protobuf serialization<br/>- Complex connection state"]
        
        TCP["gRPC over TCP<br/>üî¥ 200-1000 Œºs<br/>- Network stack overhead<br/>- TCP connection management<br/>- Additional network hops"]
    end
    
    style Custom fill:#c8e6c9
    style GRPC fill:#fff9c4  
    style TCP fill:#ffcdd2
        </div>
    </div>
</div>
</p>

<h3>Throughput Characteristics</h3>

<p><strong>Message Size Efficiency:</strong></p>

<p>| Message Type | Ray Protocol | gRPC Equivalent | Savings |</p>
<p>|-------------|-------------|-----------------|---------|</p>
<p>| <code>ActorCreationTaskDone</code> | 24 bytes | ~200 bytes | 88% |</p>
<p>| <code>NotifyUnblocked</code> | 48 bytes | ~250 bytes | 81% |</p>
<p>| <code>RegisterClient</code> | ~300 bytes | ~500 bytes | 40% |</p>

<p><strong>Connection Overhead:</strong></p>

<p>| Aspect | Ray Protocol | gRPC |</p>
<p>|--------|-------------|------|</p>
<p>| Connection setup | ~100Œºs | ~2ms |</p>
<p>| Per-message overhead | 24 bytes | 50-100 bytes |</p>
<p>| Memory per connection | ~8KB | ~32KB |</p>

<h2>Comparison with Other Systems</h2>

<h3>ScyllaDB Similarity Analysis</h3>

<p>Based on the provided ScyllaDB documentation, there are interesting parallels:</p>

<p><strong>Similarities:</strong></p>
<p>1. <strong>Custom Protocol Focus</strong>: Both Ray and ScyllaDB choose custom protocols for performance-critical paths</p>
<p>2. <strong>Memory Management</strong>: Both systems carefully manage memory allocation and use semaphores for resource control</p>
<p>3. <strong>Chunked Processing</strong>: Both handle large requests by breaking them into chunks</p>

<p><strong>Key Differences:</strong></p>

<p>| Aspect | Ray | ScyllaDB |</p>
<p>|--------|-----|----------|</p>
<p>| <strong>Transport</strong> | Unix Domain Sockets | TCP/Network |</p>
<p>| <strong>Serialization</strong> | FlatBuffers | Custom binary format |</p>
<p>| <strong>Use Case</strong> | Local IPC only | Network communication |</p>
<p>| <strong>Memory Strategy</strong> | Zero-copy when possible | Pre-reservation with expansion |</p>

<h3>Ray vs. gRPC Design Philosophy</h3>

<p><strong>Ray's Approach:</strong></p>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Ray Philosophy"
        Perf["Performance First"]
        Simple["Simple Messages"]
        Local["Local-Only"]
        ZeroCopy["Zero-Copy Optimized"]
    end
    
    Perf --> Simple
    Simple --> Local  
    Local --> ZeroCopy
        </div>
    </div>
</div>
</p>

<p><strong>gRPC's Approach:</strong></p>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Ray Message Frame"
        Cookie["Ray Cookie<br/>(8 bytes)<br/>Protocol ID"]
        Type["Message Type<br/>(8 bytes)<br/>FlatBuffer enum"]
        Length["Payload Length<br/>(8 bytes)<br/>Body size"]
        Payload["FlatBuffer Payload<br/>(variable)<br/>Serialized data"]
    end
    
    Cookie --> Type
    Type --> Length  
    Length --> Payload
    
    style Cookie fill:#e1f5fe
    style Type fill:#f3e5f5
    style Length fill:#e8f5e8
    style Payload fill:#fff3e0
        </div>
    </div>
</div>
0</p>

<h2>Implementation Details</h2>

<h3>FlatBuffers Integration</h3>

<p>Ray chose FlatBuffers over Protocol Buffers for several reasons:</p>

<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Ray Message Frame"
        Cookie["Ray Cookie<br/>(8 bytes)<br/>Protocol ID"]
        Type["Message Type<br/>(8 bytes)<br/>FlatBuffer enum"]
        Length["Payload Length<br/>(8 bytes)<br/>Body size"]
        Payload["FlatBuffer Payload<br/>(variable)<br/>Serialized data"]
    end
    
    Cookie --> Type
    Type --> Length  
    Length --> Payload
    
    style Cookie fill:#e1f5fe
    style Type fill:#f3e5f5
    style Length fill:#e8f5e8
    style Payload fill:#fff3e0
        </div>
    </div>
</div>
1</p>

<h3>Connection Management</h3>

<p>Each worker maintains a persistent connection to the raylet:</p>

<p>
<div class="codehilite">
<pre><code class="cpp">class RayletConnection {
private:
  std::shared_ptr<ServerConnection> conn_;           // UDS connection
  std::mutex mutex_;                                // Thread safety
  std::mutex write_mutex_;                          // Write synchronization
  
public:
  Status WriteMessage(MessageType type, flatbuffers::FlatBufferBuilder *fbb);
  Status AtomicRequestReply(MessageType request_type, MessageType reply_type, 
                           std::vector<uint8_t> *reply, flatbuffers::FlatBufferBuilder *fbb);
};</code></pre>
</div>
</p>

<h3>Error Handling and Recovery</h3>

<p>Ray's protocol includes robust error handling:</p>

<p><strong>1. Connection-Level Errors:</strong></p>
<p>
<div class="codehilite">
<pre><code class="cpp">void RayletConnection::ShutdownIfLocalRayletDisconnected(const Status &status) {
  if (!status.ok() && IsRayletFailed(RayConfig::instance().RAYLET_PID())) {
    RAY_LOG(WARNING) << "Local raylet died. Terminating process.";
    QuickExit();  // Fast process termination
  }
}</code></pre>
</div>
</p>

<p><strong>2. Protocol-Level Validation:</strong></p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Cookie validation for message integrity
if (read_cookie != RayConfig::instance().ray_cookie()) {
  return Status::IOError("Ray cookie mismatch - protocol corruption detected");
}

// Message type validation
if (expected_type != read_type) {
  return Status::IOError("Message type mismatch - connection corrupted");
}</code></pre>
</div>
</p>

<p><strong>3. Graceful Shutdown:</strong></p>
<p>
<div class="diagram-container">
    <div class="diagram-header">
        <div>üìä</div>
        <div>Interactive Diagram</div>
    </div>
    <div style="padding: 2rem; background: white;">
        <div class="mermaid">
graph LR
    subgraph "Ray Message Frame"
        Cookie["Ray Cookie<br/>(8 bytes)<br/>Protocol ID"]
        Type["Message Type<br/>(8 bytes)<br/>FlatBuffer enum"]
        Length["Payload Length<br/>(8 bytes)<br/>Body size"]
        Payload["FlatBuffer Payload<br/>(variable)<br/>Serialized data"]
    end
    
    Cookie --> Type
    Type --> Length  
    Length --> Payload
    
    style Cookie fill:#e1f5fe
    style Type fill:#f3e5f5
    style Length fill:#e8f5e8
    style Payload fill:#fff3e0
        </div>
    </div>
</div>
2</p>

<h2>Advantages and Trade-offs</h2>

<h3>Advantages</h3>

<p><strong>1. Performance Benefits:</strong></p>
<ul>
<li><strong>Ultra-low latency</strong>: 1-10Œºs vs 50-200Œºs for gRPC</li>
<li><strong>High throughput</strong>: Minimal serialization overhead</li>
<li><strong>Zero-copy operations</strong>: Direct buffer access where possible</li>
<li><strong>Reduced memory footprint</strong>: ~8KB vs ~32KB per connection</li>
</ul>

<p><strong>2. Simplicity Benefits:</strong></p>
<ul>
<li><strong>Minimal dependencies</strong>: No complex gRPC stack</li>
<li><strong>Deterministic behavior</strong>: Simple protocol, predictable performance</li>
<li><strong>Easy debugging</strong>: Human-readable message types and simple framing</li>
</ul>

<p><strong>3. Optimization Benefits:</strong></p>
<ul>
<li><strong>Custom tuning</strong>: Protocol optimized for Ray's specific use cases</li>
<li><strong>Efficient batching</strong>: Can batch multiple small messages</li>
<li><strong>Direct integration</strong>: Tight coupling with Ray's object model</li>
</ul>

<h3>Trade-offs</h3>

<p><strong>1. Development Overhead:</strong></p>
<ul>
<li><strong>Custom protocol maintenance</strong>: Need to maintain protocol evolution</li>
<li><strong>Limited tooling</strong>: Fewer debugging tools compared to gRPC</li>
<li><strong>Documentation burden</strong>: Need to document protocol thoroughly</li>
</ul>

<p><strong>2. Feature Limitations:</strong></p>
<ul>
<li><strong>No built-in features</strong>: No automatic compression, authentication, etc.</li>
<li><strong>Local-only</strong>: Cannot be used for network communication</li>
<li><strong>Platform-specific</strong>: Unix Domain Sockets are not available on all platforms</li>
</ul>

<p><strong>3. Ecosystem Integration:</strong></p>
<ul>
<li><strong>Non-standard</strong>: Harder for external tools to integrate</li>
<li><strong>Learning curve</strong>: Developers need to understand custom protocol</li>
<li><strong>Testing complexity</strong>: Need custom testing infrastructure</li>
</ul>

<h3>When This Approach Makes Sense</h3>

<p>Ray's custom protocol is justified because:</p>

<p>1. <strong>High-frequency, low-latency requirements</strong>: Worker-raylet communication is extremely frequent</p>
<p>2. <strong>Simple message patterns</strong>: Most messages are small and follow predictable patterns</p>
<p>3. <strong>Local-only communication</strong>: No need for network features like load balancing</p>
<p>4. <strong>Performance-critical path</strong>: This communication is on the critical path for task execution</p>
<p>5. <strong>Controlled environment</strong>: Ray controls both ends of the communication</p>

<h2>Conclusion</h2>

<p>Ray's custom protocol over Unix Domain Sockets represents a <strong>performance-first design decision</strong> that prioritizes the critical path of distributed computing. The choice demonstrates that <strong>there's no one-size-fits-all solution</strong> in distributed systems design.</p>

<p><strong>Key Takeaways:</strong></p>

<p>1. <strong>When performance matters most</strong>, custom protocols can provide significant advantages over general-purpose solutions</p>

<p>2. <strong>Protocol simplicity</strong> can be a feature - Ray's 24-byte header and FlatBuffer payload are easy to understand and debug</p>

<p>3. <strong>Hybrid approaches work well</strong> - Ray uses custom protocols for local communication and gRPC for remote communication</p>

<p>4. <strong>Context matters</strong> - What works for Ray's local IPC may not work for other use cases like network communication</p>

<p>This approach is similar to ScyllaDB's philosophy of optimizing the critical path, but differs in implementation details based on the specific requirements of each system.</p>

<p>---</p>

<p><em>This analysis is based on Ray's source code, particularly files in <code>src/ray/raylet_client/</code>, <code>src/ray/common/client_connection.cc</code>, and <code>src/ray/raylet/format/node_manager.fbs</code>.</em></p>
        </div>
            
        <div class="chapter" id="chapter-13">
            <h1 class="chapter-title">Chapter 13: Part IV: System Internals</h1>
            <h1>Part IV: System Internals</h1>


<h2>Overview</h2>

<p>This document provides a comprehensive explanation of how Ray allocates and manages ports for actors and tasks. Understanding this mechanism is crucial for configuring Ray clusters properly, especially in environments with strict firewall rules or limited port availability.</p>

<h2>Key Concepts</h2>

<h3>1. **Single Port Pool Architecture**</h3>
<p>Ray uses a <strong>unified port pool</strong> managed by the <code>WorkerPool</code> class for both actors and tasks. This is not separate pools - it's one shared resource.</p>

<p><strong>Code Reference</strong>: <code>src/ray/raylet/worker_pool.h:834</code></p>
<p>
<div class="codehilite">
<pre><code class="cpp">/// Keeps track of unused ports that newly-created workers can bind on.
/// If null, workers will not be passed ports and will choose them randomly.
std::unique_ptr<std::queue<int>> free_ports_;</code></pre>
</div>
</p>

<h3>2. **Port Allocation Model**</h3>
<ul>
<li><strong>One port per worker</strong> (regardless of CPU usage)</li>
<li><strong>Both actors and tasks</strong> use the same pool</li>
<li><strong>Ports are assigned</strong> when workers register with the raylet</li>
<li><strong>Ports are returned</strong> to the pool when workers terminate</li>
</ul>

<h2>Port Pool Creation</h2>

<h3>Port Pool Initialization</h3>
<p>The port pool is created during <code>WorkerPool</code> construction with ports from either:</p>

<p>1. <strong>Port Range</strong> (min_worker_port to max_worker_port)</p>
<p>2. <strong>Explicit Port List</strong> (worker_port_list)</p>

<p><strong>Code Reference</strong>: <code>src/ray/raylet/worker_pool.cc:148-161</code></p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
</p>

<h3>Configuration Options</h3>

<h4>Method 1: Port Range</h4>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
</p>

<h4>Method 2: Explicit Port List</h4>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
</p>

<p><strong>Code Reference</strong>: <code>src/ray/raylet/main.cc:55-60</code></p>
<p>
<div class="codehilite">
<pre><code class="cpp">DEFINE_int32(min_worker_port, 0, "The lowest port that workers' gRPC servers will bind on.");
DEFINE_int32(max_worker_port, 0, "The highest port that workers' gRPC servers will bind on.");
DEFINE_string(worker_port_list, "", "An explicit list of ports that workers' gRPC servers will bind on.");</code></pre>
</div>
</p>

<h2>Port Assignment Process</h2>

<h3>Worker Registration and Port Assignment</h3>
<p>When any worker (task or actor) starts, it follows this exact process:</p>

<p><strong>Code Reference</strong>: <code>src/ray/raylet/worker_pool.cc:796-812</code></p>
<p>
<div class="codehilite">
<pre><code class="cpp">// The port that this worker's gRPC server should listen on
int port = 0;
Status status = GetNextFreePort(&port);
if (!status.ok()) {
  return PopWorkerStatus::Failed;
}
worker->SetAssignedPort(port);</code></pre>
</div>
</p>

<h3>Port Allocation Function</h3>
<p><strong>Code Reference</strong>: <code>src/ray/raylet/worker_pool.cc:683-701</code></p>
<p>
<div class="codehilite">
<pre><code class="cpp">Status WorkerPool::GetNextFreePort(int *port) {
  if (free_ports_ == nullptr || free_ports_->empty()) {
    return Status::Invalid(
        "No available ports. Please specify a wider port range using --min-worker-port and "
        "--max-worker-port.");
  }
  
  // Try up to the current number of ports.
  int current_size = free_ports_->size();
  for (int i = 0; i < current_size; i++) {
    *port = free_ports_->front();
    free_ports_->pop();
    
    if (IsPortAvailable(*port)) {
      return Status::OK();
    } else {
      // Port is occupied, try next one
      free_ports_->push(*port);
    }
  }
  
  return Status::Invalid(
      "No available ports. Please specify a wider port range using --min-worker-port and "
      "--max-worker-port.");
}</code></pre>
</div>
</p>

<h2>Actor vs Task Port Usage</h2>

<h3>Actors: Long-lived Port Dedication</h3>
<p>
<div class="codehilite">
<pre><code class="python">@ray.remote
class MyActor:
    def method(self):
        return "Hello"

actor = MyActor.remote()</code></pre>
</div>
</p>

<p><strong>Characteristics</strong>:</p>
<ul>
<li><strong>Dedicated Port</strong>: Each actor gets its own port</li>
<li><strong>Long-lived</strong>: Port is held until actor terminates/dies</li>
<li><strong>Persistent</strong>: Same port for all method calls on the actor</li>
<li><strong>gRPC Server</strong>: Actor runs a gRPC server on its assigned port</li>
</ul>

<h3>Tasks: Short-lived Port Usage</h3>
<p>
<div class="codehilite">
<pre><code class="python">@ray.remote
def my_task():
    return "Hello"

future = my_task.remote()</code></pre>
</div>
</p>

<p><strong>Characteristics</strong>:</p>
<ul>
<li><strong>Temporary Port</strong>: Task gets port from pool when worker is assigned</li>
<li><strong>Short-lived</strong>: Port returned to pool when task completes</li>
<li><strong>Worker Reuse</strong>: Same worker (and port) can execute multiple sequential tasks</li>
<li><strong>Pooled Workers</strong>: Tasks share a pool of workers</li>
</ul>

<h2>Worker Pool Size Limits</h2>

<h3>The `num_workers_soft_limit` Configuration</h3>
<p>This is the <strong>critical parameter</strong> that controls maximum port usage.</p>

<p><strong>Code Reference</strong>: <code>src/ray/raylet/node_manager.cc:130-150</code></p>
<p>
<div class="codehilite">
<pre><code class="cpp">[this, config]() {
  // Callback to determine the maximum number of idle workers to keep around.
  if (config.num_workers_soft_limit >= 0) {
    return config.num_workers_soft_limit;
  }
  // If no limit is provided, use the available number of CPUs,
  // assuming that each incoming task will likely require 1 CPU.
  return static_cast<int64_t>(
      cluster_resource_scheduler_->GetLocalResourceManager()
          .GetLocalAvailableCpus());
}</code></pre>
</div>
</p>

<p><strong>Default Behavior</strong>: <code>num_workers_soft_limit = -1</code> ‚Üí <strong>defaults to CPU count</strong></p>

<p><strong>Code Reference</strong>: <code>src/ray/common/ray_config_def.h:617-624</code></p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
0</p>

<h3>Configuration Examples</h3>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
1</p>

<h2>Port Exhaustion Scenarios</h2>

<h3>When Do You Run Out of Ports?</h3>

<h4>Scenario 1: Too Many Concurrent Actors</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
2</p>

<h4>Scenario 2: Fractional CPU Tasks</h4>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
3</p>

<h3>Error Messages</h3>
<p><strong>Code Reference</strong>: <code>src/ray/raylet/worker_pool.cc:693-701</code></p>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
4</p>

<h2>Best Practices & Solutions</h2>

<h3>1. **Calculate Required Ports**</h3>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
5</p>

<h3>2. **Configure Appropriate Port Range**</h3>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
6</p>

<h3>3. **Use Explicit Port Lists for Control**</h3>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
7</p>

<h3>4. **Monitor Port Usage**</h3>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
8</p>

<h2>Advanced Configuration Examples</h2>

<h3>Large Cluster Setup (1000 nodes)</h3>
<p>
<div class="codehilite">
<pre><code class="cpp">// Initialize free ports list with all ports in the specified range.
if (!worker_ports.empty()) {
  free_ports_ = std::make_unique<std::queue<int>>();
  for (int port : worker_ports) {
    free_ports_->push(port);
  }
} else if (min_worker_port != 0 && max_worker_port != 0) {
  free_ports_ = std::make_unique<std::queue<int>>();
  if (max_worker_port == 0) {
    max_worker_port = 65535;  // Maximum valid port number
  }
  for (int port = min_worker_port; port <= max_worker_port; port++) {
    free_ports_->push(port);
  }
}</code></pre>
</div>
9</p>

<h3>Actor-Heavy Workload</h3>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
0</p>

<h3>Mixed Workload (Actors + Tasks)</h3>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
1</p>

<h2>Port Usage Summary</h2>

<p>| Component | Port Usage | Lifetime | Pool Source |</p>
<p>|-----------|------------|----------|-------------|</p>
<p>| <strong>Actor</strong> | 1 dedicated port | Until actor dies | Worker port pool |</p>
<p>| <strong>Task</strong> | 1 temporary port | Until task completes | Worker port pool |</p>
<p>| <strong>Node Manager</strong> | 1 fixed port | Node lifetime | Fixed configuration |</p>
<p>| <strong>Object Manager</strong> | 1 fixed port | Node lifetime | Fixed configuration |</p>
<p>| <strong>GCS</strong> | 1 fixed port | Cluster lifetime | Fixed configuration |</p>
<p>| <strong>Dashboard</strong> | 1 fixed port | Node lifetime | Fixed configuration |</p>

<h2>Total Port Calculation for Ray Cluster</h2>

<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
2</p>

<h2>Common Issues and Solutions</h2>

<h3>Issue 1: Port Exhaustion with Fractional CPU Tasks</h3>
<p><strong>Problem</strong>: <code>num_workers_soft_limit</code> defaults to CPU count, but fractional CPU tasks can exceed this.</p>

<p><strong>Solution</strong>: Increase <code>num_workers_soft_limit</code> and port range:</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
3</p>

<h3>Issue 2: Firewall Restrictions</h3>
<p><strong>Problem</strong>: Need to specify exact ports for firewall rules.</p>

<p><strong>Solution</strong>: Use explicit port lists:</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
4</p>

<h3>Issue 3: Actor Port Leakage</h3>
<p><strong>Problem</strong>: Dead actors not releasing ports properly.</p>

<p><strong>Solution</strong>: Ensure proper actor cleanup:</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
5</p>

<h2>Code References Summary</h2>

<p>| Component | File | Key Functions |</p>
<p>|-----------|------|---------------|</p>
<p>| Port Pool Management | <code>src/ray/raylet/worker_pool.cc</code> | <code>GetNextFreePort()</code>, <code>PopWorker()</code> |</p>
<p>| Port Configuration | <code>src/ray/raylet/main.cc</code> | Command line flag definitions |</p>
<p>| Worker Limits | <code>src/ray/raylet/node_manager.cc</code> | <code>num_workers_soft_limit</code> logic |</p>
<p>| Port Pool Storage | <code>src/ray/raylet/worker_pool.h</code> | <code>free_ports_</code> member variable |</p>

<h2>Conclusion</h2>

<p>Ray's port allocation is straightforward but requires careful planning:</p>

<p>1. <strong>Single shared pool</strong> for all workers (actors + tasks)</p>
<p>2. <strong>One port per concurrent worker</strong></p>
<p>3. <strong>Bounded by <code>num_workers_soft_limit</code></strong> (defaults to CPU count)</p>
<p>4. <strong>Configure based on your workload</strong> (actors vs tasks, CPU requirements)</p>
<p>5. <strong>Plan for peak concurrency</strong>, not just average usage</p>

<p>Understanding this model helps you properly size your port ranges and avoid common pitfalls in production Ray deployments.</p>

<h2>Advanced Q&A: Port Management Deep Dive</h2>

<p>This section covers advanced questions about Ray's port management system that frequently arise in production environments.</p>

<h3>**Q1: What happens when a task invokes ray.get() and blocks?**</h3>

<p><strong>CPU</strong>: ‚úÖ <strong>Task RELEASES CPU</strong> when blocked on <code>ray.get()</code></p>
<p><strong>Port</strong>: ‚ùå <strong>Port is KEPT OPEN</strong> during blocking</p>

<p><strong>Detailed Explanation</strong>:</p>
<p>When a task calls <code>ray.get()</code> and blocks waiting for another task's result:</p>

<p>1. <strong>CPU Resource Management</strong>:</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
6</p>
<p>1. Task Submission:</p>
<p>Worker/Driver ‚Üí GCS (via GCS Port ~6379)</p>

<p>2. Task Scheduling:</p>
<p>GCS ‚Üí Raylet (via Node Manager Port ~10001)</p>

<p>3. Worker Assignment:</p>
<p>Raylet ‚Üí Worker (via Worker's gRPC Port from pool)</p>

<p>4. Result Return:</p>
<p>Worker ‚Üí Raylet ‚Üí GCS ‚Üí Requester</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
7cpp</p>
<p>// Node Manager Port Configuration</p>
<p>// src/ray/raylet/main.cc:48</p>
<p>DEFINE_int32(node_manager_port, -1, "The port of node manager.");</p>

<p>// GCS to Raylet Communication</p>
<p>// Tasks are assigned via gRPC calls to the Node Manager service</p>
<p>// The raylet listens on node_manager_port for task assignments</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
8</p>
<p>Task A (Port 10000) ‚Üí Direct gRPC ‚Üí Task B (Port 10001)</p>
<p>‚Üë</p>
<p>(No raylet involvement)</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --min-worker-port=10000 --max-worker-port=10100

ray.init(min_worker_port=10000, max_worker_port=10100)</code></pre>
</div>
9</p>
<p>Task A (Node 1, Port 10000) ‚Üí Raylet 1 ‚Üí Network ‚Üí Raylet 2 ‚Üí Task B (Node 2, Port 10001)</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
0cpp</p>
<p>// src/ray/raylet/worker_pool.cc:683-700</p>
<p>Status WorkerPool::GetNextFreePort(int *port) {</p>
<p>// Same pool used for ALL worker types</p>
<p>if (free_ports_->empty()) {</p>
<p>return Status::Invalid("No available ports...");</p>
<p>}</p>
<p>*port = free_ports_->front();</p>
<p>free_ports_->pop();</p>
<p>return Status::OK();</p>
<p>}</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
1</p>
<p>Max Ports = min(</p>
<p>max_worker_port - min_worker_port + 1,  // Port range size</p>
<p>num_workers_soft_limit,                 // Worker pool limit</p>
<p>System file descriptor limit            // OS limit</p>
<p>)</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
2</p>
<p>Node: 16 CPUs</p>
<p>Port Range: 10000-65535 (55,536 ports)</p>
<p>Worker Limit: Default = 16 (CPU count)</p>
<p>Actual Max: 16 ports (limited by worker pool)</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
3bash</p>
<p>ray start --num_workers_soft_limit=1000 --min-worker-port=10000 --max-worker-port=11000</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
4</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Raylet Start  ‚îÇ    ‚îÇ   WorkerPool     ‚îÇ    ‚îÇ   Port Queue    ‚îÇ</p>
<p>‚îÇ                 ‚îÇ    ‚îÇ   Constructor    ‚îÇ    ‚îÇ                 ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>‚îÇ 1. Initialize        ‚îÇ                       ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ                       ‚îÇ</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>‚îÇ                      ‚îÇ 2. Create free_ports_ ‚îÇ</p>
<p>‚îÇ                      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>‚îÇ                      ‚îÇ 3. Parse port range   ‚îÇ</p>
<p>‚îÇ                      ‚îÇ    or explicit list   ‚îÇ</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>‚îÇ                      ‚îÇ 4. Push ports to queue‚îÇ</p>
<p>‚îÇ                      ‚îÇ    (10000‚Üí10100)      ‚îÇ</p>
<p>‚îÇ                      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>‚îÇ 5. Pool Ready        ‚îÇ                       ‚îÇ</p>
<p>‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                       ‚îÇ</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>

<p>Port Range: --min-worker-port=10000 --max-worker-port=10100</p>
<p>Result: 101 ports in queue [10000, 10001, 10002, ..., 10100]</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
5</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ  Worker   ‚îÇ  ‚îÇ   Raylet    ‚îÇ  ‚îÇ WorkerPool  ‚îÇ  ‚îÇ Port Queue  ‚îÇ</p>
<p>‚îÇ Process   ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ 1. Register   ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ 2. PopWorker() ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ 3. GetNextFreePort()</p>
<p>‚îÇ               ‚îÇ                ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ 4. port=10005 ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ 5. SetAssignedPort(10005)       ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ 6. Port: 10005‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ 7. Start gRPC ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ    Server on  ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ    port 10005 ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>

<p>Result: Worker now has dedicated port 10005 for its gRPC server</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
6</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Driver/   ‚îÇ    ‚îÇ     GCS     ‚îÇ    ‚îÇ   Raylet    ‚îÇ    ‚îÇ   Worker    ‚îÇ</p>
<p>‚îÇ   Client    ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ 1. task.remote() ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ 2. Schedule Task ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ    (find node)   ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ 3. RequestWorker ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ    Lease         ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ 4. PopWorker()   ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ    (assign port) ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ 5. WorkerLease   ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ    (port info)   ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ 6. SubmitTask    ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ    (to worker)   ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ 7. Execute</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ    Task</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ 8. Task Result  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ 9. ray.get()     ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ    result        ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îÇ                  ‚îÇ</p>

<p>Ports Used:</p>
<ul>
<li>GCS Port: ~6379 (Driver ‚Üí GCS)</li>
<li>Node Manager Port: ~10001 (GCS ‚Üí Raylet)</li>
<li>Worker Port: from pool, e.g., 10005 (Task execution)</li>
</ul>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
7</p>
<p>ACTOR LIFECYCLE:</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                        Actor Lifetime                           ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ Create ‚Üí Get Port 10005 ‚Üí Keep Port ‚Üí Method Calls ‚Üí Die       ‚îÇ</p>
<p>‚îÇ   ‚Üì         ‚Üì              ‚Üì           ‚Üì             ‚Üì         ‚îÇ</p>
<p>‚îÇ Start    Dedicated      Port Held   Same Port    Return Port   ‚îÇ</p>
<p>‚îÇ          Port           Throughout   Used         to Pool      ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>

<p>TASK LIFECYCLE:</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Task A  ‚îÇ ‚îÇ   Task B  ‚îÇ ‚îÇ   Task C  ‚îÇ ‚îÇ   Task D  ‚îÇ ‚îÇ   Task E  ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇPort: 10005‚îÇ ‚îÇPort: 10005‚îÇ ‚îÇPort: 10006‚îÇ ‚îÇPort: 10005‚îÇ ‚îÇPort: 10007‚îÇ</p>
<p>‚îÇWorker: W1 ‚îÇ ‚îÇWorker: W1 ‚îÇ ‚îÇWorker: W2 ‚îÇ ‚îÇWorker: W1 ‚îÇ ‚îÇWorker: W3 ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚Üì             ‚Üì             ‚Üì             ‚Üì             ‚Üì</p>
<p>Finish        Reuse         New Port      Reuse         New Port</p>
<p>Same Worker    (W1 busy)    Same Worker   (W1,W2 busy)</p>

<p>Key Difference:</p>
<ul>
<li>Actors: 1 Actor = 1 Dedicated Port (Long-term)</li>
<li>Tasks: 1 Worker = 1 Port, Multiple Tasks Share Worker (Short-term)</li>
</ul>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
8</p>
<p>SAME NODE COMMUNICATION (Direct):</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Task A    ‚îÇ    Direct gRPC Call       ‚îÇ   Task B    ‚îÇ</p>
<p>‚îÇ (Port 10005)‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ (Port 10006)‚îÇ</p>
<p>‚îÇ   Worker 1  ‚îÇ                           ‚îÇ   Worker 2  ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚Üë                                         ‚Üë</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Same Raylet ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>

<p>Benefits: Low latency, No raylet overhead, High throughput</p>

<p>CROSS NODE COMMUNICATION (Via Raylet):</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Task A    ‚îÇ    ‚îÇ  Raylet 1   ‚îÇ    ‚îÇ  Raylet 2   ‚îÇ    ‚îÇ   Task B    ‚îÇ</p>
<p>‚îÇ (Port 10005)‚îÇ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ(Node Mgr    ‚îÇ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ(Node Mgr    ‚îÇ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ (Port 10006)‚îÇ</p>
<p>‚îÇ Node 1      ‚îÇ    ‚îÇ Port 10001) ‚îÇ    ‚îÇ Port 10001) ‚îÇ    ‚îÇ Node 2      ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>

<p>Benefits: Network routing, Load balancing, Fault tolerance</p>
<p>
<div class="codehilite">
<pre><code class="bash">ray start --worker-port-list="10000,10001,10002,10003"

ray.init(worker_port_list=[10000, 10001, 10002, 10003])</code></pre>
</div>
9</p>
<p>NORMAL OPERATION:</p>
<p>Port Pool: [10000, 10001, 10002, 10003, 10004] (5 ports available)</p>
<p>Active Workers: 2</p>
<p>Available Ports: 3</p>
<p>Status: ‚úÖ HEALTHY</p>

<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Worker 1  ‚îÇ ‚îÇ   Worker 2  ‚îÇ ‚îÇ    Pool     ‚îÇ</p>
<p>‚îÇ Port: 10000 ‚îÇ ‚îÇ Port: 10001 ‚îÇ ‚îÇ [10002,     ‚îÇ</p>
<p>‚îÇ Status: BUSY‚îÇ ‚îÇ Status: BUSY‚îÇ ‚îÇ  10003,     ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  10004]     ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>

<p>PORT EXHAUSTION:</p>
<p>Port Pool: [] (0 ports available)</p>
<p>Active Workers: 5 (all blocked on ray.get())</p>
<p>Available Ports: 0</p>
<p>Status: ‚ùå STARVED</p>

<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Worker 1  ‚îÇ ‚îÇ   Worker 2  ‚îÇ ‚îÇ   Worker 3  ‚îÇ ‚îÇ   Worker 4  ‚îÇ ‚îÇ   Worker 5  ‚îÇ</p>
<p>‚îÇ Port: 10000 ‚îÇ ‚îÇ Port: 10001 ‚îÇ ‚îÇ Port: 10002 ‚îÇ ‚îÇ Port: 10003 ‚îÇ ‚îÇ Port: 10004 ‚îÇ</p>
<p>‚îÇBLOCKED:     ‚îÇ ‚îÇBLOCKED:     ‚îÇ ‚îÇBLOCKED:     ‚îÇ ‚îÇBLOCKED:     ‚îÇ ‚îÇBLOCKED:     ‚îÇ</p>
<p>‚îÇray.get()    ‚îÇ ‚îÇray.get()    ‚îÇ ‚îÇray.get()    ‚îÇ ‚îÇray.get()    ‚îÇ ‚îÇray.get()    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>

<p>New Task Request ‚Üí ‚ùå FAIL: "No available ports"</p>
<p>
<div class="codehilite">
<pre><code class="cpp">DEFINE_int32(min_worker_port, 0, "The lowest port that workers' gRPC servers will bind on.");
DEFINE_int32(max_worker_port, 0, "The highest port that workers' gRPC servers will bind on.");
DEFINE_string(worker_port_list, "", "An explicit list of ports that workers' gRPC servers will bind on.");</code></pre>
</div>
0</p>
<p>‚îå‚îÄ START: Configure Ray Worker Ports ‚îÄ‚îê</p>
<p>‚îÇ                                     ‚îÇ</p>
<p>‚ñº                                     ‚îÇ</p>
<p>‚îå‚îÄ What's your workload? ‚îÄ‚îê                    ‚îÇ</p>
<p>‚îÇ                         ‚îÇ                    ‚îÇ</p>
<p>‚ñº                         ‚ñº                    ‚îÇ</p>
<p>‚îå‚îÄ Many Actors ‚îÄ‚îê        ‚îå‚îÄ Many Tasks ‚îÄ‚îê             ‚îÇ</p>
<p>‚îÇ (Long-lived)  ‚îÇ        ‚îÇ (Short-lived) ‚îÇ             ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ</p>
<p>‚îÇ                        ‚îÇ                     ‚îÇ</p>
<p>‚ñº                        ‚ñº                     ‚îÇ</p>
<p>‚îå‚îÄ Port Need = ‚îÄ‚îê         ‚îå‚îÄ Port Need = ‚îÄ‚îê            ‚îÇ</p>
<p>‚îÇ Actor Count   ‚îÇ         ‚îÇ Peak Concurrent‚îÇ            ‚îÇ</p>
<p>‚îÇ Example: 500  ‚îÇ         ‚îÇ Tasks: 200     ‚îÇ            ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ</p>
<p>‚îÇ                         ‚îÇ                    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Combine ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ</p>
<p>‚îÇ                                      ‚îÇ</p>
<p>‚ñº                                      ‚îÇ</p>
<p>‚îå‚îÄ Total Port Need ‚îÄ‚îê                         ‚îÇ</p>
<p>‚îÇ = 500 + 200 = 700 ‚îÇ                         ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ</p>
<p>‚îÇ                                    ‚îÇ</p>
<p>‚ñº                                    ‚îÇ</p>
<p>‚îå‚îÄ Configure num_workers_soft_limit = 700 ‚îÄ‚îê          ‚îÇ</p>
<p>‚îÇ Configure port range = 10000-10700       ‚îÇ          ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ</p>
<p>‚îÇ                                    ‚îÇ</p>
<p>‚ñº                                    ‚îÇ</p>
<p>‚îå‚îÄ RESULT: 700 concurrent workers ‚îÄ‚îê        ‚îÇ</p>
<p>‚îÇ Each with dedicated port         ‚îÇ        ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ</p>
<p>
<div class="codehilite">
<pre><code class="cpp">DEFINE_int32(min_worker_port, 0, "The lowest port that workers' gRPC servers will bind on.");
DEFINE_int32(max_worker_port, 0, "The highest port that workers' gRPC servers will bind on.");
DEFINE_string(worker_port_list, "", "An explicit list of ports that workers' gRPC servers will bind on.");</code></pre>
</div>
1</p>
<p>RAY CLUSTER PORT LAYOUT:</p>

<p>HEAD NODE:</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                        HEAD NODE                           ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ GCS Server:           Port 6379                            ‚îÇ</p>
<p>‚îÇ Dashboard:            Port 8265                            ‚îÇ</p>
<p>‚îÇ Ray Client Server:    Port 10001                          ‚îÇ</p>
<p>‚îÇ Node Manager:         Port 10002                           ‚îÇ</p>
<p>‚îÇ Object Manager:       Port 10003                           ‚îÇ</p>
<p>‚îÇ Metrics Agent:        Port 10004                           ‚îÇ</p>
<p>‚îÇ Runtime Env Agent:    Port 10005                           ‚îÇ</p>
<p>‚îÇ                                                            ‚îÇ</p>
<p>‚îÇ Worker Pool:          Ports 20000-20100 (100 ports)       ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Actor 1:          Port 20000                           ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Actor 2:          Port 20001                           ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Task Worker 1:    Port 20002                           ‚îÇ</p>
<p>‚îÇ ‚îî‚îÄ Task Worker 2:    Port 20003                           ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>

<p>WORKER NODE 1:</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                      WORKER NODE 1                         ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ Node Manager:         Port 10002                           ‚îÇ</p>
<p>‚îÇ Object Manager:       Port 10003                           ‚îÇ</p>
<p>‚îÇ Metrics Agent:        Port 10004                           ‚îÇ</p>
<p>‚îÇ Runtime Env Agent:    Port 10005                           ‚îÇ</p>
<p>‚îÇ                                                            ‚îÇ</p>
<p>‚îÇ Worker Pool:          Ports 20000-20100 (100 ports)       ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Actor 3:          Port 20000                           ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Actor 4:          Port 20001                           ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Task Worker 3:    Port 20002                           ‚îÇ</p>
<p>‚îÇ ‚îî‚îÄ Task Worker 4:    Port 20003                           ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>

<p>COMMUNICATION FLOWS:</p>
<p>Driver ‚îÄ‚îÄ(6379)‚îÄ‚îÄ‚Üí GCS ‚îÄ‚îÄ(10002)‚îÄ‚îÄ‚Üí Node Manager ‚îÄ‚îÄ(20000+)‚îÄ‚îÄ‚Üí Workers</p>
<p>‚Üë                      ‚Üì</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ Cluster State ‚îÄ‚îÄ‚îÄ‚îò</p>

<p>Worker ‚îÄ‚îÄ(20000+)‚îÄ‚îÄ‚Üí Worker (Same Node: Direct)</p>
<p>Worker ‚îÄ‚îÄ(10003)‚îÄ‚îÄ‚îÄ‚Üí Object Manager ‚îÄ‚îÄ(Network)‚îÄ‚îÄ‚Üí Object Manager ‚îÄ‚îÄ(20000+)‚îÄ‚îÄ‚Üí Worker</p>
<p>
<div class="codehilite">
<pre><code class="cpp">DEFINE_int32(min_worker_port, 0, "The lowest port that workers' gRPC servers will bind on.");
DEFINE_int32(max_worker_port, 0, "The highest port that workers' gRPC servers will bind on.");
DEFINE_string(worker_port_list, "", "An explicit list of ports that workers' gRPC servers will bind on.");</code></pre>
</div>
2</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          RAY PORT CATEGORIES                                ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ                                                                             ‚îÇ</p>
<p>‚îÇ 1. INFRASTRUCTURE PORTS (Fixed, 1 per node)                               ‚îÇ</p>
<p>‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ</p>
<p>‚îÇ    ‚îÇ ‚Ä¢ GCS Port (6379)           ‚Ä¢ Node Manager (10002)             ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ ‚Ä¢ Dashboard (8265)          ‚Ä¢ Object Manager (10003)            ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ ‚Ä¢ Metrics Agent (10004)     ‚Ä¢ Runtime Env Agent (10005)        ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ</p>
<p>‚îÇ                                                                             ‚îÇ</p>
<p>‚îÇ 2. WORKER PORTS (Dynamic, from shared pool)                               ‚îÇ</p>
<p>‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ</p>
<p>‚îÇ    ‚îÇ                    SHARED PORT POOL                             ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    [20000, 20001, 20002, 20003, ..., 20100]                   ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ                         ‚îÇ                                       ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ           ‚ñº                           ‚ñº                        ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    ‚îå‚îÄ ACTORS ‚îÄ‚îê                ‚îå‚îÄ TASKS ‚îÄ‚îê                    ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    ‚îÇ Port: 1:1 ‚îÇ                ‚îÇPort: N:1 ‚îÇ                    ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    ‚îÇ Lifetime: ‚îÇ                ‚îÇLifetime: ‚îÇ                    ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    ‚îÇ Long      ‚îÇ                ‚îÇ Short    ‚îÇ                    ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ</p>
<p>‚îÇ                                                                             ‚îÇ</p>
<p>‚îÇ 3. PORT LIMITS                                                             ‚îÇ</p>
<p>‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ</p>
<p>‚îÇ    ‚îÇ Max Concurrent Ports = min(                                     ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ   Port Range Size,           // e.g., 100                      ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ   num_workers_soft_limit,    // e.g., 50                       ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ   System FD Limit           // e.g., 1024                      ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ )                                                               ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ Result: 50 concurrent workers maximum                           ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>```</p>
<p></details></p>

<p>---</p>

<p>These Mermaid diagrams provide a modern, professional visualization of Ray's port allocation system while maintaining backward compatibility with the text-based versions. The diagrams will render beautifully in GitHub, GitLab, and most modern documentation platforms, while the collapsed text versions ensure the documentation works everywhere.</p>
        </div>
            
    </div>
    
    <div class="back-cover">
        <div>
            <h2 class="back-title">Master Ray's Internal Architecture</h2>
            <div style="font-size: 1.2rem; max-width: 800px; margin: 0 auto;">
                <p>This comprehensive guide takes you deep inside Ray's distributed computing framework, 
                revealing the sophisticated engineering that powers modern distributed applications.</p>
                
                <p style="margin-top: 2rem;">From the foundational driver system to advanced fault tolerance mechanisms, 
                you'll gain intimate knowledge of how Ray orchestrates computation across clusters 
                of machines with remarkable efficiency and reliability.</p>
                
                <div style="margin-top: 3rem; font-size: 1rem; opacity: 0.9;">
                    <strong>Advanced Distributed Computing Series</strong><br>
                    13 Chapters ‚Ä¢ Interactive Diagrams ‚Ä¢ Professional Formatting
                </div>
            </div>
        </div>
    </div>
</body>
</html>