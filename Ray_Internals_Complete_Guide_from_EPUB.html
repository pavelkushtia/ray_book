<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Ray Internals: A Comprehensive Technical Guide</title>
    <style>
        @page {
            size: A4;
            margin: 2cm;
        }
        
        body {
            font-family: 'Times New Roman', serif;
            line-height: 1.6;
            color: #000;
            font-size: 12pt;
        }
        
        h1 {
            color: #1976d2;
            font-size: 18pt;
            margin: 30pt 0 15pt 0;
            border-bottom: 2pt solid #1976d2;
            padding-bottom: 5pt;
            page-break-after: avoid;
        }
        
        h2 {
            color: #388e3c;
            font-size: 14pt;
            margin: 20pt 0 10pt 0;
            page-break-after: avoid;
        }
        
        h3 {
            color: #f57c00;
            font-size: 12pt;
            margin: 15pt 0 8pt 0;
            page-break-after: avoid;
        }
        
        h4 {
            color: #c2185b;
            font-size: 11pt;
            margin: 12pt 0 6pt 0;
            page-break-after: avoid;
        }
        
        p {
            margin: 8pt 0;
            text-align: justify;
        }
        
        pre, code {
            font-family: 'Courier New', monospace;
            background-color: #f5f5f5;
            border: 1pt solid #ddd;
            padding: 8pt;
            margin: 8pt 0;
            font-size: 9pt;
            page-break-inside: avoid;
        }
        
        code {
            padding: 2pt 4pt;
            display: inline;
        }
        
        .page-break {
            page-break-before: always;
        }
        
        .title-page {
            text-align: center;
            margin-top: 100pt;
            page-break-after: always;
        }
        
        .title-page h1 {
            font-size: 24pt;
            border: none;
            margin-bottom: 20pt;
        }
        
        .chapter-title {
            page-break-before: always;
        }
    </style>
</head>
<body>

<div class="title-page">
    <h1>Ray Internals</h1>
    <h2>A Comprehensive Technical Guide</h2>
    <p style="font-size: 14pt; color: #666; margin-top: 20pt;">
        The Complete Guide to Understanding Ray's Architecture, Implementation, and Internals
    </p>
    <p style="margin-top: 40pt; color: #888;">Generated: June 2025</p>
</div>

<h1>Ray Internals: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<p>The Complete Guide to Understanding Ray's Architecture, Implementation, and Internals</p>
<h2>üìñ Preface</h2>
<p>----------------------------------------</p>
<p>Welcome to the most comprehensive technical documentation of Ray's internal architecture and implementation. This collection of guides has been crafted to provide deep insights into how Ray works under the hood, enabling developers, researchers, and engineers to understand, modify, and extend Ray's distributed computing capabilities.</p>
<p>Ray is a powerful distributed computing framework, but its true potential can only be unlocked when you understand its internal mechanisms. This documentation bridges the gap between using Ray and truly mastering it by providing detailed explanations of its core systems, complete with code references, architectural diagrams, and practical insights.</p>
<h2>üë• Intended Audience</h2>
<p>----------------------------------------</p>
<p>This documentation is designed for:</p>
<p>‚Ä¢ üîß Ray Contributors: Developers who want to contribute to the Ray project</p>
<p>‚Ä¢ üèóÔ∏è System Architects: Engineers designing distributed systems with Ray</p>
<p>‚Ä¢ üéì Researchers: Academic researchers studying distributed computing systems</p>
<p>‚Ä¢ üíº Advanced Users: Power users who need to customize Ray for specific use cases</p>
<p>‚Ä¢ üêõ Troubleshooters: Engineers debugging complex Ray deployment issues</p>
<p>‚Ä¢ üìö Students: Computer science students learning distributed systems concepts</p>
<h3>Prerequisites</h3>
<p>‚Ä¢ Strong understanding of distributed systems concepts</p>
<p>‚Ä¢ Proficiency in Python and C++</p>
<p>‚Ä¢ Familiarity with Ray's user-facing APIs</p>
<p>‚Ä¢ Basic knowledge of system programming and networking</p>
<h2>üìö How This Book is Organized</h2>
<p>----------------------------------------</p>
<p>This documentation is structured as a progressive journey through Ray's architecture, from fundamental concepts to advanced internals. Each chapter builds upon previous knowledge while remaining self-contained enough for reference use.</p>
<p>[Diagram content removed for EPUB version]</p>
<h1>üìã Table of Contents</h1>
<p>============================================================</p>
<h2>üìñ Book Organization</h2>
<p>----------------------------------------</p>
<h3>Part I: Ray Fundamentals ‚ö°</h3>
<p>Understanding the core building blocks of the Ray ecosystem</p>
<p>‚Ä¢ Chapter 1: Ray Architecture Overview (3-4 hours)</p>
<p>‚Ä¢ System architecture and component interactions</p>
<p>‚Ä¢ Bootstrap process and initialization</p>
<p>‚Ä¢ </p>
<p>Communication patterns and protocols</p>
<p>‚Ä¢ </p>
<p>Chapter 2: The Ray Driver System (2-3 hours)</p>
<p>‚Ä¢ Driver lifecycle and initialization</p>
<p>‚Ä¢ Client-server communication mechanisms</p>
<p>‚Ä¢ </p>
<p>Ray context management and session handling</p>
<p>‚Ä¢ </p>
<p>Chapter 3: Task Lifecycle and Management (2-3 hours)</p>
<p>‚Ä¢ Task creation, submission, and execution</p>
<p>‚Ä¢ Dependency resolution and data handling</p>
<p>‚Ä¢ </p>
<p>Performance optimization patterns</p>
<p>‚Ä¢ </p>
<p>Chapter 4: Actor Lifecycle and Management (1-2 hours)</p>
<p>‚Ä¢ Actor creation and state management</p>
<p>‚Ä¢ Method invocation and result handling</p>
<p>‚Ä¢ </p>
<p>Actor placement and resource allocation</p>
<p>‚Ä¢ </p>
<p>Chapter 5: Memory and Object Reference System (1-2 hours)</p>
<p>‚Ä¢ Object storage and reference management</p>
<p>‚Ä¢ Memory optimization and garbage collection</p>
<p>‚Ä¢ Distributed object handling</p>
<h3>Part II: Core Ray Services üèóÔ∏è</h3>
<p>Deep dive into the essential Ray system services</p>
<p>‚Ä¢ Chapter 6: Global Control Service (GCS) (2-3 hours)</p>
<p>‚Ä¢ Cluster metadata and coordination</p>
<p>‚Ä¢ Service discovery and health monitoring</p>
<p>‚Ä¢ </p>
<p>Actor and placement group scheduling</p>
<p>‚Ä¢ </p>
<p>Chapter 7: Raylet Implementation and Lifecycle (4-5 hours)</p>
<p>‚Ä¢ Node-level task scheduling and resource management</p>
<p>‚Ä¢ Worker process lifecycle management</p>
<p>‚Ä¢ </p>
<p>Communication mechanisms and load handling</p>
<p>‚Ä¢ </p>
<p>Chapter 8: Distributed Object Store (2-3 hours)</p>
<p>‚Ä¢ Plasma store integration and object management</p>
<p>‚Ä¢ Data transfer and locality optimization</p>
<p>‚Ä¢ Memory management and spilling strategies</p>
<h3>Part III: Advanced Ray Systems üöÄ</h3>
<p>Sophisticated scheduling and scaling mechanisms</p>
<p>‚Ä¢ Chapter 9: Distributed Scheduling Implementation (3-4 hours)</p>
<p>‚Ä¢ Multi-level scheduling architecture</p>
<p>‚Ä¢ Resource allocation algorithms</p>
<p>‚Ä¢ </p>
<p>Placement strategies and locality optimization</p>
<p>‚Ä¢ </p>
<p>Chapter 10: Autoscaling System (2-3 hours)</p>
<p>‚Ä¢ Demand-driven scaling algorithms</p>
<p>‚Ä¢ Node provisioning and resource management</p>
<p>‚Ä¢ </p>
<p>Integration with cloud providers</p>
<p>‚Ä¢ </p>
<p>Chapter 11: High Availability and Fault Tolerance (2-3 hours)</p>
<p>‚Ä¢ GCS fault tolerance and recovery mechanisms</p>
<p>‚Ä¢ Distributed system resilience patterns</p>
<p>‚Ä¢ Failure detection and handling strategies</p>
<h3>Part IV: System Internals üîß</h3>
<p>Low-level implementation details and networking</p>
<p>‚Ä¢ Chapter 12: Network Communication and Protocols (1-2 hours)</p>
<p>‚Ä¢ Custom protocol implementation</p>
<p>‚Ä¢ gRPC integration and message handling</p>
<p>‚Ä¢ </p>
<p>Performance optimization techniques</p>
<p>‚Ä¢ </p>
<p>Chapter 13: Port Assignment and Management (2-3 hours)</p>
<p>‚Ä¢ Dynamic port allocation strategies</p>
<p>‚Ä¢ Service discovery and networking</p>
<p>‚Ä¢ Cluster communication patterns</p>
<h2>üìö Appendices</h2>
<p>----------------------------------------</p>
<h3>Appendix A: Code Navigation Guide</h3>
<p>How to navigate the Ray codebase effectively</p>
<p>Key Directories:</p>
- <code>src/ray/core_worker/</code> - CoreWorker implementation
- <code>src/ray/raylet/</code> - Raylet implementation
- <code>src/ray/gcs/</code> - Global Control Service
- <code>src/ray/object_store/</code> - Object store integration
- <code>python/ray/</code> - Python API implementation
<p>Important Files:</p>
- <code>src/ray/raylet/main.cc</code> - Raylet entry point
- <code>src/ray/core_worker/core_worker.cc</code> - Core worker implementation
- <code>src/ray/gcs/gcs_server/gcs_server.cc</code> - GCS server implementation
<h3>Appendix B: Troubleshooting Reference</h3>
<p>Common issues and debugging techniques</p>
<p>Debugging Tools:</p>
- <code>ray status</code> - Cluster state overview
- <code>ray logs</code> - Component logs access
- <code>ray memory</code> - Memory usage analysis
<p>- Ray Dashboard - Web-based monitoring</p>
<p>Common Issues:</p>
<p>- Task scheduling problems</p>
<p>- Object store memory issues</p>
<p>- Network connectivity problems</p>
<p>- Actor lifecycle issues</p>
<h3>Appendix C: Performance Optimization</h3>
<p>Best practices for optimal Ray performance</p>
<p>Performance Guidelines:</p>
<p>- Task granularity optimization</p>
<p>- Memory management best practices</p>
<p>- Resource specification guidelines</p>
<p>- Network optimization techniques</p>
<h3>Appendix D: Additional Resources</h3>
<p>Official Resources:</p>
<p>- Ray Documentation</p>
<p>- Ray GitHub Repository</p>
<p>- Ray Community Forum</p>
<p>Research Papers:</p>
<p>- Ray: A Distributed Framework for Emerging AI Applications</p>
<p>- Ray whitepaper and related publications</p>
<p>Development Resources:</p>
<p>- Ray contribution guidelines</p>
<p>- Development environment setup</p>
<p>- Testing frameworks and procedures</p>
<h2>üöÄ Getting Started</h2>
<p>----------------------------------------</p>
<h3>For New Readers</h3>
<p>‚Ä¢ Start with Part I if you're new to Ray internals</p>
<p>‚Ä¢ Read Chapter 1 for the big picture</p>
<p>‚Ä¢ Follow the learning path through each part sequentially</p>
<h3>For Specific Topics</h3>
<p>‚Ä¢ Debugging Issues: Jump to relevant chapters + Appendix B</p>
<p>‚Ä¢ Performance Tuning: Focus on optimization sections + Appendix C</p>
<p>‚Ä¢ Contributing Code: Review relevant chapters + Appendix A</p>
<h3>For Reference Use</h3>
<p>‚Ä¢ Use the detailed table of contents to find specific topics</p>
<p>‚Ä¢ Each chapter is designed to be self-contained</p>
<p>‚Ä¢ Cross-references guide you to related information</p>
<h2>üìñ Reading Recommendations</h2>
<p>----------------------------------------</p>
<p>üìö Complete Reading Path (8-12 hours total)</p>
<p>Follow Parts I ‚Üí II ‚Üí III ‚Üí IV sequentially for comprehensive understanding</p>
<p>üéØ Focused Learning Paths</p>
<p>For Ray Contributors:</p>
<p>- Chapter 2 (Driver) ‚Üí Chapter 7 (Raylet) ‚Üí Chapter 6 (GCS) ‚Üí Appendix A</p>
<p>For System Architects:</p>
<p>- Chapter 1 (Overview) ‚Üí Chapter 9 (Scheduling) ‚Üí Chapter 10 (Autoscaling) ‚Üí Chapter 11 (HA)</p>
<p>For Performance Engineers:</p>
<p>- Chapter 5 (Memory) ‚Üí Chapter 8 (Object Store) ‚Üí Chapter 9 (Scheduling) ‚Üí Appendix C</p>
<p>For Distributed Systems Students:</p>
<p>- Chapter 1 (Overview) ‚Üí Chapter 6 (GCS) ‚Üí Chapter 7 (Raylet) ‚Üí Chapter 11 (Fault Tolerance)</p>
<p>Happy Learning! üéì</p>
<p>Last Updated: December 2024</p>
<p>Total Reading Time: 8-12 hours</p>
<p>Difficulty Level: Advanced</p>
<p>Prerequisites: Distributed systems knowledge, Python/C++ proficiency</p>

<div class="page-break"></div>
<h1>Part I: Ray Fundamentals</h1>
<p>============================================================</p>
<h1>Chapter 1: Ray Architecture Overview</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Ray Cluster Architecture</p>
<p>‚Ä¢ Core Components Overview</p>
<p>‚Ä¢ Scheduling Architecture</p>
<p>‚Ä¢ Communication Patterns</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Process Architecture</p>
<p>‚Ä¢ Component Interactions</p>
<p>‚Ä¢ System Bootstrap</p>
<p>‚Ä¢ Configuration System</p>
<p>‚Ä¢ Performance Characteristics</p>
<p>‚Ä¢ Fault Tolerance Overview</p>
<p>‚Ä¢ Development and Testing</p>
<p>‚Ä¢ Best Practices</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>Ray is a distributed computing framework designed for machine learning and AI workloads. This chapter provides a comprehensive overview of Ray's architecture, covering the fundamental components, their interactions, and the overall system design that enables scalable distributed computing.</p>
<h3>What is Ray?</h3>
<p>Ray is an open-source unified framework for scaling AI workloads. It provides:</p>
<p>- Distributed Computing: Scale Python workloads across multiple machines</p>
<p>- Unified API: Single interface for tasks, actors, and data processing</p>
<p>- Fault Tolerance: Built-in error handling and recovery mechanisms</p>
<p>- Resource Management: Efficient allocation of CPU, GPU, and memory resources</p>
<p>- Ecosystem: Libraries for ML (Ray Train), reinforcement learning (Ray RLlib), hyperparameter tuning (Ray Tune), and more</p>
<h3>Key Features</h3>
<p>‚Ä¢ Multi-level Scheduling: Task-level, actor-level, and placement group scheduling</p>
<p>‚Ä¢ Resource-Aware: CPU, GPU, memory, and custom resource scheduling</p>
<p>‚Ä¢ Placement Strategies: PACK, SPREAD, STRICT_PACK, STRICT_SPREAD</p>
<p>‚Ä¢ Locality Optimization: Data locality-aware task placement</p>
<p>‚Ä¢ Dynamic Scaling: Integration with autoscaler for cluster growth/shrinkage</p>
<p>‚Ä¢ Label-Based Scheduling: Node affinity and label constraints</p>
<p>‚Ä¢ Performance Optimization: Efficient algorithms for large-scale clusters</p>
<h3>Scheduling Hierarchy</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Scheduling Architecture Overview</h2>
<p>----------------------------------------</p>
<h3>Multi-Level Scheduling Architecture</h3>
<p>Ray implements a hierarchical scheduling architecture with multiple decision points:</p>
<h4>1. Client-Side Scheduling</h4>
<p>[Diagram content removed for EPUB version]</p>
Location: <code>src/ray/core_worker/lease_policy.cc</code>
<p>The client-side scheduling makes initial placement decisions based on:</p>
<p>- Data locality (object location)</p>
<p>- Scheduling strategies (spread, node affinity)</p>
<p>- Resource requirements</p>
<h4>2. Raylet-Level Scheduling</h4>
<p>[Diagram content removed for EPUB version]</p>
Location: <code>src/ray/raylet/scheduling/cluster_task_manager.cc</code>
<h4>3. GCS-Level Scheduling</h4>
<p>[Diagram content removed for EPUB version]</p>
Location: <code>src/ray/gcs/gcs_server/gcs_actor_scheduler.cc</code>
<h3>Core Scheduling Flow</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Core Scheduling Components</h2>
<p>----------------------------------------</p>
<h3>ClusterResourceScheduler</h3>
Location: <code>src/ray/raylet/scheduling/cluster_resource_scheduler.h</code>
<p>The central coordinator for cluster-wide resource scheduling decisions.</p>
<code>class ClusterResourceScheduler {
<p>// Core scheduling method</p>
<p>scheduling::NodeID GetBestSchedulableNode(</p>
<p>const ResourceRequest &amp;resource_request,</p>
<p>const rpc::SchedulingStrategy &amp;scheduling_strategy,</p>
<p>bool actor_creation,</p>
<p>bool force_spillback,</p>
<p>const std::string &amp;preferred_node_id,</p>
<p>int64_t *total_violations,</p>
<p>bool *is_infeasible);</p>
<p>// Bundle scheduling for placement groups</p>
<p>SchedulingResult Schedule(</p>
<p>const std::vector&lt;const ResourceRequest *&gt; &amp;resource_request_list,</p>
<p>SchedulingOptions options);</p>
<p>}</p>
<p></code></p>
<p>Key Responsibilities:</p>
<p>- Node feasibility checking</p>
<p>- Resource availability tracking</p>
<p>- Scheduling strategy implementation</p>
<p>- Placement group bundle scheduling</p>
<h3>ClusterTaskManager</h3>
Location: <code>src/ray/raylet/scheduling/cluster_task_manager.h</code>
<p>Manages task queuing and scheduling at the cluster level.</p>
<code>class ClusterTaskManager {
<p>void QueueAndScheduleTask(</p>
<p>RayTask task,</p>
<p>bool grant_or_reject,</p>
<p>bool is_selected_based_on_locality,</p>
<p>rpc::RequestWorkerLeaseReply *reply,</p>
<p>rpc::SendReplyCallback send_reply_callback);</p>
<p>void ScheduleAndDispatchTasks();</p>
<p>}</p>
<p></code></p>
<p>Scheduling Queues:</p>
- <code>tasks_to_schedule_</code>: Tasks waiting for resources
- <code>infeasible_tasks_</code>: Tasks that cannot be scheduled
<h3>LocalTaskManager</h3>
Location: <code>src/ray/raylet/local_task_manager.h</code>
<p>Handles local task execution and worker management.</p>
<code>class LocalTaskManager {
<p>void QueueAndScheduleTask(std::shared_ptr&lt;internal::Work&gt; work);</p>
<p>void ScheduleAndDispatchTasks();</p>
<p>bool TrySpillback(const std::shared_ptr&lt;internal::Work&gt; &amp;work,</p>
<p>bool &amp;is_infeasible);</p>
<p>}</p>
<p></code></p>
<p>Fairness Policy: Implements CPU-fair scheduling to prevent resource starvation:</p>
<code>// From src/ray/raylet/local_task_manager.cc
<p>if (total_cpu_requests_ &gt; total_cpus) {</p>
<p>RAY_LOG(DEBUG) &lt;&lt; &quot;Applying fairness policy. Total CPU requests (&quot;</p>
<p>&lt;&lt; total_cpu_requests_ &lt;&lt; &quot;) exceed total CPUs (&quot; </p>
<p>&lt;&lt; total_cpus &lt;&lt; &quot;)&quot;;</p>
<p>// Apply fair dispatching logic</p>
<p>}</p>
<p></code></p>
<h3>Scheduling Policies</h3>
Location: <code>src/ray/raylet/scheduling/policy/</code>
<p>Ray implements multiple scheduling policies:</p>
<h4>HybridSchedulingPolicy</h4>
<p>‚Ä¢ Default scheduling strategy</p>
<p>‚Ä¢ Balances locality and load distribution</p>
<p>‚Ä¢ Configurable spread threshold</p>
<h4>SpreadSchedulingPolicy</h4>
<p>‚Ä¢ Distributes tasks across nodes</p>
<p>‚Ä¢ Minimizes resource contention</p>
<p>‚Ä¢ Used for embarrassingly parallel workloads</p>
<h4>NodeAffinitySchedulingPolicy</h4>
<p>‚Ä¢ Hard/soft node constraints</p>
<p>‚Ä¢ Supports spillback on unavailability</p>
<p>‚Ä¢ Critical for stateful workloads</p>
<h4>NodeLabelSchedulingPolicy</h4>
<code>class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
<p>scheduling::NodeID Schedule(const ResourceRequest &amp;resource_request,</p>
<p>SchedulingOptions options) override;</p>
<p>private:</p>
<p>bool IsNodeMatchLabelExpression(const Node &amp;node,</p>
<p>const rpc::LabelMatchExpression &amp;expression);</p>
<p>};</p>
<p></code></p>
<h3>Scheduling Context and Options</h3>
Location: <code>src/ray/raylet/scheduling/policy/scheduling_options.h</code>
<code>struct SchedulingOptions {
<p>SchedulingType scheduling_type;</p>
<p>float spread_threshold;</p>
<p>bool avoid_local_node;</p>
<p>bool require_node_available;</p>
<p>bool avoid_gpu_nodes;</p>
<p>double max_cpu_fraction_per_node; // For placement groups</p>
<p>static SchedulingOptions Hybrid(bool avoid_local_node,</p>
<p>bool require_node_available,</p>
<p>const std::string &amp;preferred_node_id);</p>
<p>static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);</p>
<p>static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);</p>
<p>};</p>
<p></code></p>
<h2>Resource Management and Allocation</h2>
<p>----------------------------------------</p>
<h3>Resource Model</h3>
<p>Ray uses a multi-dimensional resource model:</p>
<code>// Resource types from src/ray/common/scheduling/scheduling_ids.h
<p>enum PredefinedResources {</p>
<p>CPU = 0,</p>
<p>MEM = 1,</p>
<p>GPU = 2,</p>
<p>OBJECT_STORE_MEM = 3,</p>
<p>// Custom resources start from 4</p>
<p>};</p>
<p></code></p>
<h3>Resource Request Structure</h3>
<pre><code><code>class ResourceRequest {
ResourceSet resource_set_;           // Required resources
LabelSelector label_selector_;       // Node label requirements
bool requires_object_store_memory_;  // Memory constraint flag
bool IsEmpty() const;
const ResourceSet &amp;GetResourceSet() const;
bool RequiresObjectStoreMemory() const;
};
</code></code></pre>
<h3>NodeResources</h3>
Location: <code>src/ray/common/scheduling/cluster_resource_data.h</code>
<code>struct NodeResources {
<p>NodeResourceSet total;      // Total node capacity</p>
<p>NodeResourceSet available; // Currently available</p>
<p>NodeResourceSet normal_task_resources; // Reserved for tasks</p>
<p>absl::flat_hash_map&lt;std::string, std::string&gt; labels; // Node labels</p>
<p>bool object_pulls_queued;   // Object store status</p>
<p>bool IsAvailable(const ResourceRequest &amp;resource_request) const;</p>
<p>bool IsFeasible(const ResourceRequest &amp;resource_request) const;</p>
<p>bool HasRequiredLabels(const LabelSelector &amp;label_selector) const;</p>
<p>float CalculateCriticalResourceUtilization() const;</p>
<p>};</p>
<p></code></p>
<h3>Resource Allocation Algorithm</h3>
<pre><code><code>bool ClusterResourceScheduler::IsSchedulable(
const ResourceRequest &amp;resource_request,
scheduling::NodeID node_id) const {
return cluster_resource_manager_-&gt;HasAvailableResources(
node_id,
resource_request,
/*ignore_object_store_memory_requirement*/ 
node_id == local_node_id_) &amp;&amp;
NodeAvailable(node_id);
}
</code></code></pre>
<h3>Dynamic Resource Management</h3>
<pre><code><code>// From src/ray/raylet/scheduling/cluster_resource_scheduler_test.cc
TEST_F(ClusterResourceSchedulerTest, DynamicResourceTest) {
// Add dynamic resources at runtime
resource_scheduler.GetLocalResourceManager().AddLocalResourceInstances(
scheduling::ResourceID(&quot;custom123&quot;), {0., 1.0, 1.0});
// Verify schedulability
auto result = resource_scheduler.GetBestSchedulableNode(resource_request, ...);
ASSERT_FALSE(result.IsNil());
}
</code></code></pre>
<h3>Resource Binpacking</h3>
<p>Ray implements sophisticated binpacking for resource allocation:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Task Scheduling Algorithms</h2>
<p>----------------------------------------</p>
<h3>Hybrid Scheduling Algorithm</h3>
<p>Default Strategy: Balances locality and load distribution</p>
<code>// Configuration from src/ray/raylet/scheduling/cluster_resource_scheduler.cc
<p>best_node_id = scheduling_policy_-&gt;Schedule(</p>
<p>resource_request,</p>
<p>SchedulingOptions::Hybrid(</p>
<p>/*avoid_local_node*/ force_spillback,</p>
<p>/*require_node_available*/ force_spillback,</p>
<p>preferred_node_id));</p>
<p></code></p>
<p>Algorithm Steps:</p>
<p>1. Score Calculation: Based on resource utilization</p>
<p>2. Top-K Selection: Choose from best k nodes (default: 20% of cluster)</p>
<p>3. Random Selection: Within top-k for load balancing</p>
<p>Scoring Function:</p>
<code>float NodeResources::CalculateCriticalResourceUtilization() const {
<p>float highest = 0;</p>
<p>for (const auto &amp;i : {CPU, MEM, OBJECT_STORE_MEM}) {</p>
<p>float utilization = 1 - (available / total);</p>
<p>if (utilization &gt; highest) {</p>
<p>highest = utilization;</p>
<p>}</p>
<p>}</p>
<p>return highest;</p>
<p>}</p>
<p></code></p>
<h3>Spread Scheduling Algorithm</h3>
<p>Purpose: Distribute tasks across maximum number of nodes</p>
<code>// From scheduling policy tests
<p>TEST_F(SchedulingPolicyTest, SpreadSchedulingStrategyTest) {</p>
<p>rpc::SchedulingStrategy scheduling_strategy;</p>
<p>scheduling_strategy.mutable_spread_scheduling_strategy();</p>
<p>auto node_id = resource_scheduler.GetBestSchedulableNode(</p>
<p>resource_request, LabelSelector(), scheduling_strategy, ...);</p>
<p>}</p>
<p></code></p>
<p>Implementation:</p>
<p>- Prioritizes nodes with lowest task count</p>
<p>- Avoids resource hotspots</p>
<p>- Maximizes fault tolerance</p>
<h3>Node Affinity Scheduling</h3>
<p>Hard Affinity: Must run on specific node</p>
<code>if (IsHardNodeAffinitySchedulingStrategy(scheduling_strategy)) {
<p>// Must schedule on specified node or fail</p>
<p>best_node_id = scheduling_policy_-&gt;Schedule(</p>
<p>resource_request,</p>
<p>SchedulingOptions::NodeAffinity(</p>
<p>force_spillback, force_spillback,</p>
<p>scheduling_strategy.node_affinity_scheduling_strategy().node_id(),</p>
<p>/*soft=*/false, /*spill_on_unavailable=*/false,</p>
<p>/*fail_on_unavailable=*/true));</p>
<p>}</p>
<p></code></p>
<p>Soft Affinity: Prefer specific node but allow spillback</p>
<code>scheduling_strategy.mutable_node_affinity_scheduling_strategy()-&gt;set_soft(true);
<p>// Will try preferred node first, then other nodes</p>
<p></code></p>
<h3>Fair Scheduling</h3>
<p>CPU Fair Scheduling: Prevents starvation across scheduling classes</p>
<code>// From src/ray/raylet/local_task_manager.cc
<p>if (total_cpu_requests_ &gt; total_cpus) {</p>
<p>// Calculate fair share per scheduling class</p>
<p>double fair_share = total_cpus / num_classes_with_cpu;</p>
<p>// Apply throttling based on fair share</p>
<p>for (auto &amp;[scheduling_class, dispatch_queue] : tasks_to_dispatch_) {</p>
<p>double cpu_request = /* CPU required by this class */;</p>
<p>if (cpu_request &gt; fair_share) {</p>
<p>// Throttle this class</p>
<p>next_update_time = current_time + throttle_delay;</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h2>Actor Placement and Scheduling</h2>
<p>----------------------------------------</p>
<h3>Actor Scheduling Architecture</h3>
Location: <code>src/ray/gcs/gcs_server/gcs_actor_scheduler.cc</code>
<p>Ray provides two actor scheduling modes:</p>
<h4>1. GCS-Based Actor Scheduling</h4>
<code>void GcsActorScheduler::ScheduleByGcs(std::shared_ptr&lt;GcsActor&gt; actor) {
<p>// Create task for actor creation</p>
<p>auto task = std::make_shared&lt;RayTask&gt;(actor-&gt;GetCreationTaskSpecification());</p>
<p>// Use cluster task manager for scheduling</p>
<p>cluster_task_manager_.QueueAndScheduleTask(</p>
<p>std::move(task),</p>
<p>/*grant_or_reject*/ false,</p>
<p>/*is_selected_based_on_locality*/ false,</p>
<p>reply.get(),</p>
<p>send_reply_callback);</p>
<p>}</p>
<p></code></p>
<h4>2. Raylet-Based Actor Scheduling</h4>
<pre><code><code>void GcsActorScheduler::ScheduleByRaylet(std::shared_ptr&lt;GcsActor&gt; actor) {
// Select forwarding node
auto node_id = SelectForwardingNode(actor);
// Lease worker directly from node
LeaseWorkerFromNode(actor, node.value());
}
</code></code></pre>
<h3>Actor Resource Requirements</h3>
<p>Placement vs Execution Resources:</p>
<code>// From src/ray/common/task/task_spec.cc
<p>const auto &amp;resource_set = </p>
<p>(is_actor_creation_task &amp;&amp; should_report_placement_resources)</p>
<p>? GetRequiredPlacementResources()  // For scheduling decisions</p>
<p>: GetRequiredResources();          // For execution</p>
<p></code></p>
<p>Actor Creation Example:</p>
<code>@ray.remote(num_cpus=2, num_gpus=1, memory=1000)
<p>class MyActor:</p>
<p>def __init__(self):</p>
<p>pass</p>
<p>def method(self):</p>
<p>pass</p>
<h1>Actor placement considers both creation and method resources</h1>
<p>actor = MyActor.remote()</p>
<p></code></p>
<h3>Actor Lifecycle and Scheduling</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Actor Scheduling Considerations</h3>
<p>Resource Lifetime: Actors hold resources for their entire lifetime</p>
<code>if (task_spec.IsActorCreationTask()) {
<p>// The actor belongs to this worker now</p>
<p>worker-&gt;SetLifetimeAllocatedInstances(allocated_instances);</p>
<p>} else {</p>
<p>worker-&gt;SetAllocatedInstances(allocated_instances);</p>
<p>}</p>
<p></code></p>
<p>Scheduling Class: Actors use placement resources for scheduling decisions</p>
<code>TEST(TaskSpecTest, TestActorSchedulingClass) {
<p>// Actor's scheduling class determined by placement resources</p>
<p>TaskSpecification actor_task(actor_task_spec_proto);</p>
<p>TaskSpecification regular_task(regular_task_spec_proto);</p>
<p>ASSERT_EQ(regular_task.GetSchedulingClass(), actor_task.GetSchedulingClass());</p>
<p>}</p>
<p></code></p>
<h2>Placement Group Scheduling</h2>
<p>----------------------------------------</p>
<h3>Placement Group Architecture</h3>
Location: <code>src/ray/gcs/gcs_server/gcs_placement_group_scheduler.cc</code>
<p>Placement groups enable gang scheduling of related resources across multiple nodes.</p>
<code>class GcsPlacementGroupScheduler {
<p>void SchedulePlacementGroup(</p>
<p>std::shared_ptr&lt;GcsPlacementGroup&gt; placement_group,</p>
<p>PGSchedulingFailureCallback failure_callback,</p>
<p>PGSchedulingSuccessfulCallback success_callback);</p>
<p>}</p>
<p></code></p>
<h3>Bundle Specification</h3>
Location: <code>src/ray/common/bundle_spec.h</code>
<code>class BundleSpecification {
<p>BundleID BundleId() const;</p>
<p>PlacementGroupID PlacementGroupId() const;</p>
<p>NodeID NodeId() const;</p>
<p>int64_t Index() const;</p>
<p>const ResourceRequest &amp;GetRequiredResources() const;</p>
<p>const absl::flat_hash_map&lt;std::string, double&gt; &amp;GetFormattedResources() const;</p>
<p>};</p>
<p></code></p>
<h3>Placement Strategies</h3>
<h4>PACK Strategy</h4>
<pre><code><code>case rpc::PlacementStrategy::PACK:
return SchedulingOptions::BundlePack(max_cpu_fraction_per_node);
</code></code></pre>
<p>‚Ä¢ Goal: Minimize number of nodes used</p>
<p>‚Ä¢ Use Case: Maximize locality, minimize network overhead</p>
<p>‚Ä¢ Algorithm: First-fit decreasing binpacking</p>
<h4>SPREAD Strategy</h4>
<pre><code><code>case rpc::PlacementStrategy::SPREAD:
return SchedulingOptions::BundleSpread(max_cpu_fraction_per_node);
</code></code></pre>
<p>‚Ä¢ Goal: Distribute bundles across nodes</p>
<p>‚Ä¢ Use Case: Fault tolerance, load distribution</p>
<p>‚Ä¢ Algorithm: Round-robin placement with load balancing</p>
<h4>STRICT_PACK Strategy</h4>
<pre><code><code>case rpc::PlacementStrategy::STRICT_PACK:
return SchedulingOptions::BundleStrictPack(
max_cpu_fraction_per_node,
soft_target_node_id);
</code></code></pre>
<p>‚Ä¢ Goal: All bundles on single node (if possible)</p>
<p>‚Ä¢ Use Case: Shared memory, minimal latency</p>
<p>‚Ä¢ Algorithm: Single-node placement with fallback</p>
<h4>STRICT_SPREAD Strategy</h4>
<pre><code><code>case rpc::PlacementStrategy::STRICT_SPREAD:
return SchedulingOptions::BundleStrictSpread(
max_cpu_fraction_per_node, 
CreateSchedulingContext(placement_group_id));
</code></code></pre>
<p>‚Ä¢ Goal: Each bundle on different node</p>
<p>‚Ä¢ Use Case: Maximum fault tolerance</p>
<p>‚Ä¢ Algorithm: One bundle per node constraint</p>
<h3>Bundle Scheduling Algorithm</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Bundle Resource Formatting</h3>
<p>Ray formats placement group resources with special naming:</p>
<code>// From src/ray/common/bundle_spec.h
<p>std::string FormatPlacementGroupResource(</p>
<p>const std::string &amp;original_resource_name,</p>
<p>const std::string &amp;group_id_str,</p>
<p>int64_t bundle_index) {</p>
<p>if (bundle_index == -1) {</p>
<p>// Wildcard resource: CPU_group_&lt;group_id&gt;</p>
<p>return original_resource_name + &quot;_group_&quot; + group_id_str;</p>
<p>} else {</p>
<p>// Indexed resource: CPU_group_&lt;bundle_index&gt;_&lt;group_id&gt;</p>
<p>return original_resource_name + &quot;_group_&quot; + </p>
<p>std::to_string(bundle_index) + &quot;_&quot; + group_id_str;</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h3>CPU Fraction Limits</h3>
<p>Purpose: Prevent placement groups from monopolizing nodes</p>
<code>bool AllocationWillExceedMaxCpuFraction(
<p>const NodeResources &amp;node_resources,</p>
<p>const ResourceRequest &amp;bundle_resource_request,</p>
<p>double max_cpu_fraction_per_node,</p>
<p>double available_cpus_before_current_pg_request) {</p>
<p>if (max_cpu_fraction_per_node == 1.0) {</p>
<p>return false; // No limit</p>
<p>}</p>
<p>auto max_reservable_cpus = </p>
<p>max_cpu_fraction_per_node * node_resources.total.Get(cpu_id).Double();</p>
<p>// Ensure at least 1 CPU is excluded from placement groups</p>
<p>if (max_reservable_cpus &gt; total_cpus - 1) {</p>
<p>max_reservable_cpus = total_cpus - 1;</p>
<p>}</p>
<p>return cpus_used_by_pg_after &gt; max_reservable_cpus;</p>
<p>}</p>
<p></code></p>
<h3>Placement Group Lifecycle</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Scheduling Strategies</h2>
<p>----------------------------------------</p>
<h3>Strategy Types and Implementation</h3>
Ray supports multiple scheduling strategies through the <code>rpc::SchedulingStrategy</code> protocol buffer:
<code>// From src/ray/raylet/scheduling/cluster_resource_scheduler.cc
<p>scheduling::NodeID ClusterResourceScheduler::GetBestSchedulableNode(</p>
<p>const ResourceRequest &amp;resource_request,</p>
<p>const rpc::SchedulingStrategy &amp;scheduling_strategy,</p>
<p>bool actor_creation,</p>
<p>bool force_spillback,</p>
<p>const std::string &amp;preferred_node_id,</p>
<p>int64_t *total_violations,</p>
<p>bool *is_infeasible) {</p>
<p>if (scheduling_strategy.scheduling_strategy_case() ==</p>
<p>rpc::SchedulingStrategy::SchedulingStrategyCase::kSpreadSchedulingStrategy) {</p>
<p>best_node_id = scheduling_policy_-&gt;Schedule(</p>
<p>resource_request,</p>
<p>SchedulingOptions::Spread(force_spillback, force_spillback));</p>
<p>} else if (scheduling_strategy.scheduling_strategy_case() ==</p>
<p>rpc::SchedulingStrategy::SchedulingStrategyCase::</p>
<p>kNodeAffinitySchedulingStrategy) {</p>
<p>best_node_id = scheduling_policy_-&gt;Schedule(</p>
<p>resource_request,</p>
<p>SchedulingOptions::NodeAffinity(/* ... */));</p>
<p>} else if (scheduling_strategy.has_node_label_scheduling_strategy()) {</p>
<p>best_node_id = scheduling_policy_-&gt;Schedule(</p>
<p>resource_request, </p>
<p>SchedulingOptions::NodeLabelScheduling(scheduling_strategy));</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h3>DEFAULT Strategy</h3>
<p>Implementation: Hybrid policy with configurable parameters</p>
<code># Environment variables controlling DEFAULT strategy
<p>RAY_scheduler_spread_threshold = 0.5      # Utilization threshold</p>
<p>RAY_scheduler_top_k_fraction = 0.2        # Top-k selection ratio  </p>
<p>RAY_scheduler_top_k_absolute = 5          # Minimum top-k count</p>
<p></code></p>
<p>Algorithm:</p>
<p>1. Calculate node scores based on resource utilization</p>
<p>2. Select top-k nodes with lowest scores</p>
<p>3. Randomly choose from top-k for load balancing</p>
<h3>SPREAD Strategy</h3>
<p>Purpose: Maximize distribution across nodes</p>
<code>import ray
<p>@ray.remote(scheduling_strategy=&quot;SPREAD&quot;)</p>
<p>def distributed_task():</p>
<p>return &quot;Running on different nodes&quot;</p>
<h1>Tasks will be distributed across available nodes</h1>
<p>futures = [distributed_task.remote() for _ in range(100)]</p>
<p></code></p>
<p>Implementation Details:</p>
<p>- Prioritizes nodes with fewer running tasks</p>
<p>- Considers resource utilization as secondary factor</p>
<p>- Useful for embarrassingly parallel workloads</p>
<h3>Node Affinity Strategy</h3>
<p>Hard Affinity: Must run on specific node</p>
<code>import ray
<p>from ray.util.scheduling_strategies import NodeAffinitySchedulingStrategy</p>
<p>@ray.remote(scheduling_strategy=NodeAffinitySchedulingStrategy(</p>
<p>node_id=&quot;specific-node-id&quot;, </p>
<p>soft=False</p>
<p>))</p>
<p>def pinned_task():</p>
<p>return &quot;Must run on specific node&quot;</p>
<p></code></p>
<p>Soft Affinity: Prefer specific node with fallback</p>
<code>@ray.remote(scheduling_strategy=NodeAffinitySchedulingStrategy(
<p>node_id=&quot;preferred-node-id&quot;, </p>
<p>soft=True</p>
<p>))</p>
<p>def preferred_task():</p>
<p>return &quot;Prefers specific node but can run elsewhere&quot;</p>
<p></code></p>
<h3>Placement Group Strategy</h3>
<p>Bundle-Specific Scheduling:</p>
<code>import ray
<p>from ray.util.placement_group import placement_group</p>
<p>from ray.util.scheduling_strategies import PlacementGroupSchedulingStrategy</p>
<h1>Create placement group</h1>
<p>pg = placement_group([{&quot;CPU&quot;: 2}, {&quot;CPU&quot;: 2}], strategy=&quot;PACK&quot;)</p>
<p>@ray.remote(scheduling_strategy=PlacementGroupSchedulingStrategy(</p>
<p>placement_group=pg,</p>
<p>placement_group_bundle_index=0</p>
<p>))</p>
<p>def task_on_bundle_0():</p>
<p>return &quot;Running on bundle 0&quot;</p>
<p>@ray.remote(scheduling_strategy=PlacementGroupSchedulingStrategy(</p>
<p>placement_group=pg,</p>
<p>placement_group_bundle_index=-1  # Any bundle</p>
<p>))</p>
<p>def task_on_any_bundle():</p>
<p>return &quot;Running on any available bundle&quot;</p>
<p></code></p>
<h2>Node Affinity and Label-Based Scheduling</h2>
<p>----------------------------------------</p>
<h3>Node Label Scheduling Policy</h3>
Location: <code>src/ray/raylet/scheduling/policy/node_label_scheduling_policy.cc</code>
<p>Ray supports sophisticated label-based scheduling for fine-grained node selection:</p>
<code>scheduling::NodeID NodeLabelSchedulingPolicy::Schedule(
<p>const ResourceRequest &amp;resource_request,</p>
<p>SchedulingOptions options) {</p>
<p>// 1. Select feasible nodes</p>
<p>auto hard_match_nodes = SelectFeasibleNodes(resource_request);</p>
<p>// 2. Filter by hard expressions</p>
<p>if (node_label_scheduling_strategy.hard().expressions().size() &gt; 0) {</p>
<p>hard_match_nodes = FilterNodesByLabelMatchExpressions(</p>
<p>hard_match_nodes, node_label_scheduling_strategy.hard());</p>
<p>}</p>
<p>// 3. Filter by soft expressions  </p>
<p>auto hard_and_soft_match_nodes = FilterNodesByLabelMatchExpressions(</p>
<p>hard_match_nodes, node_label_scheduling_strategy.soft());</p>
<p>return SelectBestNode(hard_match_nodes, hard_and_soft_match_nodes, resource_request);</p>
<p>}</p>
<p></code></p>
<h3>Label Matching Implementation</h3>
<pre><code><code>bool NodeLabelSchedulingPolicy::IsNodeMatchLabelExpression(
const Node &amp;node, const rpc::LabelMatchExpression &amp;expression) const {
const auto &amp;key = expression.key();
const auto &amp;operator_type = expression.operator_();
const auto &amp;values = expression.values();
switch (operator_type) {
case rpc::LabelMatchExpression::IN:
return IsNodeLabelInValues(node, key, values);
case rpc::LabelMatchExpression::NOT_IN:
return !IsNodeLabelInValues(node, key, values);
case rpc::LabelMatchExpression::EXISTS:
return IsNodeLabelKeyExists(node, key);
case rpc::LabelMatchExpression::DOES_NOT_EXIST:
return !IsNodeLabelKeyExists(node, key);
}
}
</code></code></pre>
<h3>Label Selector Usage</h3>
<pre><code><code>import ray
from ray.util.scheduling_strategies import NodeLabelSchedulingStrategy
<h1>Hard constraints (must match)</h1>
hard_constraints = {
&quot;ray.io/node-type&quot;: &quot;gpu-node&quot;,
&quot;zone&quot;: &quot;us-west-1a&quot;
}
<h1>Soft constraints (preferred)</h1>
soft_constraints = {
&quot;instance-type&quot;: &quot;p3.2xlarge&quot;
}
@ray.remote(scheduling_strategy=NodeLabelSchedulingStrategy(
hard=hard_constraints,
soft=soft_constraints
))
def gpu_task():
return &quot;Running on GPU node in preferred zone&quot;
</code></code></pre>
<h3>Node Label Management</h3>
<p>Static Labels: Set during node startup</p>
<code># Set node labels via environment
<p>export RAY_NODE_LABELS='{&quot;zone&quot;:&quot;us-west-1a&quot;,&quot;instance-type&quot;:&quot;m5.large&quot;}'</p>
<p>ray start --head</p>
<p></code></p>
<p>Dynamic Labels: Updated at runtime</p>
<code>// From cluster resource data
<p>struct NodeResources {</p>
<p>absl::flat_hash_map&lt;std::string, std::string&gt; labels;</p>
<p>bool HasRequiredLabels(const LabelSelector &amp;label_selector) const;</p>
<p>bool NodeLabelMatchesConstraint(const LabelConstraint &amp;constraint) const;</p>
<p>};</p>
<p></code></p>
<h2>Locality-Aware Scheduling</h2>
<p>----------------------------------------</p>
<h3>Locality-Aware Lease Policy</h3>
Location: <code>src/ray/core_worker/lease_policy.cc</code>
<p>Ray implements data locality-aware scheduling to minimize data movement:</p>
<code>std::pair&lt;rpc::Address, bool&gt; LocalityAwareLeasePolicy::GetBestNodeForTask(
<p>const TaskSpecification &amp;spec) {</p>
<p>// Check for explicit scheduling strategies first</p>
<p>if (spec.IsSpreadSchedulingStrategy() || spec.IsNodeAffinitySchedulingStrategy()) {</p>
<p>return std::make_pair(fallback_rpc_address_, false);</p>
<p>}</p>
<p>// Pick node based on locality</p>
<p>if (auto node_id = GetBestNodeIdForTask(spec)) {</p>
<p>if (auto addr = node_addr_factory_(node_id.value())) {</p>
<p>return std::make_pair(addr.value(), true);</p>
<p>}</p>
<p>}</p>
<p>return std::make_pair(fallback_rpc_address_, false);</p>
<p>}</p>
<p></code></p>
<h3>Locality Calculation</h3>
<p>Criteria: Node with most object bytes local</p>
<code>std::optional&lt;NodeID&gt; LocalityAwareLeasePolicy::GetBestNodeIdForTask(
<p>const TaskSpecification &amp;spec) {</p>
<p>const auto &amp;dependencies = spec.GetDependencies();</p>
<p>if (dependencies.empty()) {</p>
<p>return std::nullopt;</p>
<p>}</p>
<p>// Calculate locality scores for each node</p>
<p>absl::flat_hash_map&lt;NodeID, int64_t&gt; locality_scores;</p>
<p>for (const auto &amp;obj_id : dependencies) {</p>
<p>auto locality_data = locality_data_provider_.GetLocalityData(obj_id);</p>
<p>for (const auto &amp;node_id : locality_data.nodes_containing_object) {</p>
<p>locality_scores[node_id] += locality_data.object_size;</p>
<p>}</p>
<p>}</p>
<p>// Return node with highest locality score</p>
<p>return GetNodeWithMaxScore(locality_scores);</p>
<p>}</p>
<p></code></p>
<h3>Locality vs Strategy Priority</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Locality Testing</h3>
<code>// From src/ray/tests/test_scheduling.py
<p>def test_locality_aware_leasing(ray_start_cluster):</p>
<p>@ray.remote(resources={&quot;pin&quot;: 1})</p>
<p>def non_local():</p>
<p>return ray._private.worker.global_worker.node.unique_id</p>
<p>@ray.remote</p>
<p>def f(x):</p>
<p>return ray._private.worker.global_worker.node.unique_id</p>
<h1>Test that task f() runs on the same node as non_local()</h1>
<h1>due to data locality</h1>
<p>assert ray.get(f.remote(non_local.remote())) == non_local_node.unique_id</p>
<p></code></p>
<h2>Cluster Resource Scheduling</h2>
<p>----------------------------------------</p>
<h3>Cluster Resource Manager</h3>
Location: <code>src/ray/raylet/scheduling/cluster_resource_manager.h</code>
<p>Maintains global view of cluster resources:</p>
<code>class ClusterResourceManager {
<p>// Add or update node resources</p>
<p>void AddOrUpdateNode(scheduling::NodeID node_id,</p>
<p>const NodeResources &amp;node_resources);</p>
<p>// Check resource availability</p>
<p>bool HasAvailableResources(scheduling::NodeID node_id,</p>
<p>const ResourceRequest &amp;resource_request) const;</p>
<p>// Resource allocation</p>
<p>bool SubtractNodeAvailableResources(scheduling::NodeID node_id,</p>
<p>const ResourceRequest &amp;resource_request);</p>
<p>};</p>
<p></code></p>
<h3>Resource Synchronization</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Resource Reporting</h3>
Location: <code>src/ray/raylet/scheduling/scheduler_resource_reporter.cc</code>
<code>void SchedulerResourceReporter::FillResourceUsage(rpc::ResourcesData &amp;data) const {
<p>// Report resource demands by shape</p>
<p>auto resource_load_by_shape = data.mutable_resource_load_by_shape();</p>
<p>for (const auto &amp;[scheduling_class, task_queue] : tasks_to_schedule_) {</p>
<p>const auto &amp;resources = scheduling_class_descriptor.resource_set.GetResourceMap();</p>
<p>auto by_shape_entry = resource_load_by_shape-&gt;Add();</p>
<p>for (const auto &amp;resource : resources) {</p>
<p>(*by_shape_entry-&gt;mutable_shape())[resource.first] = resource.second;</p>
<p>}</p>
<p>by_shape_entry-&gt;set_num_ready_requests_queued(task_queue.size());</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h2>Autoscaler Integration</h2>
<p>----------------------------------------</p>
<h3>Resource Demand Scheduler</h3>
Location: <code>python/ray/autoscaler/v2/scheduler.py</code>
<p>The autoscaler uses sophisticated scheduling algorithms to determine cluster scaling decisions:</p>
<code>class ResourceDemandScheduler(IResourceScheduler):
<p>def schedule(self, request: SchedulingRequest) -&gt; SchedulingReply:</p>
<p>ctx = self.ScheduleContext.from_schedule_request(request)</p>
<h1>1. Enforce min workers per type</h1>
<p>self._enforce_min_workers_per_type(ctx)</p>
<h1>2. Enforce resource constraints</h1>
<p>infeasible_constraints = self._enforce_resource_constraints(</p>
<p>ctx, request.cluster_resource_constraints)</p>
<h1>3. Schedule gang resource requests</h1>
<p>infeasible_gang_requests = self._sched_gang_resource_requests(</p>
<p>ctx, request.gang_resource_requests)</p>
<h1>4. Schedule regular resource requests</h1>
<p>infeasible_requests = self._sched_resource_requests(</p>
<p>ctx, ResourceRequestUtil.ungroup_by_count(request.resource_requests))</p>
<h1>5. Enforce idle termination</h1>
<p>self._enforce_idle_termination(ctx)</p>
<p>return SchedulingReply(</p>
<p>to_launch=ctx.get_launch_requests(),</p>
<p>to_terminate=ctx.get_terminate_requests(),</p>
<p>infeasible_resource_requests=infeasible_requests,</p>
<p>infeasible_gang_resource_requests=infeasible_gang_requests,</p>
<p>infeasible_cluster_resource_constraints=infeasible_constraints</p>
<p>)</p>
<p></code></p>
<h3>Binpacking Algorithm</h3>
<pre><code><code>def _try_schedule(
ctx: ScheduleContext,
requests_to_sched: List[ResourceRequest],
resource_request_source: ResourceRequestSource,
) -&gt; Tuple[List[SchedulingNode], List[ResourceRequest]]:
<h1>Sort requests by complexity for better binpacking</h1>
def _sort_resource_request(req: ResourceRequest) -&gt; Tuple:
return (
len(req.placement_constraints),
len(req.resources_bundle.values()),
sum(req.resources_bundle.values()),
sorted(req.resources_bundle.items()),
)
requests_to_sched = sorted(
requests_to_sched, key=_sort_resource_request, reverse=True)
<h1>Try scheduling on existing nodes first</h1>
while len(requests_to_sched) &gt; 0 and len(existing_nodes) &gt; 0:
best_node, requests_to_sched, existing_nodes = \
self._sched_best_node(requests_to_sched, existing_nodes, resource_request_source)
if best_node is None:
break
target_nodes.append(best_node)
<h1>Try scheduling on new nodes</h1>
for node_type, num_available in node_type_available.items():
if num_available &gt; 0:
new_node = SchedulingNode.from_node_config(
ctx.get_node_type_configs()[node_type],
status=SchedulingNodeStatus.TO_LAUNCH)
<h1>Try to schedule remaining requests on new node</h1>
</code></code></pre>
<h3>Placement Group Autoscaling</h3>
<pre><code><code>def placement_groups_to_resource_demands(
pending_placement_groups: List[PlacementGroupTableData],
) -&gt; Tuple[List[ResourceDict], List[List[ResourceDict]]]:
resource_demand_vector = []
unconverted = []
for placement_group in pending_placement_groups:
shapes = [dict(bundle.unit_resources) for bundle in placement_group.bundles 
if bundle.node_id == b&quot;&quot;]  # Only unplaced bundles
if placement_group.strategy == PlacementStrategy.PACK:
resource_demand_vector.extend(shapes)
elif placement_group.strategy == PlacementStrategy.STRICT_PACK:
<h1>Combine all bundles into single demand</h1>
combined = collections.defaultdict(float)
for shape in shapes:
for label, quantity in shape.items():
combined[label] += quantity
resource_demand_vector.append(combined)
elif placement_group.strategy == PlacementStrategy.STRICT_SPREAD:
<h1>Cannot be converted - needs special handling</h1>
unconverted.append(shapes)
return resource_demand_vector, unconverted
</code></code></pre>
<h3>Autoscaler Configuration</h3>
<pre><code><code># Example autoscaler configuration
cluster_name: ray-cluster
max_workers: 100
upscaling_speed: 1.0
idle_timeout_minutes: 5
available_node_types:
ray.head.default:
min_workers: 0
max_workers: 0
resources: {&quot;CPU&quot;: 4}
ray.worker.cpu:
min_workers: 0
max_workers: 50
resources: {&quot;CPU&quot;: 8, &quot;memory&quot;: 32000000000}
ray.worker.gpu:
min_workers: 0
max_workers: 10
resources: {&quot;CPU&quot;: 16, &quot;GPU&quot;: 4, &quot;memory&quot;: 64000000000}
</code></code></pre>
<h2>Performance Characteristics</h2>
<p>----------------------------------------</p>
<h3>Scheduling Latency</h3>
<p>Typical Latencies:</p>
<p>- Local scheduling: 1-5ms</p>
<p>- Remote scheduling: 10-50ms</p>
<p>- Placement group creation: 100-1000ms</p>
<p>- Autoscaler response: 30-300s</p>
<h3>Scalability Metrics</h3>
<p>Cluster Size: Ray scheduling tested up to 1000+ nodes</p>
<p>Task Throughput: </p>
<p>- Simple tasks: 100K+ tasks/second</p>
<p>- Complex scheduling: 10K+ tasks/second</p>
<p>- Placement groups: 100+ groups/second</p>
<h3>Memory Usage</h3>
<p>Scheduler Memory Overhead:</p>
<code>// Per-node overhead in ClusterResourceManager
<p>struct NodeResources {</p>
<p>NodeResourceSet total;      // ~1KB per node</p>
<p>NodeResourceSet available; // ~1KB per node  </p>
<p>NodeResourceSet normal_task_resources; // ~1KB per node</p>
<p>absl::flat_hash_map&lt;std::string, std::string&gt; labels; // Variable</p>
<p>};</p>
<p>// Total: ~3KB + labels per node</p>
<p></code></p>
<p>Task Queue Memory:</p>
<code>// Per-task overhead in scheduling queues
<p>class Work {</p>
<p>RayTask task;                    // ~2KB per task</p>
<p>TaskResourceInstances allocated; // ~500B per task</p>
<p>WorkStatus state;               // ~100B per task</p>
<p>};</p>
<p>// Total: ~2.6KB per queued task</p>
<p></code></p>
<h3>Performance Optimization</h3>
<p>Top-K Selection: Reduces scheduling complexity from O(N) to O(K)</p>
<code>// Default configuration
<p>RAY_scheduler_top_k_fraction = 0.2  // 20% of nodes</p>
<p>RAY_scheduler_top_k_absolute = 5    // Minimum 5 nodes</p>
<p></code></p>
<p>Caching: Resource views cached to avoid repeated calculations</p>
<code>class ClusterResourceManager {
<p>// Cached resource calculations</p>
<p>mutable absl::flat_hash_map&lt;scheduling::NodeID, float&gt; utilization_cache_;</p>
<p>mutable int64_t cache_timestamp_;</p>
<p>};</p>
<p></code></p>
<h2>Configuration and Tuning</h2>
<p>----------------------------------------</p>
<h3>Environment Variables</h3>
<p>Core Scheduling:</p>
<code># Spread threshold for hybrid scheduling
<p>export RAY_scheduler_spread_threshold=0.5</p>
<h1>Top-k node selection</h1>
<p>export RAY_scheduler_top_k_fraction=0.2</p>
<p>export RAY_scheduler_top_k_absolute=5</p>
<h1>Worker management</h1>
<p>export RAY_num_workers_soft_limit=1000</p>
<p>export RAY_maximum_startup_concurrency=10</p>
<p></code></p>
<p>Resource Management:</p>
<code># Object store memory scheduling
<p>export RAY_object_store_memory=1000000000</p>
<h1>Pull manager configuration  </h1>
<p>export RAY_object_manager_pull_timeout_ms=10000</p>
<p>export RAY_object_manager_max_bytes_in_flight=100000000</p>
<p></code></p>
<p>Placement Groups:</p>
<code># CPU fraction limits
<p>export RAY_placement_group_max_cpu_fraction_per_node=0.8</p>
<h1>Bundle scheduling timeout</h1>
<p>export RAY_placement_group_bundle_resource_timeout_s=30</p>
<p></code></p>
<h3>Runtime Configuration</h3>
<p>Cluster Resource Constraints:</p>
<code>import ray
<h1>Set cluster-wide resource constraints</h1>
<p>ray.autoscaler.sdk.request_resources([</p>
<p>{&quot;CPU&quot;: 100, &quot;GPU&quot;: 10},  # Ensure cluster can handle this workload</p>
<p>{&quot;memory&quot;: 1000000000}    # Minimum memory requirement</p>
<p>])</p>
<p></code></p>
<p>Node Type Configuration:</p>
<code># Configure node types for autoscaling
<p>node_config = {</p>
<p>&quot;ray.worker.cpu&quot;: {</p>
<p>&quot;min_workers&quot;: 2,</p>
<p>&quot;max_workers&quot;: 20,</p>
<p>&quot;resources&quot;: {&quot;CPU&quot;: 8, &quot;memory&quot;: 32000000000}</p>
<p>},</p>
<p>&quot;ray.worker.gpu&quot;: {</p>
<p>&quot;min_workers&quot;: 0, </p>
<p>&quot;max_workers&quot;: 5,</p>
<p>&quot;resources&quot;: {&quot;CPU&quot;: 16, &quot;GPU&quot;: 4, &quot;memory&quot;: 64000000000}</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h3>Performance Tuning</h3>
<p>For High Throughput:</p>
<code># Increase worker limits
<p>export RAY_num_workers_soft_limit=2000</p>
<p>export RAY_maximum_startup_concurrency=50</p>
<h1>Reduce scheduling overhead</h1>
<p>export RAY_scheduler_top_k_absolute=10</p>
<p>export RAY_scheduler_spread_threshold=0.3</p>
<p></code></p>
<p>For Low Latency:</p>
<code># Prioritize local scheduling
<p>export RAY_scheduler_spread_threshold=0.8</p>
<p>export RAY_scheduler_top_k_fraction=0.1</p>
<h1>Reduce worker startup time</h1>
<p>export RAY_worker_lease_timeout_milliseconds=1000</p>
<p></code></p>
<p>For Large Clusters:</p>
<code># Optimize for scale
<p>export RAY_scheduler_top_k_fraction=0.1  # Top 10% of nodes</p>
<p>export RAY_raylet_report_resources_period_milliseconds=1000</p>
<p>export RAY_gcs_resource_report_poll_period_milliseconds=1000</p>
<p></code></p>
<h2>Best Practices</h2>
<p>----------------------------------------</p>
<h3>Task Scheduling</h3>
<p>1. Use Appropriate Scheduling Strategies:</p>
<code># For embarrassingly parallel workloads
<p>@ray.remote(scheduling_strategy=&quot;SPREAD&quot;)</p>
<p>def parallel_task(data):</p>
<p>return process(data)</p>
<h1>For data-dependent tasks (default locality-aware)</h1>
<p>@ray.remote</p>
<p>def dependent_task(large_object):</p>
<p>return analyze(large_object)</p>
<h1>For specific hardware requirements</h1>
<p>@ray.remote(scheduling_strategy=NodeAffinitySchedulingStrategy(</p>
<p>node_id=gpu_node_id, soft=True))</p>
<p>def gpu_task():</p>
<p>return train_model()</p>
<p></code></p>
<p>2. Resource Specification:</p>
<code># Be specific about resource requirements
<p>@ray.remote(num_cpus=2, num_gpus=1, memory=4000*1024*1024)</p>
<p>def resource_intensive_task():</p>
<p>return compute()</p>
<h1>Use custom resources for specialized hardware</h1>
<p>@ray.remote(resources={&quot;accelerator&quot;: 1})</p>
<p>def accelerated_task():</p>
<p>return specialized_compute()</p>
<p></code></p>
<h3>Actor Placement</h3>
<p>1. Consider Resource Lifetime:</p>
<code># Actors hold resources for their lifetime
<p>@ray.remote(num_cpus=4, num_gpus=1)</p>
<p>class ModelServer:</p>
<p>def __init__(self):</p>
<p>self.model = load_large_model()</p>
<p>def predict(self, data):</p>
<p>return self.model.predict(data)</p>
<h1>Create fewer, long-lived actors rather than many short-lived ones</h1>
<p>server = ModelServer.remote()</p>
<p></code></p>
<p>2. Use Placement Groups for Related Actors:</p>
<code># Group related actors together
<p>pg = placement_group([{&quot;CPU&quot;: 4}, {&quot;CPU&quot;: 4}, {&quot;CPU&quot;: 4}], strategy=&quot;PACK&quot;)</p>
<p>actors = [</p>
<p>Actor.options(scheduling_strategy=PlacementGroupSchedulingStrategy(</p>
<p>placement_group=pg, placement_group_bundle_index=i</p>
<p>)).remote() for i in range(3)</p>
<p>]</p>
<p></code></p>
<h3>Placement Group Design</h3>
<p>1. Choose Appropriate Strategies:</p>
<code># For tightly coupled workloads
<p>pg_pack = placement_group([{&quot;CPU&quot;: 2, &quot;GPU&quot;: 1}] * 4, strategy=&quot;PACK&quot;)</p>
<h1>For fault tolerance</h1>
<p>pg_spread = placement_group([{&quot;CPU&quot;: 2}] * 8, strategy=&quot;SPREAD&quot;)</p>
<h1>For strict requirements</h1>
<p>pg_strict = placement_group([{&quot;CPU&quot;: 4}] * 2, strategy=&quot;STRICT_SPREAD&quot;)</p>
<p></code></p>
<p>2. Bundle Size Optimization:</p>
<code># Avoid bundles larger than single node capacity
<h1>Bad: Bundle requires more than any node has</h1>
<p>bad_pg = placement_group([{&quot;CPU&quot;: 64, &quot;GPU&quot;: 8}])  # If max node has 32 CPU</p>
<h1>Good: Bundle fits on available nodes</h1>
<p>good_pg = placement_group([{&quot;CPU&quot;: 16, &quot;GPU&quot;: 2}] * 4)</p>
<p></code></p>
<h3>Autoscaler Optimization</h3>
<p>1. Configure Appropriate Limits:</p>
<code># Set realistic min/max workers
<p>available_node_types:</p>
<p>ray.worker.default:</p>
<p>min_workers: 2      # Always keep some capacity</p>
<p>max_workers: 100    # Prevent runaway scaling</p>
<p>upscaling_speed: 2.0  # Scale up aggressively</p>
<p></code></p>
<p>2. Use Resource Constraints:</p>
<code># Ensure cluster can handle expected workload
<p>ray.autoscaler.sdk.request_resources([</p>
<p>{&quot;CPU&quot;: 200, &quot;memory&quot;: 500000000000},  # Expected peak usage</p>
<p>])</p>
<p></code></p>
<h2>Troubleshooting</h2>
<p>----------------------------------------</p>
<h3>Common Scheduling Issues</h3>
<p>1. Tasks Stuck in Pending State:</p>
<p>Symptoms: Tasks remain in PENDING_SCHEDULING state</p>
<p>Causes:</p>
<p>- Insufficient cluster resources</p>
<p>- Infeasible resource requirements</p>
<p>- Node affinity to unavailable nodes</p>
<p>Debugging:</p>
<code># Check cluster resources
<p>print(ray.cluster_resources())</p>
<p>print(ray.available_resources())</p>
<h1>Check task resource requirements</h1>
<p>@ray.remote(num_cpus=1)</p>
<p>def debug_task():</p>
<p>return ray.get_runtime_context().get_assigned_resources()</p>
<h1>Check for infeasible tasks</h1>
<p>ray.autoscaler.sdk.request_resources([{&quot;CPU&quot;: 1000}])  # Will show if infeasible</p>
<p></code></p>
<p>2. Poor Load Balancing:</p>
<p>Symptoms: Some nodes overloaded while others idle</p>
<p>Causes:</p>
<p>- Inappropriate scheduling strategy</p>
<p>- Data locality overriding load balancing</p>
<p>- Sticky worker assignment</p>
<p>Solutions:</p>
<code># Use SPREAD strategy for better distribution
<p>@ray.remote(scheduling_strategy=&quot;SPREAD&quot;)</p>
<p>def distributed_task():</p>
<p>return compute()</p>
<h1>Adjust spread threshold</h1>
<p>import os</p>
<p>os.environ[&quot;RAY_scheduler_spread_threshold&quot;] = &quot;0.3&quot;</p>
<p></code></p>
<p>3. Placement Group Creation Failures:</p>
<p>Symptoms: Placement groups fail to create or timeout</p>
<p>Causes:</p>
<p>- Insufficient cluster capacity</p>
<p>- Conflicting resource constraints</p>
<p>- Network partitions</p>
<p>Debugging:</p>
<code>import ray
<p>from ray.util.placement_group import placement_group</p>
<h1>Check placement group status</h1>
<p>pg = placement_group([{&quot;CPU&quot;: 2}] * 4, strategy=&quot;STRICT_SPREAD&quot;)</p>
<p>print(pg.ready())  # False if creation failed</p>
<h1>Check bundle placement</h1>
<p>print(ray.util.placement_group_table())</p>
<p></code></p>
<h3>Performance Issues</h3>
<p>1. High Scheduling Latency:</p>
<p>Symptoms: Long delays between task submission and execution</p>
<p>Causes:</p>
<p>- Large cluster with inefficient node selection</p>
<p>- Complex placement constraints</p>
<p>- Resource fragmentation</p>
<p>Solutions:</p>
<code># Reduce top-k selection size
<p>export RAY_scheduler_top_k_fraction=0.1</p>
<h1>Increase spread threshold for faster local scheduling</h1>
<p>export RAY_scheduler_spread_threshold=0.7</p>
<p></code></p>
<p>2. Memory Issues in Scheduler:</p>
<p>Symptoms: Raylet OOM, high memory usage in scheduling components</p>
<p>Causes:</p>
<p>- Large number of queued tasks</p>
<p>- Memory leaks in scheduling data structures</p>
<p>- Excessive resource tracking overhead</p>
<p>Solutions:</p>
<code># Limit concurrent tasks
<p>export RAY_num_workers_soft_limit=500</p>
<h1>Reduce resource reporting frequency</h1>
<p>export RAY_raylet_report_resources_period_milliseconds=5000</p>
<p></code></p>
<h3>Debugging Tools</h3>
<p>1. Ray Status Commands:</p>
<code># Check cluster state
<p>ray status</p>
<h1>Check resource usage</h1>
<p>ray status --verbose</p>
<h1>Check placement groups</h1>
<p>ray status --placement-groups</p>
<p></code></p>
<p>2. Programmatic Debugging:</p>
<code># Check scheduling state
<p>import ray._private.state as state</p>
<h1>Get pending tasks</h1>
<p>pending_tasks = state.tasks(filters=[(&quot;state&quot;, &quot;=&quot;, &quot;PENDING_SCHEDULING&quot;)])</p>
<h1>Get resource usage by node</h1>
<p>nodes = state.nodes()</p>
<p>for node in nodes:</p>
<p>print(f&quot;Node {node['node_id']}: {node['resources_total']}&quot;)</p>
<p></code></p>
<p>3. Logging Configuration:</p>
<code># Enable debug logging for scheduling
<p>export RAY_LOG_LEVEL=DEBUG</p>
<p>export RAY_BACKEND_LOG_LEVEL=DEBUG</p>
<h1>Focus on specific components</h1>
<p>export RAY_LOG_TO_STDERR=1</p>
<p>ray start --head --log-to-driver</p>
<p></code></p>
<h3>Monitoring and Observability</h3>
<p>1. Metrics Collection:</p>
<code># Custom metrics for scheduling performance
<p>import ray</p>
<p>from ray.util.metrics import Counter, Histogram</p>
<p>scheduling_latency = Histogram(</p>
<p>&quot;ray_scheduling_latency_seconds&quot;,</p>
<p>description=&quot;Time from task submission to scheduling&quot;,</p>
<p>boundaries=[0.001, 0.01, 0.1, 1.0, 10.0]</p>
<p>)</p>
<p>task_queue_size = Counter(</p>
<p>&quot;ray_task_queue_size&quot;,</p>
<p>description=&quot;Number of tasks in scheduling queue&quot;</p>
<p>)</p>
<p></code></p>
<p>2. Dashboard Integration:</p>
<p>- Use Ray Dashboard for real-time cluster monitoring</p>
<p>- Monitor resource utilization trends</p>
<p>- Track placement group creation success rates</p>
<p>- Observe task scheduling patterns</p>
<p>This comprehensive guide covers Ray's distributed scheduling system from architecture to implementation details, providing developers and operators with the knowledge needed to effectively use and optimize Ray's scheduling capabilities in production environments.</p>

<div class="page-break"></div>
<h1>Part I: Ray Fundamentals</h1>
<p>============================================================</p>
<h1>Chapter 2: The Ray Driver System</h1>
<p>============================================================</p>
<h1>Ray Driver - Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Driver Architecture Overview</p>
<p>‚Ä¢ Driver Lifecycle Deep Dive</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Driver-GCS Integration</p>
<p>‚Ä¢ Driver-Raylet Communication</p>
<p>‚Ä¢ Object Management and References</p>
<p>‚Ä¢ Task and Actor Submission</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code Navigation Guide</p>
<p>‚Ä¢ Common Patterns and Best Practices</p>
<p>‚Ä¢ Troubleshooting and Debugging</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
The Ray driver is like the conductor of an orchestra - it coordinates all the distributed computation in your Ray cluster. When you run a Python script with <code>ray.init()</code>, that script becomes the driver process. The driver is responsible for submitting tasks, creating actors, managing object references, and collecting results from the distributed cluster.
<h3>What Makes the Ray Driver Special?</h3>
<p>Centralized Control with Distributed Execution: The driver provides a single point of control for your distributed program while execution happens across many machines. Think of it as the "brain" that sends instructions to "hands" (workers) throughout the cluster.</p>
<p>Seamless Local-to-Distributed: Your Python code looks almost identical whether running locally or on a 1000-node cluster. The driver handles all the complexity of distribution transparently.</p>
<p>Fault-Tolerant Coordination: The driver can recover from worker failures, network partitions, and other distributed system challenges while maintaining program correctness.</p>
<h3>Core Driver Responsibilities</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Driver Architecture Overview</h2>
<p>----------------------------------------</p>
<h3>High-Level Architecture</h3>
<p>The Ray driver is built on a multi-layered architecture where each layer handles specific aspects of distributed computing:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Core Components Deep Dive</h3>
<h4>1. CoreWorker - The Heart of the Driver</h4>
Location: <code>src/ray/core_worker/core_worker.h</code> and <code>src/ray/core_worker/core_worker.cc</code>
<p>The CoreWorker is the most important component of the driver. Think of it as the driver's "execution engine" that handles all distributed operations.</p>
<code>class CoreWorker {
<p>public:</p>
<p>/// Constructor for driver process</p>
<p>CoreWorker(const CoreWorkerOptions &amp;options, const WorkerID &amp;worker_id);</p>
<p>/// Submit a task for remote execution</p>
<p>Status SubmitTask(const RayFunction &amp;function,</p>
<p>const std::vector&lt;std::unique_ptr&lt;TaskArg&gt;&gt; &amp;args,</p>
<p>const TaskOptions &amp;task_options,</p>
<p>std::vector&lt;rpc::ObjectReference&gt; *returned_refs);</p>
<p>/// Create an actor</p>
<p>Status CreateActor(const RayFunction &amp;function,</p>
<p>const std::vector&lt;std::unique_ptr&lt;TaskArg&gt;&gt; &amp;args,</p>
<p>const ActorCreationOptions &amp;actor_creation_options,</p>
<p>std::vector&lt;rpc::ObjectReference&gt; *returned_refs);</p>
<p>/// Get objects from the object store</p>
<p>Status Get(const std::vector&lt;ObjectID&gt; &amp;ids,</p>
<p>int64_t timeout_ms,</p>
<p>std::vector&lt;std::shared_ptr&lt;RayObject&gt;&gt; *results);</p>
<p>/// Put an object into the object store</p>
<p>Status Put(const RayObject &amp;object,</p>
<p>const std::vector&lt;ObjectID&gt; &amp;contained_object_ids,</p>
<p>ObjectID *object_id);</p>
<p>};</p>
<p></code></p>
<p>What the CoreWorker Does (In Simple Terms):</p>
<p>- Task Coordinator: When you call a @ray.remote function, CoreWorker packages it up and sends it to the right worker</p>
<p>- Object Tracker: Keeps track of all the data objects your program creates and where they're stored</p>
<p>- Communication Hub: Manages all the network connections to GCS, raylets, and other workers</p>
<p>- Memory Manager: Handles garbage collection of distributed objects when they're no longer needed</p>
<h4>2. Task Management System</h4>
Location: <code>src/ray/core_worker/task_manager.h</code>
<code>class TaskManager {
<p>private:</p>
<p>/// Map from task ID to task specification and metadata</p>
<p>absl::flat_hash_map&lt;TaskID, TaskSpec&gt; submittable_tasks_;</p>
<p>/// Tasks that have been submitted but not yet completed</p>
<p>absl::flat_hash_map&lt;TaskID, rpc::TaskStatus&gt; pending_tasks_;</p>
<p>public:</p>
<p>/// Add a task that is pending execution</p>
<p>void AddPendingTask(const TaskID &amp;task_id,</p>
<p>const TaskSpec &amp;spec,</p>
<p>const std::string &amp;call_site);</p>
<p>/// Mark a task as completed and handle its return values</p>
<p>void CompletePendingTask(const TaskID &amp;task_id,</p>
<p>const rpc::PushTaskReply &amp;reply,</p>
<p>const rpc::Address &amp;worker_addr);</p>
<p>/// Handle task failure and potential retry</p>
<p>void FailPendingTask(const TaskID &amp;task_id,</p>
<p>rpc::ErrorType error_type,</p>
<p>const Status *status);</p>
<p>};</p>
<p></code></p>
<h4>3. Actor Management System</h4>
Location: <code>src/ray/core_worker/actor_manager.h</code>
<code>class ActorManager {
<p>private:</p>
<p>/// Map from actor ID to actor handle information</p>
<p>absl::flat_hash_map&lt;ActorID, ActorHandle&gt; actor_handles_;</p>
<p>/// Actors created by this worker</p>
<p>absl::flat_hash_map&lt;ActorID, std::unique_ptr&lt;ActorCreationState&gt;&gt; created_actors_;</p>
<p>public:</p>
<p>/// Create a new actor</p>
<p>Status CreateActor(const TaskSpec &amp;task_spec,</p>
<p>const gcs::ActorCreationOptions &amp;options,</p>
<p>std::vector&lt;rpc::ObjectReference&gt; *returned_refs);</p>
<p>/// Submit a task to an existing actor</p>
<p>Status SubmitActorTask(const ActorID &amp;actor_id,</p>
<p>const TaskSpec &amp;task_spec,</p>
<p>std::vector&lt;rpc::ObjectReference&gt; *returned_refs);</p>
<p>/// Handle actor death and cleanup</p>
<p>void HandleActorStateNotification(const ActorID &amp;actor_id,</p>
<p>const gcs::ActorTableData &amp;actor_data);</p>
<p>};</p>
<p></code></p>
<h2>Driver Lifecycle Deep Dive</h2>
<p>----------------------------------------</p>
<h3>Phase 1: Initialization (<code>ray.init()</code>)</h3>
When you call <code>ray.init()</code>, a complex initialization sequence begins:
<p>[Diagram content removed for EPUB version]</p>
<p>Detailed Initialization Steps:</p>
<p>‚Ä¢ Configuration Resolution: Ray determines cluster address, resources, and other settings</p>
<p>‚Ä¢ CoreWorker Creation: The main driver execution engine is initialized</p>
<p>‚Ä¢ GCS Connection: Establishes connection to cluster metadata service</p>
<p>‚Ä¢ Raylet Connection: Connects to local scheduling and execution service</p>
<p>‚Ä¢ Object Store Connection: Sets up shared memory access for data storage</p>
<p>‚Ä¢ Driver Registration: Registers with GCS as a special "driver" worker type</p>
<code># From python/ray/_private/worker.py
<p>def init(address=None, </p>
<p>num_cpus=None,</p>
<p>num_gpus=None,</p>
<p>resources=None,</p>
<p>object_store_memory=None,</p>
<p>local_mode=False,</p>
<p>**kwargs):</p>
<p>&quot;&quot;&quot;Initialize Ray for distributed computing.&quot;&quot;&quot;</p>
<h1>Step 1: Process configuration</h1>
<p>config = _load_config(kwargs)</p>
<h1>Step 2: Start or connect to cluster</h1>
<p>if address is None:</p>
<h1>Start local cluster</h1>
<p>_global_node = ray._private.node.Node(</p>
<p>head=True,</p>
<p>shutdown_at_exit=True,</p>
<p>ray_params=ray_params)</p>
<p>else:</p>
<h1>Connect to existing cluster</h1>
<p>ray_params.update_if_absent(redis_address=address)</p>
<h1>Step 3: Initialize CoreWorker</h1>
<p>worker = Worker()</p>
<p>worker.mode = LOCAL_MODE if local_mode else WORKER_MODE</p>
<h1>Step 4: Connect to services</h1>
<p>gcs_client = GcsClient(address=gcs_address)</p>
<p>worker.gcs_client = gcs_client</p>
<h1>Step 5: Register as driver</h1>
<p>worker.worker_id = ray._private.utils.compute_driver_id_from_job(</p>
<p>job_id, ray_params.driver_id)</p>
<h1>CoreWorker handles the rest of initialization</h1>
<p>_global_worker = worker</p>
<p>worker.check_connected()</p>
<p></code></p>
<h3>Phase 2: Task and Actor Submission</h3>
<h4>Task Submission Flow</h4>
<p>[Diagram content removed for EPUB version]</p>
<p>Code Deep Dive - Task Submission:</p>
<code>// From src/ray/core_worker/core_worker.cc
<p>Status CoreWorker::SubmitTask(const RayFunction &amp;function,</p>
<p>const std::vector&lt;std::unique_ptr&lt;TaskArg&gt;&gt; &amp;args,</p>
<p>const TaskOptions &amp;task_options,</p>
<p>std::vector&lt;rpc::ObjectReference&gt; *returned_refs) {</p>
<p>// Step 1: Create unique task ID</p>
<p>const TaskID task_id = TaskID::FromRandom();</p>
<p>// Step 2: Build task specification</p>
<p>TaskSpecBuilder builder;</p>
<p>builder.SetCommonTaskSpec(task_id, function.GetLanguage(), </p>
<p>function.GetFunctionDescriptor(),</p>
<p>job_id_, task_id, /*parent_counter=*/0, </p>
<p>caller_id_, rpc_address_, </p>
<p>task_options.resources,</p>
<p>task_options.placement_group_bundle_index);</p>
<p>// Step 3: Add function arguments</p>
<p>for (const auto &amp;arg : args) {</p>
<p>if (arg-&gt;IsPassedByReference()) {</p>
<p>builder.AddByRefArg(arg-&gt;GetReference());</p>
<p>} else {</p>
<p>builder.AddByValueArg(*arg-&gt;GetValue());</p>
<p>}</p>
<p>}</p>
<p>const TaskSpec task_spec = builder.Build();</p>
<p>// Step 4: Generate return object references</p>
<p>for (int i = 0; i &lt; task_spec.NumReturns(); i++) {</p>
<p>returned_refs-&gt;emplace_back();</p>
<p>returned_refs-&gt;back().set_object_id(</p>
<p>ObjectID::FromIndex(task_id, i + 1).Binary());</p>
<p>}</p>
<p>// Step 5: Submit to task manager for tracking</p>
<p>task_manager_-&gt;AddPendingTask(task_id, task_spec, &quot;&quot;);</p>
<p>// Step 6: Send to raylet for scheduling</p>
<p>return raylet_client_-&gt;SubmitTask(task_spec, task_options.concurrency_group_name);</p>
<p>}</p>
<p></code></p>
<h3>Phase 3: Result Collection and Object Management</h3>
<h4>Object Reference System</h4>
<p>Ray uses a sophisticated object reference system where the driver tracks references to distributed objects:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Phase 4: Cleanup and Shutdown</h3>
<p>When the driver shuts down, it must carefully clean up all distributed resources:</p>
<code># From python/ray/_private/worker.py  
<p>def shutdown(verbose=True):</p>
<p>&quot;&quot;&quot;Clean shutdown of Ray driver.&quot;&quot;&quot;</p>
<h1>Step 1: Cancel all pending tasks</h1>
<p>_global_worker.core_worker.cancel_all_tasks()</p>
<h1>Step 2: Destroy all actors created by this driver</h1>
<p>for actor_id in _global_worker.actor_handles:</p>
<p>_global_worker.core_worker.kill_actor(actor_id, no_restart=True)</p>
<h1>Step 3: Clean up object references</h1>
<p>_global_worker.core_worker.shutdown()</p>
<h1>Step 4: Disconnect from cluster services</h1>
<p>if _global_worker.gcs_client:</p>
<p>_global_worker.gcs_client.disconnect()</p>
<h1>Step 5: Cleanup local services if running standalone</h1>
<p>if _global_node:</p>
<p>_global_node.kill_all_processes()</p>
<p></code></p>
<h2>Communication Mechanisms</h2>
<p>----------------------------------------</p>
<p>The Ray driver uses multiple communication channels optimized for different types of operations:</p>
<h3>1. Driver-to-GCS Communication</h3>
<p>Purpose: Cluster metadata, actor lifecycle, job management</p>
<p>[Diagram content removed for EPUB version]</p>
<p>Code Example - GCS Client:</p>
<code>// From src/ray/gcs/gcs_client/gcs_client.h
<p>class GcsClient {</p>
<p>public:</p>
<p>/// Create an actor via GCS</p>
<p>Status CreateActor(const TaskSpec &amp;task_spec,</p>
<p>const gcs::ActorCreationOptions &amp;options,</p>
<p>std::vector&lt;rpc::ObjectReference&gt; *returned_refs) {</p>
<p>rpc::CreateActorRequest request;</p>
<p>request.mutable_task_spec()-&gt;CopyFrom(task_spec.GetMessage());</p>
<p>request.mutable_options()-&gt;CopyFrom(options);</p>
<p>return actor_accessor_-&gt;AsyncCreateActor(</p>
<p>request,</p>
<p>[this, returned_refs](Status status, const rpc::CreateActorReply &amp;reply) {</p>
<p>if (status.ok()) {</p>
<p>// Extract actor handle and return references</p>
<p>for (const auto &amp;ref : reply.returned_refs()) {</p>
<p>returned_refs-&gt;push_back(ref);</p>
<p>}</p>
<p>}</p>
<p>});</p>
<p>}</p>
<p>};</p>
<p></code></p>
<h3>2. Driver-to-Raylet Communication</h3>
<p>Purpose: Task submission, resource requests, local scheduling</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>3. Driver-to-Object Store Communication</h3>
<p>Purpose: High-bandwidth data transfer, shared memory access</p>
<p>The driver accesses the object store through optimized shared memory interfaces:</p>
<code>// From src/ray/object_store/plasma/client.h
<p>class PlasmaClient {</p>
<p>public:</p>
<p>/// Get objects from local object store</p>
<p>Status Get(const std::vector&lt;ObjectID&gt; &amp;object_ids,</p>
<p>int64_t timeout_ms,</p>
<p>std::vector&lt;ObjectBuffer&gt; *object_buffers) {</p>
<p>// Step 1: Check local availability</p>
<p>std::vector&lt;plasma::ObjectBuffer&gt; results(object_ids.size());</p>
<p>// Step 2: Wait for objects if needed</p>
<p>Status wait_status = impl_-&gt;Wait(object_ids, timeout_ms, &amp;results);</p>
<p>// Step 3: Map shared memory segments</p>
<p>for (size_t i = 0; i &lt; results.size(); i++) {</p>
<p>if (results[i].data != nullptr) {</p>
<p>object_buffers-&gt;emplace_back(results[i].data, results[i].data_size);</p>
<p>}</p>
<p>}</p>
<p>return wait_status;</p>
<p>}</p>
<p>/// Put object into local object store  </p>
<p>Status Put(const ray::ObjectID &amp;object_id,</p>
<p>const uint8_t *data,</p>
<p>size_t data_size) {</p>
<p>// Step 1: Create plasma object</p>
<p>std::shared_ptr&lt;Buffer&gt; buffer;</p>
<p>Status create_status = impl_-&gt;Create(object_id, data_size, &amp;buffer);</p>
<p>// Step 2: Copy data into shared memory</p>
<p>std::memcpy(buffer-&gt;mutable_data(), data, data_size);</p>
<p>// Step 3: Seal object (make immutable)</p>
<p>return impl_-&gt;Seal(object_id);</p>
<p>}</p>
<p>};</p>
<p></code></p>
<h2>Driver-GCS Integration</h2>
<p>----------------------------------------</p>
<p>The Global Control Service (GCS) acts as the cluster's "central nervous system" and the driver maintains a close relationship with it:</p>
<h3>Actor Lifecycle Management</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Job Management and Driver Registration</h3>
<code>// From src/ray/gcs/gcs_server/gcs_job_manager.h
<p>class GcsJobManager {</p>
<p>public:</p>
<p>/// Register a new driver/job with the cluster</p>
<p>void HandleAddJob(const rpc::AddJobRequest &amp;request,</p>
<p>rpc::AddJobReply *reply,</p>
<p>rpc::SendReplyCallback send_reply_callback) {</p>
<p>// Extract job information</p>
<p>const auto &amp;job_data = request.data();</p>
<p>const JobID job_id = JobID::FromBinary(job_data.job_id());</p>
<p>// Store job metadata</p>
<p>auto job_table_data = std::make_shared&lt;rpc::JobTableData&gt;();</p>
<p>job_table_data-&gt;CopyFrom(job_data);</p>
<p>// Add to job table in persistent store</p>
<p>auto status = gcs_table_storage_-&gt;JobTable().Put(</p>
<p>job_id,</p>
<p>*job_table_data,</p>
<p>[send_reply_callback, reply](Status status) {</p>
<p>reply-&gt;set_success(status.ok());</p>
<p>send_reply_callback(status, nullptr, nullptr);</p>
<p>});</p>
<p>}</p>
<p>};</p>
<p></code></p>
<h3>Resource Management Integration</h3>
<p>The driver coordinates with GCS for cluster-wide resource management:</p>
<code># Example: Driver requesting specific resources
<p>@ray.remote(num_cpus=4, num_gpus=1, memory=8000)</p>
<p>def gpu_task(data):</p>
<h1>This task needs specific resources</h1>
<p>return process_on_gpu(data)</p>
<h1>Behind the scenes, the driver:</h1>
<h1>1. Registers resource requirements with GCS</h1>
<h1>2. GCS finds nodes with available resources  </h1>
<h1>3. GCS tells raylet to schedule the task</h1>
<h1>4. Raylet allocates resources and starts worker</h1>
<p></code></p>
<h2>Code Navigation Guide</h2>
<p>----------------------------------------</p>
<h3>Key Entry Points for Driver Functionality</h3>
<h4>1. Python API Layer</h4>
Location: <code>python/ray/_private/worker.py</code>
<p>This is where the user-facing Ray API is implemented:</p>
<code># Main initialization
<p>def init(...) -&gt; ray.init()</p>
<h1>Task submission  </h1>
<p>class RemoteFunction:</p>
<p>def remote(self, *args, **kwargs) -&gt; ObjectRef</p>
<h1>Object operations</h1>
<p>def get(object_refs, timeout=None) -&gt; ray.get()</p>
<p>def put(value) -&gt; ray.put()</p>
<p>def wait(object_refs, num_returns=1, timeout=None) -&gt; ray.wait()</p>
<p></code></p>
<h4>2. CoreWorker Implementation</h4>
Location: <code>src/ray/core_worker/core_worker.{h,cc}</code>
<p>The main C++ driver implementation:</p>
<code>// Key methods for understanding driver behavior:
<p>Status CoreWorker::SubmitTask(...)        // Task submission logic</p>
<p>Status CoreWorker::CreateActor(...)       // Actor creation logic  </p>
<p>Status CoreWorker::Get(...)               // Object retrieval logic</p>
<p>Status CoreWorker::Put(...)               // Object storage logic</p>
<p></code></p>
<h4>3. Task and Actor Management</h4>
Location: <code>src/ray/core_worker/task_manager.{h,cc}</code> and <code>src/ray/core_worker/actor_manager.{h,cc}</code>
<code>class TaskManager {
<p>void AddPendingTask(...)               // Track submitted tasks</p>
<p>void CompletePendingTask(...)          // Handle task completion</p>
<p>void FailPendingTask(...)              // Handle task failures</p>
<p>};</p>
<p>class ActorManager {</p>
<p>Status CreateActor(...)                // Actor lifecycle start</p>
<p>Status SubmitActorTask(...)            // Send methods to actors</p>
<p>void HandleActorStateNotification(...) // React to actor events</p>
<p>};</p>
<p></code></p>
<h4>4. Communication Layers</h4>
Location: <code>src/ray/rpc/</code> and <code>src/ray/core_worker/transport/</code>
<code>// GCS communication
<p>class GcsClient : public GcsClientInterface {...}</p>
<p>// Raylet communication  </p>
<p>class CoreWorkerRayletTaskSubmitter {...}</p>
<p>// Direct worker communication</p>
<p>class CoreWorkerDirectTaskSubmitter {...}</p>
<p></code></p>
<h3>Debugging and Instrumentation Points</h3>
<h4>1. Driver State Inspection</h4>
<pre><code><code># Get current driver state
import ray
worker = ray._private.worker.global_worker
<h1>View pending tasks</h1>
print(f&quot;Pending tasks: {len(worker.core_worker.get_all_pending_tasks())}&quot;)
<h1>View actor handles  </h1>
print(f&quot;Actor handles: {len(worker.actor_handles)}&quot;)
<h1>View object references</h1>
print(f&quot;Object refs in scope: {worker.core_worker.get_objects_in_scope()}&quot;)
</code></code></pre>
<h4>2. Enable Detailed Logging</h4>
<pre><code><code>import logging
logging.getLogger(&quot;ray.core_worker&quot;).setLevel(logging.DEBUG)
logging.getLogger(&quot;ray.gcs_client&quot;).setLevel(logging.DEBUG)
</code></code></pre>
<h4>3. Ray Status and Debugging Tools</h4>
<pre><code><code># View cluster state from driver perspective
ray status
<h1>Get detailed driver information</h1>
ray logs --actor-id &lt;driver-worker-id&gt;
<h1>Monitor object references</h1>
ray memory --stats-only
</code></code></pre>
<p>This comprehensive guide provides the foundation for understanding Ray's driver implementation. The driver serves as the central coordinator for distributed Ray applications, managing task submission, actor lifecycles, object references, and communication with cluster services through sophisticated APIs and communication protocols.</p>

<div class="page-break"></div>
<h1>Part I: Ray Fundamentals</h1>
<p>============================================================</p>
<h1>Chapter 3: Task Lifecycle and Management</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Task Architecture Overview</p>
<p>‚Ä¢ Task Creation and Submission</p>
<p>‚Ä¢ Task Scheduling and Placement</p>
<p>‚Ä¢ Task Execution Engine</p>
<p>‚Ä¢ Task Dependencies and Lineage</p>
<p>‚Ä¢ Error Handling and Retry Logic</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code Navigation Guide</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>Ray tasks are the fundamental units of computation in the Ray ecosystem. Think of a task as a function call that can run anywhere in your cluster - it could execute on your local machine, a machine in another data center, or even on a different cloud provider. Tasks are stateless, immutable, and designed for maximum parallelism.</p>
<h3>What Makes Ray Tasks Special?</h3>
<p>Stateless Execution: Tasks don't maintain state between calls, making them easy to distribute, retry, and scale horizontally.</p>
<p>Automatic Parallelism: When you call a remote function, Ray automatically distributes the work across available workers without you having to think about threads, processes, or network communication.</p>
<p>Fault Tolerance: If a task fails, Ray can automatically retry it on different machines, ensuring your computation completes even in the face of hardware failures.</p>
<p>Efficient Data Sharing: Tasks can share large datasets efficiently through Ray's distributed object store without copying data unnecessarily.</p>
<h3>Core Task Concepts</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Task Architecture Overview</h2>
<p>----------------------------------------</p>
<h3>High-Level Task System Architecture</h3>
<p>Ray's task system is built on multiple layers that handle different aspects of distributed task execution:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Task vs Actor Comparison</h3>
<p>Understanding the differences between tasks and actors is crucial for designing Ray applications:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Task Creation and Submission</h2>
<p>----------------------------------------</p>
<h3>Phase 1: Function Registration</h3>
When you decorate a function with <code>@ray.remote</code>, Ray prepares it for distributed execution:
<code># User code
<p>@ray.remote(num_cpus=2, memory=1000)</p>
<p>def process_data(data_chunk, model_params):</p>
<p>&quot;&quot;&quot;Example computation-intensive task&quot;&quot;&quot;</p>
<p>import numpy as np</p>
<h1>Simulate data processing</h1>
<p>processed = np.array(data_chunk) * np.array(model_params)</p>
<p>result = np.sum(processed ** 2)</p>
<p>return {</p>
<p>'result': result,</p>
<p>'chunk_size': len(data_chunk),</p>
<p>'processing_time': time.time()</p>
<p>}</p>
<h1>Submit tasks</h1>
<p>data_chunks = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]</p>
<p>model_params = [0.1, 0.2, 0.3]</p>
<h1>These calls return immediately with ObjectRefs</h1>
<p>futures = [process_data.remote(chunk, model_params) for chunk in data_chunks]</p>
<h1>Retrieve results when needed</h1>
<p>results = ray.get(futures)</p>
<p></code></p>
<p>Behind the Scenes - Function Registration:</p>
<code># From python/ray/_private/worker.py
<p>def make_function_remote(function, num_cpus, num_gpus, memory, **kwargs):</p>
<p>&quot;&quot;&quot;Convert a regular function into a Ray remote function.&quot;&quot;&quot;</p>
<h1>Step 1: Create function metadata</h1>
<p>function_id = compute_function_id(function)</p>
<h1>Step 2: Register function with driver's core worker</h1>
<p>driver_worker = ray._private.worker.global_worker</p>
<p>driver_worker.function_actor_manager.export_function(</p>
<p>function, function_id, num_cpus, num_gpus, memory)</p>
<h1>Step 3: Create remote function wrapper</h1>
<p>def remote(*args, **kwargs):</p>
<p>return RemoteFunction._remote(</p>
<p>args=args, kwargs=kwargs,</p>
<p>num_cpus=num_cpus, num_gpus=num_gpus, memory=memory)</p>
<h1>Step 4: Return enhanced function</h1>
<p>function.remote = remote</p>
<p>return function</p>
<p></code></p>
<h3>Phase 2: Task Specification Creation</h3>
When you call <code>function.remote()</code>, Ray creates a detailed task specification:
<p>[Diagram content removed for EPUB version]</p>
<p>Detailed Task Specification Code:</p>
<code>// From src/ray/core_worker/core_worker.cc
<p>Status CoreWorker::SubmitTask(const RayFunction &amp;function,</p>
<p>const std::vector&lt;std::unique_ptr&lt;TaskArg&gt;&gt; &amp;args,</p>
<p>const TaskOptions &amp;task_options,</p>
<p>std::vector&lt;rpc::ObjectReference&gt; *returned_refs) {</p>
<p>// Step 1: Generate unique task ID</p>
<p>const TaskID task_id = TaskID::FromRandom();</p>
<p>// Step 2: Build comprehensive task specification</p>
<p>TaskSpecBuilder builder;</p>
<p>builder.SetCommonTaskSpec(</p>
<p>task_id,                                    // Unique identifier</p>
<p>function.GetLanguage(),                     // Python/Java/C++</p>
<p>function.GetFunctionDescriptor(),           // Function metadata</p>
<p>job_id_,                                    // Current job</p>
<p>TaskID::Nil(),                             // Parent task (for nested)</p>
<p>/*parent_counter=*/0,                      // Ordering within parent</p>
<p>caller_id_,                                // Calling worker ID</p>
<p>rpc_address_,                              // Return address</p>
<p>task_options.resources,                    // Resource requirements</p>
<p>task_options.placement_group_bundle_index  // Placement constraints</p>
<p>);</p>
<p>// Step 3: Process function arguments</p>
<p>for (size_t i = 0; i &lt; args.size(); i++) {</p>
<p>const auto &amp;arg = args[i];</p>
<p>if (arg-&gt;IsPassedByReference()) {</p>
<p>// Argument is an ObjectRef from another task</p>
<p>builder.AddByRefArg(arg-&gt;GetReference());</p>
<p>} else {</p>
<p>// Argument is a direct value (serialized)</p>
<p>builder.AddByValueArg(*arg-&gt;GetValue());</p>
<p>}</p>
<p>}</p>
<p>const TaskSpec task_spec = builder.Build();</p>
<p>// Step 4: Create return object references</p>
<p>for (int i = 0; i &lt; task_spec.NumReturns(); i++) {</p>
<p>returned_refs-&gt;emplace_back();</p>
<p>returned_refs-&gt;back().set_object_id(</p>
<p>ObjectID::FromIndex(task_id, i + 1).Binary());</p>
<p>returned_refs-&gt;back().set_owner_id(GetWorkerID().Binary());</p>
<p>}</p>
<p>// Step 5: Submit to task manager for tracking</p>
<p>task_manager_-&gt;AddPendingTask(task_id, task_spec, &quot;user_task&quot;);</p>
<p>// Step 6: Forward to appropriate scheduler</p>
<p>return raylet_client_-&gt;SubmitTask(task_spec, &quot;&quot;);</p>
<p>}</p>
<p></code></p>
<h3>Phase 3: Argument Processing and Serialization</h3>
<p>Ray carefully handles different types of task arguments:</p>
<code># Example: Different argument types
<p>@ray.remote</p>
<p>def complex_task(</p>
<p>simple_value,          # Serialized directly</p>
<p>numpy_array,           # Efficient serialization</p>
<p>object_ref,            # Reference to distributed object</p>
<p>large_dataset,         # Stored in object store</p>
<p>custom_object          # User-defined class</p>
<p>):</p>
<h1>Function body</h1>
<p>pass</p>
<h1>Different ways to pass arguments</h1>
<p>simple_result = ray.put(&quot;large data&quot;)                    # Explicit put</p>
<p>array_result = other_task.remote()                       # Task dependency</p>
<p>large_data = np.random.random((1000000,))               # Auto-stored</p>
<h1>All argument types in one call</h1>
<p>result = complex_task.remote(</p>
<p>42,                    # Simple value</p>
<p>np.array([1, 2, 3]),  # Small array (serialized)</p>
<p>array_result,          # ObjectRef dependency</p>
<p>large_data,            # Large data (auto-put)</p>
<p>MyCustomClass()        # Custom object</p>
<p>)</p>
<p></code></p>
<p>Argument Processing Logic:</p>
<code>// From src/ray/core_worker/core_worker.cc
<p>std::unique_ptr&lt;TaskArg&gt; CreateTaskArg(const py::object &amp;obj) {</p>
<p>// Check if object is already an ObjectRef</p>
<p>if (IsObjectRef(obj)) {</p>
<p>ObjectID object_id = GetObjectID(obj);</p>
<p>return std::make_unique&lt;TaskArgByReference&gt;(object_id);</p>
<p>}</p>
<p>// Check object size to decide on storage strategy</p>
<p>size_t serialized_size = GetSerializedSize(obj);</p>
<p>if (serialized_size &gt; kObjectStoreThreshold) {</p>
<p>// Large object: store in object store and pass by reference</p>
<p>ObjectID object_id;</p>
<p>Status status = Put(obj, &amp;object_id);</p>
<p>RAY_CHECK_OK(status);</p>
<p>return std::make_unique&lt;TaskArgByReference&gt;(object_id);</p>
<p>} else {</p>
<p>// Small object: serialize and pass by value</p>
<p>auto serialized_obj = SerializeObject(obj);</p>
<p>return std::make_unique&lt;TaskArgByValue&gt;(std::move(serialized_obj));</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h2>Task Scheduling and Placement</h2>
<p>----------------------------------------</p>
<h3>Cluster-Level Task Scheduling</h3>
<p>Ray's task scheduler makes intelligent decisions about where to run tasks:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Local Task Scheduling (Raylet)</h3>
<p>Once a task arrives at a raylet, local scheduling decisions are made:</p>
<code>// From src/ray/raylet/local_task_manager.cc
<p>void LocalTaskManager::ScheduleAndDispatchTasks() {</p>
<p>// Step 1: Process tasks waiting for dependencies</p>
<p>SchedulePendingTasks();</p>
<p>// Step 2: Dispatch ready tasks to workers</p>
<p>DispatchScheduledTasksToWorkers();</p>
<p>// Step 3: Handle task completion and cleanup</p>
<p>ProcessTaskCompletion();</p>
<p>}</p>
<p>void LocalTaskManager::SchedulePendingTasks() {</p>
<p>auto it = tasks_to_schedule_.begin();</p>
<p>while (it != tasks_to_schedule_.end()) {</p>
<p>const auto &amp;task_id = it-&gt;first;</p>
<p>const auto &amp;task_spec = it-&gt;second;</p>
<p>// Check if all dependencies are satisfied</p>
<p>if (task_dependency_manager_-&gt;CheckTaskReady(task_id)) {</p>
<p>// Check if resources are available</p>
<p>if (cluster_resource_scheduler_-&gt;HasSufficientResource(</p>
<p>task_spec.GetRequiredResources())) {</p>
<p>// Move to dispatch queue</p>
<p>tasks_to_dispatch_[task_id] = task_spec;</p>
<p>it = tasks_to_schedule_.erase(it);</p>
<p>// Reserve resources for this task</p>
<p>cluster_resource_scheduler_-&gt;AllocateTaskResources(</p>
<p>task_id, task_spec.GetRequiredResources());</p>
<p>} else {</p>
<p>++it;  // Keep waiting for resources</p>
<p>}</p>
<p>} else {</p>
<p>++it;  // Keep waiting for dependencies</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h3>Intelligent Worker Selection</h3>
<p>The scheduler considers multiple factors when selecting workers:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Task Execution Engine</h2>
<p>----------------------------------------</p>
<h3>Worker Process Task Execution</h3>
<p>Once a task is assigned to a worker, a sophisticated execution engine takes over:</p>
<p>[Diagram content removed for EPUB version]</p>
<p>Task Execution Implementation:</p>
<code># From python/ray/_private/worker.py (worker process)
<p>class TaskExecutor:</p>
<p>def execute_task(self, task_spec, task_execution_spec):</p>
<p>&quot;&quot;&quot;Execute a single task in the worker process.&quot;&quot;&quot;</p>
<h1>Step 1: Extract task information</h1>
<p>function_descriptor = task_spec.function_descriptor</p>
<p>args = task_spec.args</p>
<p>task_id = task_spec.task_id</p>
<h1>Step 2: Resolve function from registry</h1>
<p>function = worker.function_actor_manager.get_function(function_descriptor)</p>
<h1>Step 3: Resolve input arguments</h1>
<p>resolved_args = []</p>
<p>for arg in args:</p>
<p>if arg.is_by_ref:</p>
<h1>Resolve ObjectRef to actual value</h1>
<p>obj = ray.get(ObjectRef(arg.object_ref.object_id))</p>
<p>resolved_args.append(obj)</p>
<p>else:</p>
<h1>Deserialize direct value</h1>
<p>obj = ray._private.serialization.deserialize(arg.data)</p>
<p>resolved_args.append(obj)</p>
<h1>Step 4: Execute the function</h1>
<p>try:</p>
<p>with ray._private.profiling.profile_task(task_id):</p>
<p>result = function(*resolved_args)</p>
<h1>Step 5: Store result in object store</h1>
<p>if isinstance(result, tuple):</p>
<h1>Multiple return values</h1>
<p>return_refs = []</p>
<p>for i, ret_val in enumerate(result):</p>
<p>object_id = ObjectID.from_task_and_index(task_id, i + 1)</p>
<p>ray.put(ret_val, object_id=object_id)</p>
<p>return_refs.append(object_id)</p>
<p>return return_refs</p>
<p>else:</p>
<h1>Single return value</h1>
<p>object_id = ObjectID.from_task_and_index(task_id, 1)</p>
<p>ray.put(result, object_id=object_id)</p>
<p>return [object_id]</p>
<p>except Exception as e:</p>
<h1>Handle task execution error</h1>
<p>error_info = TaskExecutionError(e, traceback.format_exc())</p>
<p>self._store_task_error(task_id, error_info)</p>
<p>raise</p>
<p></code></p>
<h3>Dependency Resolution System</h3>
<p>Ray automatically resolves task dependencies before execution:</p>
<code># Example: Complex dependency chain
<p>@ray.remote</p>
<p>def load_data(filename):</p>
<p>&quot;&quot;&quot;Load data from file&quot;&quot;&quot;</p>
<p>import pandas as pd</p>
<p>return pd.read_csv(filename)</p>
<p>@ray.remote  </p>
<p>def preprocess_data(data):</p>
<p>&quot;&quot;&quot;Clean and prepare data&quot;&quot;&quot;</p>
<h1>Remove nulls, normalize, etc.</h1>
<p>cleaned = data.dropna()</p>
<p>normalized = (cleaned - cleaned.mean()) / cleaned.std()</p>
<p>return normalized</p>
<p>@ray.remote</p>
<p>def train_model(train_data, test_data):</p>
<p>&quot;&quot;&quot;Train ML model&quot;&quot;&quot;</p>
<p>from sklearn.linear_model import LinearRegression</p>
<p>model = LinearRegression()</p>
<p>model.fit(train_data[['feature1', 'feature2']], train_data['target'])</p>
<p>score = model.score(test_data[['feature1', 'feature2']], test_data['target'])</p>
<p>return {'model': model, 'score': score}</p>
<p>@ray.remote</p>
<p>def evaluate_model(model_data, validation_data):</p>
<p>&quot;&quot;&quot;Evaluate trained model&quot;&quot;&quot;</p>
<p>model = model_data['model']</p>
<p>predictions = model.predict(validation_data[['feature1', 'feature2']])</p>
<p>accuracy = calculate_accuracy(predictions, validation_data['target'])</p>
<p>return accuracy</p>
<h1>Create dependency graph automatically</h1>
<p>raw_train = load_data.remote(&quot;train.csv&quot;)        # Independent</p>
<p>raw_test = load_data.remote(&quot;test.csv&quot;)          # Independent  </p>
<p>raw_val = load_data.remote(&quot;validation.csv&quot;)    # Independent</p>
<p>clean_train = preprocess_data.remote(raw_train)  # Depends on raw_train</p>
<p>clean_test = preprocess_data.remote(raw_test)    # Depends on raw_test</p>
<p>clean_val = preprocess_data.remote(raw_val)      # Depends on raw_val</p>
<p>model_result = train_model.remote(clean_train, clean_test)  # Depends on both</p>
<p>final_accuracy = evaluate_model.remote(model_result, clean_val)  # Depends on all</p>
<h1>Ray automatically manages the entire dependency graph</h1>
<p>print(f&quot;Final model accuracy: {ray.get(final_accuracy)}&quot;)</p>
<p></code></p>
<h2>Task Dependencies and Lineage</h2>
<p>----------------------------------------</p>
<h3>Dependency Graph Management</h3>
<p>Ray maintains a sophisticated dependency graph for tasks:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Lineage Tracking and Fault Tolerance</h3>
<p>Ray tracks the complete lineage of objects to enable fault tolerance:</p>
<code>// From src/ray/core_worker/reference_count.h
<p>class ReferenceCounter {</p>
<p>private:</p>
<p>// Maps object ID to its lineage information</p>
<p>absl::flat_hash_map&lt;ObjectID, ObjectLineage&gt; object_lineage_map_;</p>
<p>// Maps object ID to the task that created it</p>
<p>absl::flat_hash_map&lt;ObjectID, TaskID&gt; object_to_task_map_;</p>
<p>public:</p>
<p>/// Add lineage information when object is created</p>
<p>void AddObjectLineage(const ObjectID &amp;object_id,</p>
<p>const TaskID &amp;task_id,</p>
<p>const std::vector&lt;ObjectID&gt; &amp;dependencies) {</p>
<p>ObjectLineage lineage;</p>
<p>lineage.task_id = task_id;</p>
<p>lineage.dependencies = dependencies;</p>
<p>lineage.creation_time = absl::Now();</p>
<p>object_lineage_map_[object_id] = lineage;</p>
<p>object_to_task_map_[object_id] = task_id;</p>
<p>}</p>
<p>/// Reconstruct object by re-executing its task</p>
<p>Status ReconstructObject(const ObjectID &amp;object_id) {</p>
<p>auto it = object_lineage_map_.find(object_id);</p>
<p>if (it == object_lineage_map_.end()) {</p>
<p>return Status::NotFound(&quot;Object lineage not found&quot;);</p>
<p>}</p>
<p>const auto &amp;lineage = it-&gt;second;</p>
<p>// First ensure all dependencies are available</p>
<p>for (const auto &amp;dep_id : lineage.dependencies) {</p>
<p>if (!IsObjectAvailable(dep_id)) {</p>
<p>// Recursively reconstruct dependencies</p>
<p>auto status = ReconstructObject(dep_id);</p>
<p>if (!status.ok()) {</p>
<p>return status;</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p>// Re-execute the task that created this object</p>
<p>return ReExecuteTask(lineage.task_id);</p>
<p>}</p>
<p>};</p>
<p></code></p>
<p>This comprehensive guide covers the essential aspects of Ray's task system, from creation through execution to fault tolerance. Tasks form the foundation of Ray's distributed computing model, enabling scalable and fault-tolerant parallel computation.</p>

<div class="page-break"></div>
<h1>Part I: Ray Fundamentals</h1>
<p>============================================================</p>
<h1>Chapter 4: Actor Lifecycle and Management</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Actor Architecture Overview</p>
<p>‚Ä¢ Actor Creation Deep Dive</p>
<p>‚Ä¢ Method Invocation and Execution</p>
<p>‚Ä¢ Fault Tolerance and Recovery</p>
<p>‚Ä¢ Performance Optimization</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>Ray actors are long-running, stateful workers that live somewhere in your cluster and can be called like remote objects. Think of an actor as a combination of a server process and a Python object - it has its own memory, state, and can handle multiple requests over time.</p>
<h3>What Makes Ray Actors Special?</h3>
<p>Stateful Distributed Computing: Unlike functions that are stateless, actors maintain state between calls. Imagine having a database connection, machine learning model, or game state that persists across multiple operations.</p>
<p>Location Transparency: You interact with actors using handles that look like regular Python objects, even though the actor might be running on a machine thousands of miles away.</p>
<h3>Core Actor Concepts</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Actor Architecture Overview</h2>
<p>----------------------------------------</p>
<h3>High-Level Actor System Architecture</h3>
<p>Ray's actor system is built on several layers that work together to provide the illusion of stateful, distributed objects:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Actor Creation Deep Dive</h2>
<p>----------------------------------------</p>
<h3>Phase 1: Actor Definition and Registration</h3>
<p>When you define an actor class, Ray prepares it for distributed execution:</p>
<code># User code
<p>@ray.remote(num_cpus=2, num_gpus=1)</p>
<p>class GameServer:</p>
<p>def __init__(self, max_players=100):</p>
<p>self.players = {}</p>
<p>self.max_players = max_players</p>
<p>self.game_state = &quot;waiting&quot;</p>
<p>def add_player(self, player_id, player_data):</p>
<p>if len(self.players) &lt; self.max_players:</p>
<p>self.players[player_id] = player_data</p>
<p>return True</p>
<p>return False</p>
<h1>Create actor instance</h1>
<p>game_server = GameServer.remote(max_players=50)</p>
<p></code></p>
<p>Behind the Scenes - Class Registration:</p>
<code># From python/ray/_private/worker.py
<p>def make_actor(cls, num_cpus, num_gpus, memory, **kwargs):</p>
<p>&quot;&quot;&quot;Convert a regular class into a Ray actor class.&quot;&quot;&quot;</p>
<h1>Step 1: Create actor class metadata</h1>
<p>class_id = compute_class_id(cls)</p>
<h1>Step 2: Register class with driver's core worker</h1>
<p>driver_worker = ray._private.worker.global_worker</p>
<p>driver_worker.function_actor_manager.export_actor_class(</p>
<p>cls, class_id, num_cpus, num_gpus, memory)</p>
<h1>Step 3: Create actor handle factory</h1>
<p>def remote(*args, **kwargs):</p>
<p>return ActorHandle._remote(args=args, kwargs=kwargs)</p>
<h1>Step 4: Return modified class with remote() method</h1>
<p>cls.remote = remote</p>
<p>return cls</p>
<p></code></p>
<h3>Phase 2: Actor Instance Creation</h3>
When you call <code>ClassName.remote()</code>, a complex creation process begins:
<p>[Diagram content removed for EPUB version]</p>
<p>Detailed Actor Creation Code:</p>
<code>// From src/ray/core_worker/core_worker.cc
<p>Status CoreWorker::CreateActor(const RayFunction &amp;function,</p>
<p>const std::vector&lt;std::unique_ptr&lt;TaskArg&gt;&gt; &amp;args,</p>
<p>const ActorCreationOptions &amp;actor_creation_options,</p>
<p>std::vector&lt;rpc::ObjectReference&gt; *returned_refs) {</p>
<p>// Step 1: Generate unique actor ID  </p>
<p>const ActorID actor_id = ActorID::FromRandom();</p>
<p>// Step 2: Build actor creation task spec</p>
<p>TaskSpecBuilder builder;</p>
<p>builder.SetActorCreationTask(</p>
<p>actor_id, function, args,</p>
<p>actor_creation_options.max_restarts,</p>
<p>actor_creation_options.resources);</p>
<p>const TaskSpec task_spec = builder.Build();</p>
<p>// Step 3: Register with actor manager for tracking</p>
<p>actor_manager_-&gt;RegisterActorHandle(actor_id, task_spec);</p>
<p>// Step 4: Submit to GCS for global scheduling</p>
<p>return gcs_client_-&gt;actor_accessor_-&gt;AsyncCreateActor(task_spec);</p>
<p>}</p>
<p></code></p>
<h2>Method Invocation and Execution</h2>
<p>----------------------------------------</p>
<h3>Method Call Flow</h3>
<p>When you call a method on an actor handle, a sophisticated routing and execution process occurs:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Method Execution Engine</h3>
<p>Inside the actor worker, methods are executed by a specialized runtime:</p>
<code># From python/ray/_private/worker.py (actor worker execution)
<p>class ActorMethodExecutor:</p>
<p>def __init__(self, actor_instance):</p>
<p>self.actor_instance = actor_instance</p>
<p>self.method_queue = queue.Queue()</p>
<p>def _execute_methods(self):</p>
<p>&quot;&quot;&quot;Main execution loop for actor methods&quot;&quot;&quot;</p>
<p>while True:</p>
<p>try:</p>
<h1>Get next method call</h1>
<p>method_call = self.method_queue.get()</p>
<p>if method_call is None:  # Shutdown signal</p>
<p>break</p>
<h1>Extract method info</h1>
<p>method_name = method_call.function_name</p>
<p>args = method_call.args</p>
<p>kwargs = method_call.kwargs</p>
<h1>Execute method on actor instance</h1>
<p>method = getattr(self.actor_instance, method_name)</p>
<p>result = method(*args, **kwargs)</p>
<h1>Store result in object store</h1>
<p>self._store_result(method_call.task_id, result)</p>
<p>except Exception as e:</p>
<h1>Handle method execution error</h1>
<p>self._store_error(method_call.task_id, e)</p>
<p></code></p>
<h2>Fault Tolerance and Recovery</h2>
<p>----------------------------------------</p>
<h3>Actor Restart Policies</h3>
<p>Ray provides sophisticated fault tolerance mechanisms for actors:</p>
<code># Different restart policies
<p>@ray.remote(max_restarts=3, max_task_retries=2)</p>
<p>class FaultTolerantActor:</p>
<p>def __init__(self):</p>
<p>self.state = {&quot;counter&quot;: 0, &quot;last_update&quot;: time.time()}</p>
<p>def increment(self):</p>
<p>self.state[&quot;counter&quot;] += 1</p>
<p>self.state[&quot;last_update&quot;] = time.time()</p>
<h1>Simulate occasional failures</h1>
<p>if random.random() &lt; 0.1:</p>
<p>raise Exception(&quot;Simulated failure&quot;)</p>
<p>return self.state[&quot;counter&quot;]</p>
<p></code></p>
<h3>Failure Detection and Recovery</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>This comprehensive guide covers the fundamental aspects of Ray's actor system. Actors provide a powerful abstraction for building stateful, distributed applications with strong consistency guarantees and fault tolerance features.</p>

<div class="page-break"></div>
<h1>Part I: Ray Fundamentals</h1>
<p>============================================================</p>
<h1>Chapter 5: Memory and Object Reference System</h1>
<p>============================================================</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>Ray's memory and object reference system is like having a distributed, shared memory across your entire cluster. Instead of copying data between machines, Ray creates smart "pointers" (ObjectRefs) that can reference data stored anywhere in the cluster. This enables efficient sharing of large datasets and computation results.</p>
<h3>What Makes Ray's Memory System Special?</h3>
<p>Zero-Copy Data Sharing: Large objects are stored once and referenced many times without copying.</p>
<p>Automatic Garbage Collection: Objects are cleaned up automatically when no longer needed.</p>
<p>Location Transparency: Your code doesn't need to know where data is physically stored.</p>
<p>Fault Tolerance: Objects can be reconstructed if they're lost due to node failures.</p>
<h2>Architecture Overview</h2>
<p>----------------------------------------</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Object References (ObjectRefs)</h2>
<p>----------------------------------------</p>
<h3>What is an ObjectRef?</h3>
<p>An ObjectRef is like a "smart pointer" that references data stored somewhere in your Ray cluster:</p>
<code>import ray
<p>import numpy as np</p>
<h1>Create a large dataset</h1>
<p>large_array = np.random.random((1000000, 100))</p>
<h1>Store in Ray's distributed object store</h1>
<p>object_ref = ray.put(large_array)</p>
<p>print(f&quot;ObjectRef: {object_ref}&quot;)</p>
<h1>Output: ObjectRef(c8ef45ccd0112571ffffffffffffffffffffffff01000000)</h1>
<h1>The actual data is stored in the cluster, not in this variable</h1>
<p>print(f&quot;ObjectRef size in memory: {sys.getsizeof(object_ref)} bytes&quot;)</p>
<h1>Output: ObjectRef size in memory: 56 bytes (just the reference!)</h1>
<h1>Retrieve the data when needed</h1>
<p>retrieved_array = ray.get(object_ref)</p>
<p>print(f&quot;Retrieved array shape: {retrieved_array.shape}&quot;)</p>
<h1>Output: Retrieved array shape: (1000000, 100)</h1>
<p></code></p>
<h3>ObjectRef Lifecycle</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Automatic Object Creation</h3>
<p>Objects are automatically stored when returned from remote functions:</p>
<code>@ray.remote
<p>def create_large_dataset():</p>
<h1>This creates a large object</h1>
<p>return np.random.random((100000, 1000))</p>
<p>@ray.remote</p>
<p>def process_dataset(data):</p>
<h1>Process the data</h1>
<p>return np.mean(data, axis=0)</p>
<h1>Object is automatically stored in object store</h1>
<p>dataset_ref = create_large_dataset.remote()  # Returns ObjectRef immediately</p>
<h1>Pass ObjectRef to another task (no data copying!)</h1>
<p>result_ref = process_dataset.remote(dataset_ref)</p>
<h1>Only retrieve when final result is needed</h1>
<p>final_result = ray.get(result_ref)</p>
<p></code></p>
<h2>Distributed Object Store</h2>
<p>----------------------------------------</p>
<h3>Plasma Object Store</h3>
<p>Ray uses Apache Plasma for high-performance object storage:</p>
<code>// From src/ray/object_store/plasma/client.h
<p>class PlasmaClient {</p>
<p>public:</p>
<p>/// Store an object in the plasma store</p>
<p>Status Put(const ObjectID &amp;object_id,</p>
<p>const uint8_t *data,</p>
<p>size_t data_size,</p>
<p>const uint8_t *metadata = nullptr,</p>
<p>size_t metadata_size = 0) {</p>
<p>// Step 1: Create plasma object buffer</p>
<p>std::shared_ptr&lt;Buffer&gt; buffer;</p>
<p>Status create_status = Create(object_id, data_size, &amp;buffer);</p>
<p>if (!create_status.ok()) {</p>
<p>return create_status;</p>
<p>}</p>
<p>// Step 2: Copy data into shared memory</p>
<p>std::memcpy(buffer-&gt;mutable_data(), data, data_size);</p>
<p>// Step 3: Seal object (make it immutable and available)</p>
<p>return Seal(object_id);</p>
<p>}</p>
<p>/// Get objects from the plasma store</p>
<p>Status Get(const std::vector&lt;ObjectID&gt; &amp;object_ids,</p>
<p>int64_t timeout_ms,</p>
<p>std::vector&lt;ObjectBuffer&gt; *object_buffers) {</p>
<p>// Wait for objects to become available</p>
<p>return impl_-&gt;Wait(object_ids, timeout_ms, object_buffers);</p>
<p>}</p>
<p>};</p>
<p></code></p>
<h3>Multi-Node Object Access</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Memory Management Patterns</h2>
<p>----------------------------------------</p>
<h3>Efficient Data Sharing</h3>
<code># Example: Sharing large datasets efficiently
<p>@ray.remote</p>
<p>def load_model():</p>
<p>&quot;&quot;&quot;Load a large ML model once&quot;&quot;&quot;</p>
<p>import joblib</p>
<p>model = joblib.load('large_model.pkl')  # 2GB model</p>
<p>return model</p>
<p>@ray.remote  </p>
<p>def predict_batch(model_ref, data_batch):</p>
<p>&quot;&quot;&quot;Use shared model for prediction&quot;&quot;&quot;</p>
<p>model = ray.get(model_ref)  # Gets reference, not copy</p>
<p>return model.predict(data_batch)</p>
<h1>Load model once, share across many tasks</h1>
<p>model_ref = load_model.remote()</p>
<h1>All tasks share the same model (no copying!)</h1>
<p>predictions = []</p>
<p>for batch in data_batches:</p>
<p>pred_ref = predict_batch.remote(model_ref, batch)</p>
<p>predictions.append(pred_ref)</p>
<p>results = ray.get(predictions)</p>
<p></code></p>
<h3>Memory-Efficient Processing</h3>
<pre><code><code># Memory-efficient processing of large datasets
@ray.remote
def process_chunk(data_chunk):
&quot;&quot;&quot;Process a chunk of data&quot;&quot;&quot;
<h1>Process data and return smaller result</h1>
processed = expensive_computation(data_chunk)
return summarize(processed)  # Return summary, not full data
<h1>Split large dataset into chunks</h1>
large_dataset = load_huge_dataset()  # 100GB dataset
chunk_size = len(large_dataset) // num_workers
chunk_refs = []
for i in range(0, len(large_dataset), chunk_size):
chunk = large_dataset[i:i + chunk_size]
chunk_ref = ray.put(chunk)  # Store chunk in object store
chunk_refs.append(chunk_ref)
<h1>Process chunks in parallel</h1>
result_refs = [process_chunk.remote(chunk_ref) for chunk_ref in chunk_refs]
<h1>Combine results (much smaller than original data)</h1>
results = ray.get(result_refs)
final_result = combine_results(results)
</code></code></pre>
<h2>Reference Counting and Garbage Collection</h2>
<p>----------------------------------------</p>
<h3>Automatic Cleanup</h3>
<p>Ray automatically cleans up objects when they're no longer needed:</p>
<code>// From src/ray/core_worker/reference_count.h
<p>class ReferenceCounter {</p>
<p>private:</p>
<p>// Track reference counts for each object</p>
<p>absl::flat_hash_map&lt;ObjectID, int&gt; object_ref_counts_;</p>
<p>// Track which worker owns each object</p>
<p>absl::flat_hash_map&lt;ObjectID, WorkerID&gt; object_owners_;</p>
<p>public:</p>
<p>/// Add a reference to an object</p>
<p>void AddObjectRef(const ObjectID &amp;object_id, const WorkerID &amp;owner_id) {</p>
<p>object_ref_counts_[object_id]++;</p>
<p>object_owners_[object_id] = owner_id;</p>
<p>}</p>
<p>/// Remove a reference to an object</p>
<p>void RemoveObjectRef(const ObjectID &amp;object_id) {</p>
<p>auto it = object_ref_counts_.find(object_id);</p>
<p>if (it != object_ref_counts_.end()) {</p>
<p>it-&gt;second--;</p>
<p>if (it-&gt;second == 0) {</p>
<p>// No more references - schedule for deletion</p>
<p>ScheduleObjectDeletion(object_id);</p>
<p>object_ref_counts_.erase(it);</p>
<p>object_owners_.erase(object_id);</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p>private:</p>
<p>void ScheduleObjectDeletion(const ObjectID &amp;object_id) {</p>
<p>// Send deletion request to object store</p>
<p>deletion_queue_.push(object_id);</p>
<p>}</p>
<p>};</p>
<p></code></p>
<h3>Manual Memory Management</h3>
<p>You can also manually control object lifecycle:</p>
<code>import ray
<h1>Create object</h1>
<p>data = ray.put(large_dataset)</p>
<h1>Use object</h1>
<p>result = process_data.remote(data)</p>
<p>final_result = ray.get(result)</p>
<h1>Manually delete when done (optional - Ray will do this automatically)</h1>
<p>del data  # Remove reference</p>
<p>ray.internal.free([data])  # Force cleanup</p>
<p></code></p>
<h2>Object Reconstruction and Fault Tolerance</h2>
<p>----------------------------------------</p>
<h3>Lineage-Based Recovery</h3>
<p>Ray can reconstruct lost objects using lineage information:</p>
<code># Example: Fault-tolerant computation chain
<p>@ray.remote</p>
<p>def step1():</p>
<p>return expensive_computation_1()</p>
<p>@ray.remote  </p>
<p>def step2(data1):</p>
<p>return expensive_computation_2(data1)</p>
<p>@ray.remote</p>
<p>def step3(data2):</p>
<p>return expensive_computation_3(data2)</p>
<h1>Build computation chain</h1>
<p>result1 = step1.remote()</p>
<p>result2 = step2.remote(result1)  </p>
<p>result3 = step3.remote(result2)</p>
<h1>If any intermediate result is lost due to node failure,</h1>
<h1>Ray can reconstruct it by re-running the necessary tasks</h1>
<p>final_result = ray.get(result3)  # Handles reconstruction transparently</p>
<p></code></p>
<h3>Reconstruction Process</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Performance Optimization</h2>
<p>----------------------------------------</p>
<h3>Object Store Memory Management</h3>
<code># Configure object store memory
<p>ray.init(object_store_memory=8_000_000_000)  # 8GB for object store</p>
<h1>Monitor object store usage</h1>
<p>print(ray.cluster_resources())</p>
<h1>Output: {'CPU': 8.0, 'memory': 16000000000, 'object_store_memory': 8000000000}</h1>
<h1>Check current object store usage</h1>
<p>import psutil</p>
<p>object_store_memory = ray._private.utils.get_system_memory() // 2</p>
<p>print(f&quot;Object store memory limit: {object_store_memory / 1e9:.1f} GB&quot;)</p>
<p></code></p>
<h3>Best Practices</h3>
<pre><code><code># 1. Use ray.put() for large objects used multiple times
large_model = load_model()
model_ref = ray.put(large_model)  # Store once
<h1>Use reference in multiple tasks</h1>
results = [predict.remote(model_ref, batch) for batch in batches]
<h1>2. Return smaller objects from tasks</h1>
@ray.remote
def process_large_data(big_data_ref):
big_data = ray.get(big_data_ref)
result = expensive_processing(big_data)
return summarize(result)  # Return summary, not full result
<h1>3. Use object references for intermediate results</h1>
@ray.remote
def pipeline_step1(data):
return process_step1(data)
@ray.remote  
def pipeline_step2(step1_result_ref):
<h1>Pass reference, not actual data</h1>
step1_result = ray.get(step1_result_ref)
return process_step2(step1_result)
</code></code></pre>
<p>This comprehensive guide covers Ray's sophisticated memory management system that enables efficient distributed computing with automatic garbage collection and fault tolerance.</p>

<div class="page-break"></div>
<h1>Part II: Core Ray Services</h1>
<p>============================================================</p>
<h1>Chapter 6: Global Control Service (GCS)</h1>
<p>============================================================</p>
<h1>Ray GCS Server: Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Architecture Overview</p>
<p>‚Ä¢ Core Components</p>
<p>‚Ä¢ Node Lifecycle Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Actor Management</p>
<p>‚Ä¢ Job Management</p>
<p>‚Ä¢ Storage and Persistence</p>
<p>‚Ä¢ Communication and RPC</p>
<p>‚Ä¢ Fault Tolerance and Recovery</p>
<p>‚Ä¢ Performance Characteristics</p>
<p>‚Ä¢ Implementation Details</p>
<p>‚Ä¢ Code Modification Guidelines</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The GCS (Global Control Service) server is the central coordination hub of a Ray cluster. It maintains authoritative global state about all cluster resources, nodes, actors, jobs, and placement groups. The GCS serves as the single source of truth for cluster-wide metadata and coordinates distributed operations across the entire Ray cluster.</p>
<h3>Key Responsibilities</h3>
<p>‚Ä¢ Node Registration and Health Monitoring: Track all nodes joining/leaving the cluster</p>
<p>‚Ä¢ Resource Management: Coordinate cluster-wide resource allocation and scheduling</p>
<p>‚Ä¢ Actor Management: Handle actor creation, placement, and lifecycle</p>
<p>‚Ä¢ Job Coordination: Manage job submission, tracking, and cleanup</p>
<p>‚Ä¢ Metadata Storage: Persist critical cluster state and configuration</p>
<p>‚Ä¢ Service Discovery: Provide endpoints for cluster services</p>
<h2>Architecture Overview</h2>
<p>----------------------------------------</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>GCS Server Design Principles</h3>
<p>‚Ä¢ Single Source of Truth: All authoritative cluster state lives in GCS</p>
<p>‚Ä¢ Event-Driven Architecture: State changes trigger cascading updates</p>
<p>‚Ä¢ Scalable Storage: Pluggable backend storage (Redis, Memory)</p>
<p>‚Ä¢ Fault Recovery: Persistent state enables cluster recovery</p>
<p>‚Ä¢ Performance Optimization: Caching and batching for high throughput</p>
<h2>Core Components</h2>
<p>----------------------------------------</p>
<p>The GCS server consists of several specialized managers working together:</p>
<h3>Component Initialization Order</h3>
From <code>src/ray/gcs/gcs_server/gcs_server.h:140-180</code>:
<p>[Diagram content removed for EPUB version]</p>
<h3>GCS Server Configuration</h3>
From <code>src/ray/gcs/gcs_server/gcs_server.h:47-62</code>:
<code>struct GcsServerConfig {
<p>std::string grpc_server_name = &quot;GcsServer&quot;;</p>
<p>uint16_t grpc_server_port = 0;               // GCS RPC port</p>
<p>uint16_t grpc_server_thread_num = 1;         // RPC thread pool size</p>
<p>std::string redis_username;                 // Redis authentication</p>
<p>std::string redis_password;</p>
<p>std::string redis_address;                  // Redis host address  </p>
<p>uint16_t redis_port = 6379;                 // Redis port</p>
<p>bool enable_redis_ssl = false;              // TLS encryption</p>
<p>bool retry_redis = true;                    // Connection retry logic</p>
<p>bool enable_sharding_conn = false;          // Redis sharding</p>
<p>std::string node_ip_address;                // GCS server IP</p>
<p>std::string log_dir;                        // Logging directory</p>
<p>std::string raylet_config_list;             // Raylet configurations</p>
<p>std::string session_name;                   // Cluster session ID</p>
<p>};</p>
<p></code></p>
<h2>Node Lifecycle Management</h2>
<p>----------------------------------------</p>
<p>The GCS Node Manager is responsible for tracking all nodes in the cluster and their health status.</p>
<h3>Node State Machine</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Node Registration Protocol</h3>
From <code>src/ray/gcs/gcs_server/gcs_node_manager.h:54-62</code>:
<p>[Diagram content removed for EPUB version]</p>
<p>Node Information Structure:</p>
<code>// From gcs.proto - rpc::GcsNodeInfo
<p>message GcsNodeInfo {</p>
<p>bytes node_id = 1;                    // Unique node identifier</p>
<p>string node_manager_address = 2;      // Node IP address</p>
<p>int32 node_manager_port = 3;         // Node manager port</p>
<p>int32 object_manager_port = 4;       // Object manager port</p>
<p>string node_name = 5;                // Human-readable name</p>
<p>map&lt;string, double&gt; resources_total = 6;  // Total node resources</p>
<p>GcsNodeState state = 7;              // Current node state</p>
<p>NodeDeathInfo death_info = 8;        // Death information if dead</p>
<p>int64 start_time_ms = 9;            // Node startup timestamp</p>
<p>}</p>
<p>enum GcsNodeState {</p>
<p>ALIVE = 0;      // Node operational</p>
<p>DEAD = 1;       // Node failed/removed</p>
<p>DRAINING = 2;   // Node shutting down gracefully</p>
<p>}</p>
<p></code></p>
<h3>Health Monitoring and Failure Detection</h3>
<p>Health Check Mechanisms:</p>
<p>‚Ä¢ Periodic Heartbeats: Raylets send regular health updates</p>
<p>‚Ä¢ Resource Reports: Nodes report resource usage changes</p>
<p>‚Ä¢ Task Status Updates: Monitor task execution health</p>
<p>‚Ä¢ Network Connectivity: Detect network partitions</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Resource Management</h2>
<p>----------------------------------------</p>
<p>The GCS Resource Manager maintains a global view of all cluster resources and coordinates scheduling decisions.</p>
<h3>Resource Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Resource Types and Management</h3>
<p>Core Resource Types:</p>
<code>// Resource categories managed by GCS
<p>enum ResourceType {</p>
<p>CPU,           // Compute cores</p>
<p>GPU,           // Graphics processors  </p>
<p>MEMORY,        // RAM allocation</p>
<p>OBJECT_STORE_MEMORY,  // Plasma store memory</p>
<p>CUSTOM         // User-defined resources</p>
<p>};</p>
<p>// Resource scheduling information</p>
<p>struct ResourceSchedulingState {</p>
<p>map&lt;string, double&gt; total;      // Total available resources</p>
<p>map&lt;string, double&gt; available;  // Currently available resources</p>
<p>map&lt;string, double&gt; used;       // Currently used resources</p>
<p>vector&lt;TaskSpec&gt; pending_tasks; // Tasks waiting for resources</p>
<p>};</p>
<p></code></p>
<h3>Resource Synchronization Protocol</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Actor Management</h2>
<p>----------------------------------------</p>
<p>The GCS Actor Manager handles the distributed coordination of Ray actors, including creation, placement, and lifecycle management.</p>
<h3>Actor Lifecycle Management</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Actor Creation Protocol</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Actor Placement Strategies</h3>
<p>Placement Group Integration:</p>
<code>// Actor placement within placement groups
<p>struct ActorPlacementSpec {</p>
<p>PlacementGroupID placement_group_id;    // Target placement group</p>
<p>int bundle_index;                       // Specific bundle in group</p>
<p>PlacementStrategy strategy;             // PACK, SPREAD, STRICT_PACK</p>
<p>map&lt;string, double&gt; resource_requirements;  // Resource needs</p>
<p>vector&lt;NodeID&gt; blacklist_nodes;        // Nodes to avoid</p>
<p>};</p>
<p></code></p>
<h2>Job Management</h2>
<p>----------------------------------------</p>
<p>The GCS Job Manager coordinates job submission, tracking, and resource cleanup across the cluster.</p>
<h3>Job Lifecycle Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Job State Management</h3>
<code>// Job states tracked by GCS
<p>enum JobState {</p>
<p>PENDING = 0;     // Job submitted, awaiting resources</p>
<p>RUNNING = 1;     // Job executing tasks</p>
<p>STOPPED = 2;     // Job terminated normally</p>
<p>FAILED = 3;      // Job failed due to error</p>
<p>};</p>
<p>// Job information maintained by GCS</p>
<p>struct JobInfo {</p>
<p>JobID job_id;                          // Unique job identifier</p>
<p>JobState state;                        // Current job state</p>
<p>string driver_ip_address;              // Driver node IP</p>
<p>int64_t driver_pid;                    // Driver process ID</p>
<p>int64_t start_time;                    // Job start timestamp</p>
<p>int64_t end_time;                      // Job end timestamp (if finished)</p>
<p>map&lt;string, double&gt; resource_mapping;  // Allocated resources</p>
<p>JobConfig config;                      // Job configuration</p>
<p>};</p>
<p></code></p>
<h2>Storage and Persistence</h2>
<p>----------------------------------------</p>
<p>The GCS uses pluggable storage backends to persist critical cluster state and enable recovery.</p>
<h3>Storage Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Storage Configuration Options</h3>
From <code>src/ray/gcs/gcs_server/gcs_server.h:98-104</code>:
<code>enum class StorageType {
<p>UNKNOWN = 0,</p>
<p>IN_MEMORY = 1,      // Fast, non-persistent storage</p>
<p>REDIS_PERSIST = 2,  // Persistent Redis storage</p>
<p>};</p>
<p>// Storage configuration constants</p>
<p>static constexpr char kInMemoryStorage[] = &quot;memory&quot;;</p>
<p>static constexpr char kRedisStorage[] = &quot;redis&quot;;</p>
<p></code></p>
<p>Storage Type Selection:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Storage Type |</p>
<p>Use Case |</p>
<p>Persistence |</p>
<p>Performance |</p>
<p>Fault Tolerance |</p>
<p>|</p>
<p>| </p>
<p>Memory |</p>
<p>Development/Testing |</p>
<p>No |</p>
<p>Highest |</p>
<p>None |</p>
<p>|</p>
<p>| </p>
<p>Redis |</p>
<p>Production |</p>
<p>Yes |</p>
<p>High |</p>
<p>Full recovery |</p>
<p>|</p>
<p>| </p>
<p>File |</p>
<p>Local debugging |</p>
<p>Yes |</p>
<p>Medium |</p>
<p>Local only |</p>
<p>|</p>
<p>[/TABLE]</p>
<h3>Data Persistence Patterns</h3>
<p>Critical Data Categories:</p>
<p>‚Ä¢ Node Registry: All registered nodes and their states</p>
<p>‚Ä¢ Actor Registry: Actor metadata and placement information  </p>
<p>‚Ä¢ Job Registry: Job specifications and execution state</p>
<p>‚Ä¢ Resource State: Cluster resource allocation and usage</p>
<p>‚Ä¢ Configuration: Cluster and component configurations</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Communication and RPC</h2>
<p>----------------------------------------</p>
<p>The GCS server provides gRPC-based APIs for all cluster components to interact with global state.</p>
<h3>RPC Service Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Key RPC Interfaces</h3>
<p>Node Management RPCs:</p>
<code>// From gcs_service.proto
<p>service NodeInfoGcsService {</p>
<p>rpc RegisterNode(RegisterNodeRequest) returns (RegisterNodeReply);</p>
<p>rpc UnregisterNode(UnregisterNodeRequest) returns (UnregisterNodeReply);</p>
<p>rpc GetAllNodeInfo(GetAllNodeInfoRequest) returns (GetAllNodeInfoReply);</p>
<p>rpc CheckAlive(CheckAliveRequest) returns (CheckAliveReply);</p>
<p>rpc DrainNode(DrainNodeRequest) returns (DrainNodeReply);</p>
<p>}</p>
<p></code></p>
<p>Actor Management RPCs:</p>
<code>service ActorInfoGcsService {
<p>rpc CreateActor(CreateActorRequest) returns (CreateActorReply);</p>
<p>rpc GetActorInfo(GetActorInfoRequest) returns (GetActorInfoReply);</p>
<p>rpc KillActorViaGcs(KillActorViaGcsRequest) returns (KillActorViaGcsReply);</p>
<p>rpc ListNamedActors(ListNamedActorsRequest) returns (ListNamedActorsReply);</p>
<p>}</p>
<p></code></p>
<h3>Performance Optimization</h3>
<p>RPC Performance Characteristics:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Operation Type |</p>
<p>Typical Latency |</p>
<p>Throughput |</p>
<p>Optimization |</p>
<p>|</p>
<p>| </p>
<p>Node registration |</p>
<p>1-5ms |</p>
<p>1K ops/s |</p>
<p>Batched updates |</p>
<p>|</p>
<p>| </p>
<p>Actor creation |</p>
<p>5-20ms |</p>
<p>500 ops/s |</p>
<p>Async processing |</p>
<p>|</p>
<p>| </p>
<p>Resource queries |</p>
<p>&lt; 1ms |</p>
<p>10K ops/s |</p>
<p>Local caching |</p>
<p>|</p>
<p>| </p>
<p>Job submission |</p>
<p>2-10ms |</p>
<p>1K ops/s |</p>
<p>Pipeline processing |</p>
<p>|</p>
<p>[/TABLE]</p>
<h2>Fault Tolerance and Recovery</h2>
<p>----------------------------------------</p>
<p>The GCS implements comprehensive fault tolerance mechanisms to ensure cluster resilience.</p>
<h3>Recovery Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>GCS Server Recovery Process</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Recovery Scenarios</h3>
<p>1. GCS Server Crash:</p>
<p>- Persistent storage preserves critical state</p>
<p>- New GCS instance loads saved data</p>
<p>- Nodes re-register and update status</p>
<p>- Clients reconnect automatically</p>
<p>2. Storage Backend Failure:</p>
<p>- GCS switches to backup storage</p>
<p>- In-memory state provides temporary continuity</p>
<p>- Storage recovery restores full persistence</p>
<p>3. Network Partition:</p>
<p>- GCS maintains authoritative state</p>
<p>- Nodes operate in degraded mode</p>
<p>- State synchronization on partition heal</p>
<h2>Performance Characteristics</h2>
<p>----------------------------------------</p>
<h3>Scalability Metrics</h3>
<p>GCS Server Performance:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Metric |</p>
<p>Small Cluster (10 nodes) |</p>
<p>Medium Cluster (100 nodes) |</p>
<p>Large Cluster (1000 nodes) |</p>
<p>|</p>
<p>| </p>
<p>Node registration throughput |</p>
<p>100 ops/s |</p>
<p>500 ops/s |</p>
<p>1K ops/s |</p>
<p>|</p>
<p>| </p>
<p>Actor creation latency |</p>
<p>5ms |</p>
<p>10ms |</p>
<p>20ms |</p>
<p>|</p>
<p>| </p>
<p>Resource query latency |</p>
<p>0.5ms |</p>
<p>1ms |</p>
<p>2ms |</p>
<p>|</p>
<p>| </p>
<p>Memory usage |</p>
<p>100MB |</p>
<p>500MB |</p>
<p>2GB |</p>
<p>|</p>
<p>| </p>
<p>Storage size |</p>
<p>10MB |</p>
<p>100MB |</p>
<p>1GB |</p>
<p>|</p>
<p>[/TABLE]</p>
<h3>Optimization Strategies</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Implementation Details</h2>
<p>----------------------------------------</p>
<h3>Core Code Structure</h3>
<p>GCS Server Main Loop:</p>
From <code>src/ray/gcs/gcs_server/gcs_server_main.cc:45-190</code>:
<code>int main(int argc, char *argv[]) {
<p>// Parse command line arguments</p>
<p>gflags::ParseCommandLineFlags(&amp;argc, &amp;argv, true);</p>
<p>// Configure logging and stream redirection</p>
<p>InitShutdownRAII ray_log_shutdown_raii(/*...*/);</p>
<p>// Initialize configuration</p>
<p>RayConfig::instance().initialize(config_list);</p>
<p>// Create main IO service</p>
<p>instrumented_io_context main_service(/*enable_lag_probe=*/true);</p>
<p>// Initialize metrics collection</p>
<p>ray::stats::Init(global_tags, metrics_agent_port, WorkerID::Nil());</p>
<p>// Create and configure GCS server</p>
<p>ray::gcs::GcsServerConfig gcs_server_config;</p>
<p>ray::gcs::GcsServer gcs_server(gcs_server_config, main_service);</p>
<p>// Set up signal handlers for graceful shutdown</p>
<p>boost::asio::signal_set signals(main_service);</p>
<p>signals.async_wait(shutdown_handler);</p>
<p>// Start the server and run main loop</p>
<p>gcs_server.Start();</p>
<p>main_service.run();</p>
<p>}</p>
<p></code></p>
<p>Component Initialization Pattern:</p>
<code>class GcsServer {
<p>void DoStart(const GcsInitData &amp;gcs_init_data) {</p>
<p>// Initialize storage backend first</p>
<p>gcs_table_storage_ = CreateStorage();</p>
<p>// Initialize core managers</p>
<p>InitGcsNodeManager(gcs_init_data);</p>
<p>InitGcsResourceManager(gcs_init_data);</p>
<p>InitGcsJobManager(gcs_init_data);</p>
<p>InitGcsActorManager(gcs_init_data);</p>
<p>InitGcsPlacementGroupManager(gcs_init_data);</p>
<p>// Initialize supporting services</p>
<p>InitKVManager();</p>
<p>InitPubSubHandler();</p>
<p>InitRuntimeEnvManager();</p>
<p>// Install cross-component event listeners</p>
<p>InstallEventListeners();</p>
<p>// Start RPC server</p>
<p>rpc_server_.Run();</p>
<p>}</p>
<p>};</p>
<p></code></p>
<h3>Critical Code Paths</h3>
<p>Node Registration Handler:</p>
<code>void GcsNodeManager::HandleRegisterNode(
<p>rpc::RegisterNodeRequest request,</p>
<p>rpc::RegisterNodeReply *reply,</p>
<p>rpc::SendReplyCallback send_reply_callback) {</p>
<p>NodeID node_id = NodeID::FromBinary(request.node_info().node_id());</p>
<p>// Create node info from request</p>
<p>auto node = std::make_shared&lt;rpc::GcsNodeInfo&gt;(request.node_info());</p>
<p>// Add to alive nodes and storage</p>
<p>AddNode(node);</p>
<p>// Publish node added event</p>
<p>RAY_CHECK_OK(gcs_publisher_-&gt;PublishNodeInfo(node_id, *node, nullptr));</p>
<p>// Notify listeners</p>
<p>for (auto &amp;listener : node_added_listeners_) {</p>
<p>listener(node);</p>
<p>}</p>
<p>send_reply_callback(Status::OK(), nullptr, nullptr);</p>
<p>}</p>
<p></code></p>
<h3>Error Handling Patterns</h3>
<p>Graceful Degradation:</p>
<code>// Example error handling in resource management
<p>Status GcsResourceManager::UpdateResourceUsage(const NodeID &amp;node_id,</p>
<p>const ResourceUsageMap &amp;usage) {</p>
<p>// Try to update local state first</p>
<p>auto status = UpdateLocalResourceView(node_id, usage);</p>
<p>if (!status.ok()) {</p>
<p>RAY_LOG(WARNING) &lt;&lt; &quot;Failed to update local resource view: &quot; &lt;&lt; status;</p>
<p>// Continue with degraded functionality</p>
<p>}</p>
<p>// Try to persist to storage</p>
<p>status = PersistResourceUsage(node_id, usage);</p>
<p>if (!status.ok()) {</p>
<p>RAY_LOG(ERROR) &lt;&lt; &quot;Failed to persist resource usage: &quot; &lt;&lt; status;</p>
<p>// Queue for retry</p>
<p>retry_queue_.push({node_id, usage});</p>
<p>}</p>
<p>return Status::OK();  // Always succeed for availability</p>
<p>}</p>
<p></code></p>
<h2>Code Modification Guidelines</h2>
<p>----------------------------------------</p>
<h3>Adding New GCS Components</h3>
<p>1. Manager Component Pattern:</p>
<p>To add a new manager (e.g., GcsCustomManager):</p>
<code>// 1. Create header file: gcs_custom_manager.h
<p>class GcsCustomManager : public rpc::CustomServiceHandler {</p>
<p>public:</p>
<p>GcsCustomManager(GcsPublisher *publisher, </p>
<p>GcsTableStorage *storage,</p>
<p>instrumented_io_context &amp;io_context);</p>
<p>// Implement RPC handlers</p>
<p>void HandleCustomRequest(rpc::CustomRequest request,</p>
<p>rpc::CustomReply *reply,</p>
<p>rpc::SendReplyCallback callback) override;</p>
<p>// Initialize from persistent data</p>
<p>void Initialize(const GcsInitData &amp;init_data);</p>
<p>private:</p>
<p>GcsPublisher *gcs_publisher_;</p>
<p>GcsTableStorage *gcs_table_storage_;</p>
<p>// Component-specific state</p>
<p>};</p>
<p>// 2. Add to GcsServer initialization</p>
<p>void GcsServer::InitGcsCustomManager(const GcsInitData &amp;init_data) {</p>
<p>gcs_custom_manager_ = std::make_unique&lt;GcsCustomManager&gt;(</p>
<p>gcs_publisher_.get(), gcs_table_storage_.get(), main_service_);</p>
<p>gcs_custom_manager_-&gt;Initialize(init_data);</p>
<p>}</p>
<p></code></p>
<p>2. Adding New RPC Services:</p>
<code>// 1. Define in protobuf (gcs_service.proto)
<p>service CustomGcsService {</p>
<p>rpc CustomOperation(CustomRequest) returns (CustomReply);</p>
<p>}</p>
<p>// 2. Register in RPC server</p>
<p>void GcsServer::StartRpcServer() {</p>
<p>rpc_server_.RegisterService(gcs_custom_manager_.get());</p>
<p>rpc_server_.Run();</p>
<p>}</p>
<p></code></p>
<p>3. State Persistence Integration:</p>
<code>// Add to storage initialization
<p>void GcsCustomManager::Initialize(const GcsInitData &amp;init_data) {</p>
<p>// Load persistent state</p>
<p>auto custom_data = gcs_table_storage_-&gt;CustomTable().GetAll();</p>
<p>// Rebuild in-memory state</p>
<p>for (const auto &amp;[key, value] : custom_data) {</p>
<p>RestoreCustomState(key, value);</p>
<p>}</p>
<p>}</p>
<p>// Persist state changes</p>
<p>void GcsCustomManager::PersistCustomData(const Key &amp;key, const Value &amp;value) {</p>
<p>auto status = gcs_table_storage_-&gt;CustomTable().Put(key, value, nullptr);</p>
<p>if (!status.ok()) {</p>
<p>RAY_LOG(ERROR) &lt;&lt; &quot;Failed to persist custom data: &quot; &lt;&lt; status;</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h3>Testing and Validation</h3>
<p>Unit Testing Pattern:</p>
<code>class GcsCustomManagerTest : public ::testing::Test {
<p>protected:</p>
<p>void SetUp() override {</p>
<p>gcs_publisher_ = std::make_shared&lt;GcsPublisher&gt;(/*...*/);</p>
<p>store_client_ = std::make_shared&lt;MemoryStoreClient&gt;();</p>
<p>gcs_table_storage_ = std::make_shared&lt;GcsTableStorage&gt;(store_client_);</p>
<p>manager_ = std::make_unique&lt;GcsCustomManager&gt;(</p>
<p>gcs_publisher_.get(), gcs_table_storage_.get(), io_context_);</p>
<p>}</p>
<p>instrumented_io_context io_context_;</p>
<p>std::unique_ptr&lt;GcsCustomManager&gt; manager_;</p>
<p>// Test fixtures</p>
<p>};</p>
<p>TEST_F(GcsCustomManagerTest, HandleCustomRequest) {</p>
<p>// Test RPC handling logic</p>
<p>rpc::CustomRequest request;</p>
<p>rpc::CustomReply reply;</p>
<p>auto callback = [](Status status, </p>
<p>std::function&lt;void()&gt; success,</p>
<p>std::function&lt;void()&gt; failure) {</p>
<p>EXPECT_TRUE(status.ok());</p>
<p>};</p>
<p>manager_-&gt;HandleCustomRequest(request, &amp;reply, callback);</p>
<p>}</p>
<p></code></p>
<p>Integration Testing:</p>
<code># Test GCS server functionality
<p>cd /home/ssiddique/ray</p>
<p>bazel test //src/ray/gcs/gcs_server/test:gcs_server_test</p>
<p>bazel test //src/ray/gcs/gcs_server/test:gcs_server_integration_test</p>
<h1>Test specific managers</h1>
<p>bazel test //src/ray/gcs/gcs_server/test:gcs_node_manager_test</p>
<p>bazel test //src/ray/gcs/gcs_server/test:gcs_actor_manager_test</p>
<p></code></p>
<p>Performance Testing:</p>
<code># GCS server load testing
<p>import ray</p>
<p>import time</p>
<p>import concurrent.futures</p>
<p>@ray.remote</p>
<p>def stress_test_actor():</p>
<p>return &quot;alive&quot;</p>
<h1>Test actor creation throughput</h1>
<p>start_time = time.time()</p>
<p>actors = [stress_test_actor.remote() for _ in range(1000)]</p>
<p>results = ray.get(actors)</p>
<p>end_time = time.time()</p>
<p>throughput = len(actors) / (end_time - start_time)</p>
<p>print(f&quot;Actor creation throughput: {throughput:.2f} actors/sec&quot;)</p>
<p></code></p>
This comprehensive guide is based on Ray's GCS server source code, particularly files in <code>src/ray/gcs/gcs_server/</code>. For the most current implementation details, refer to the source files and protobuf definitions in the Ray repository.

<div class="page-break"></div>
<h1>Part II: Core Ray Services</h1>
<p>============================================================</p>
<h1>Chapter 7: Raylet Implementation and Lifecycle</h1>
<p>============================================================</p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<code>&lt;/details&gt;
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>&lt;function_calls&gt;</p>
<p>&lt;invoke name=&quot;create_diagram&quot;&gt;</p>
<p>&lt;parameter name=&quot;content&quot;&gt;graph TB</p>
<p>subgraph &quot;Raylet Process&quot;</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<p>B --&gt; D[Local Task Manager]</p>
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph &quot;External Interfaces&quot;</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p>&lt;/code_block_to_apply_changes_from&gt;</p>
<p>&lt;/edit_instructions&gt;</p>
<p>Assistant:&lt;rewritten_file&gt;</p>
<p></code></p>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ Error Handling and Fault Tolerance</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Code References and Implementation Details</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>The Raylet is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- Task scheduling and execution within a node</p>
<p>- Resource management (CPU, GPU, memory)</p>
<p>- Object management and storage coordination</p>
<p>- Worker process lifecycle management</p>
<p>- Communication coordination between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Click to expand: High-level Architecture Diagram</p>
<code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p></code></p>
<h3>Core Components</h3>
<p>The raylet consists of several interconnected components:</p>
<p>graph TB</p>
<p>subgraph "Raylet Process"</p>
<p>A[Raylet Main] --&gt; B[Node Manager]</p>
<p>A --&gt; C[Object Manager]</p>
<code>    B --&gt; D[Local Task Manager]
<p>B --&gt; E[Cluster Task Manager]</p>
<p>B --&gt; F[Worker Pool]</p>
<p>B --&gt; G[Resource Manager]</p>
<p>D --&gt; H[Dependency Manager]</p>
<p>D --&gt; I[Local Object Manager]</p>
<p>E --&gt; J[Cluster Resource Scheduler]</p>
<p>F --&gt; K[Worker Processes]</p>
<p>F --&gt; L[I/O Workers]</p>
<p>C --&gt; M[Plasma Store]</p>
<p>C --&gt; N[Object Directory]</p>
<p>subgraph "External Interfaces"</p>
<p>O[GCS Client]</p>
<p>P[Core Worker RPC]</p>
<p>Q[Node Manager RPC]</p>
<p>end</p>
<p>B --&gt; O</p>
<p>B --&gt; P</p>
<p>B --&gt; Q</p>
<p>end</p>
<p></code></p>
<p>Assistant:</p>
<code># Ray Raylet Lifecycle: A Comprehensive Technical Guide
<h2>Table of Contents</h2>
<p>1. [Introduction](#introduction)</p>
<p>2. [Raylet Architecture Overview](#raylet-architecture-overview)</p>
<p>3. [Raylet Lifecycle](#raylet-lifecycle)</p>
<p>4. [Communication Mechanisms](#communication-mechanisms)</p>
<p>5. [Task Scheduling and Load Handling](#task-scheduling-and-load-handling)</p>
<p>6. [Worker Management](#worker-management)</p>
<p>7. [Object Management](#object-management)</p>
<p>8. [Resource Management](#resource-management)</p>
<p>9. [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance)</p>
<p>10. [Performance Optimization](#performance-optimization)</p>
<p>11. [Code References and Implementation Details](#code-references-and-implementation-details)</p>
<h2>Introduction</h2>
<p>The **Raylet** is the core component of the Ray distributed computing framework that acts as the per-node manager responsible for:</p>
<p>- **Task scheduling and execution** within a node</p>
<p>- **Resource management** (CPU, GPU, memory)</p>
<p>- **Object management** and storage coordination</p>
<p>- **Worker process lifecycle** management</p>
<p>- **Communication coordination** between workers and the global control store (GCS)</p>
<p>This document provides a deep technical dive into how the raylet operates, its internal mechanisms, and implementation details for developers who need to understand or modify the raylet codebase.</p>
<h2>Raylet Architecture Overview</h2>
<p>&lt;details&gt;</p>
<p>&lt;summary&gt;Click to expand: High-level Architecture Diagram&lt;/summary&gt;</p>
<p></code></p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          Ray Cluster                           ‚îÇ</p>
<p>‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ</p>
<p>‚îÇ  ‚îÇ   Head Node     ‚îÇ                    ‚îÇ  Worker Nodes   ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ    GCS    ‚îÇ  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ (Global   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Control   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Store)    ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Raylet   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ                 ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ  Object   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ  Workers  ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îÇ Manager   ‚îÇ  ‚îÇ                    ‚îÇ  ‚îÇ Pool      ‚îÇ  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ</p>
<p>‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<pre><code><code>&lt;/details&gt;
<h3>Core Components</h3>
The raylet consists of several interconnected components:
&lt;function_calls&gt;
&lt;invoke name=&quot;create_diagram&quot;&gt;
&lt;parameter name=&quot;content&quot;&gt;graph TB
subgraph &quot;Raylet Process&quot;
A[Raylet Main] --&gt; B[Node Manager]
A --&gt; C[Object Manager]
B --&gt; D[Local Task Manager]
B --&gt; E[Cluster Task Manager]
B --&gt; F[Worker Pool]
B --&gt; G[Resource Manager]
D --&gt; H[Dependency Manager]
D --&gt; I[Local Object Manager]
E --&gt; J[Cluster Resource Scheduler]
F --&gt; K[Worker Processes]
F --&gt; L[I/O Workers]
C --&gt; M[Plasma Store]
C --&gt; N[Object Directory]
subgraph &quot;External Interfaces&quot;
O[GCS Client]
P[Core Worker RPC]
Q[Node Manager RPC]
end
B --&gt; O
B --&gt; P
B --&gt; Q
end
&lt;/code_block_to_apply_changes_from&gt;
&lt;/edit_instructions&gt;
Assistant:&lt;rewritten_file&gt;
</code></code></pre>
<h1>Ray Raylet Lifecycle: A Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Raylet Architecture Overview</p>
<p>‚Ä¢ Raylet Lifecycle</p>
<p>‚Ä¢ Communication Mechanisms</p>
<p>‚Ä¢ Task Scheduling and Load Handling</p>
<p>‚Ä¢ Worker Management</p>
<p>‚Ä¢ Object Management</p>
<p>‚Ä¢ Resource Management</p>
<p>‚Ä¢ [Error Handling and Fault Tolerance](#error-handling-and-fault-tolerance</p>

<div class="page-break"></div>
<h1>Part II: Core Ray Services</h1>
<p>============================================================</p>
<h1>Chapter 8: Distributed Object Store</h1>
<p>============================================================</p>
<h1>Ray Distributed Object Store: Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Architecture Overview</p>
<p>‚Ä¢ Local Storage: Plasma Store</p>
<p>‚Ä¢ Distributed Management: Object Manager</p>
<p>‚Ä¢ Global Coordination: Object Directory</p>
<p>‚Ä¢ Object Lifecycle Management</p>
<p>‚Ä¢ Memory Management and Spilling</p>
<p>‚Ä¢ Performance Characteristics</p>
<p>‚Ä¢ Implementation Details</p>
<p>‚Ä¢ Code Modification Guidelines</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>Ray's distributed object store is a sophisticated system that provides efficient storage, retrieval, and movement of large data objects across a distributed cluster. The system consists of three main components:</p>
<p>‚Ä¢ Plasma Store: High-performance local object storage using shared memory</p>
<p>‚Ä¢ Object Manager: Distributed object transfer and coordination </p>
<p>‚Ä¢ Object Directory: Global metadata tracking via GCS (Global Control Service)</p>
<p>The object store is designed to handle massive datasets efficiently while providing transparent access patterns for Ray applications.</p>
<h2>Architecture Overview</h2>
<p>----------------------------------------</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Key Design Principles</h3>
<p>‚Ä¢ Zero-Copy Access: Objects stored in shared memory for direct access</p>
<p>‚Ä¢ Distributed Transparency: Objects appear local regardless of actual location</p>
<p>‚Ä¢ Automatic Spilling: Graceful handling of memory pressure</p>
<p>‚Ä¢ Fault Tolerance: Reconstruction and replication capabilities</p>
<p>‚Ä¢ Performance Optimization: Chunked transfers and bandwidth management</p>
<h2>Local Storage: Plasma Store</h2>
<p>----------------------------------------</p>
<p>The Plasma Store provides high-performance local object storage using memory-mapped shared memory.</p>
<h3>Plasma Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Object Storage Structure</h3>
From <code>src/ray/object_manager/plasma/plasma.h:35-70</code>:
<code>struct PlasmaObject {
<p>MEMFD_TYPE store_fd;          // Memory-mapped file descriptor</p>
<p>ptrdiff_t header_offset;      // Object header location</p>
<p>ptrdiff_t data_offset;        // Object data location  </p>
<p>ptrdiff_t metadata_offset;    // Object metadata location</p>
<p>int64_t data_size;           // Size of object data</p>
<p>int64_t metadata_size;       // Size of object metadata</p>
<p>int64_t allocated_size;      // Total allocated space</p>
<p>int device_num;              // Device identifier</p>
<p>int64_t mmap_size;          // Memory-mapped region size</p>
<p>bool fallback_allocated;     // Whether using fallback storage</p>
<p>bool is_experimental_mutable_object; // Mutable object flag</p>
<p>};</p>
<p></code></p>
<h3>Memory Allocation Strategy</h3>
<p>Block-Based Allocation:</p>
- Objects allocated in 64-byte aligned blocks (<code>kBlockSize = 64</code>)
<p>- Minimizes fragmentation through power-of-2 sizing</p>
<p>- Supports both main memory and fallback filesystem storage</p>
<p>Memory Layout:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Distributed Management: Object Manager</h2>
<p>----------------------------------------</p>
<p>The Object Manager handles inter-node object transfers and distributed coordination.</p>
<h3>Object Manager Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Object Transfer Protocol</h3>
<p>Ray uses a sophisticated chunked transfer protocol for large objects:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Configuration and Performance Tuning</h3>
From <code>src/ray/object_manager/object_manager.h:40-75</code>:
<code>struct ObjectManagerConfig {
<p>std::string object_manager_address;    // Network address</p>
<p>int object_manager_port;               // Listening port</p>
<p>unsigned int timer_freq_ms;            // Timer frequency</p>
<p>unsigned int pull_timeout_ms;          // Pull request timeout</p>
<p>uint64_t object_chunk_size;           // Chunk size for transfers</p>
<p>uint64_t max_bytes_in_flight;         // Max concurrent transfer bytes</p>
<p>std::string store_socket_name;         // Plasma store socket</p>
<p>int push_timeout_ms;                   // Push timeout</p>
<p>int rpc_service_threads_number;        // RPC thread pool size</p>
<p>int64_t object_store_memory;          // Total memory allocation</p>
<p>std::string plasma_directory;          // Shared memory directory</p>
<p>std::string fallback_directory;        // Fallback storage directory</p>
<p>bool huge_pages;                       // Enable huge page support</p>
<p>};</p>
<p></code></p>
<p>Key Performance Parameters:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Parameter |</p>
<p>Default |</p>
<p>Impact |</p>
<p>|</p>
<p>| </p>
<code>object_chunk_size</code> |
<p>1MB |</p>
<p>Transfer granularity, affects latency/throughput |</p>
<p>|</p>
<p>| </p>
<code>max_bytes_in_flight</code> |
<p>256MB |</p>
<p>Max concurrent transfer bandwidth |</p>
<p>|</p>
<p>| </p>
<code>pull_timeout_ms</code> |
<p>10s |</p>
<p>Request timeout, affects fault tolerance |</p>
<p>|</p>
<p>| </p>
<code>rpc_service_threads_number</code> |
<p>min(max(2, cpu/4), 8) |</p>
<p>Concurrency level |</p>
<p>|</p>
<p>[/TABLE]</p>
<h2>Global Coordination: Object Directory</h2>
<p>----------------------------------------</p>
<p>The Object Directory provides cluster-wide object location tracking and metadata management.</p>
<h3>Object Directory Design</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Object Location Subscription Model</h3>
From <code>src/ray/object_manager/object_directory.h:33-70</code>:
<code>using OnLocationsFound = std::function&lt;void(
<p>const ObjectID &amp;object_id,</p>
<p>const std::unordered_set&lt;NodeID&gt; &amp;node_locations,</p>
<p>const std::string &amp;spilled_url,</p>
<p>const NodeID &amp;spilled_node_id,</p>
<p>bool pending_creation,</p>
<p>size_t object_size)&gt;;</p>
<p>class IObjectDirectory {</p>
<p>virtual Status SubscribeObjectLocations(</p>
<p>const UniqueID &amp;callback_id,</p>
<p>const ObjectID &amp;object_id,</p>
<p>const rpc::Address &amp;owner_address,</p>
<p>const OnLocationsFound &amp;callback) = 0;</p>
<p>virtual void ReportObjectAdded(</p>
<p>const ObjectID &amp;object_id,</p>
<p>const NodeID &amp;node_id,</p>
<p>const ObjectInfo &amp;object_info) = 0;</p>
<p>virtual void ReportObjectSpilled(</p>
<p>const ObjectID &amp;object_id,</p>
<p>const NodeID &amp;node_id,</p>
<p>const rpc::Address &amp;owner_address,</p>
<p>const std::string &amp;spilled_url,</p>
<p>const ObjectID &amp;generator_id,</p>
<p>bool spilled_to_local_storage) = 0;</p>
<p>};</p>
<p></code></p>
<p>Location Update Flow:</p>
<p>1. Object Creation: Node reports object addition to directory</p>
<p>2. Subscription: Interested nodes subscribe to object locations</p>
<p>3. Notification: Directory notifies subscribers of location changes</p>
<p>4. Transfer: Subscribers initiate object transfers as needed</p>
<h2>Object Lifecycle Management</h2>
<p>----------------------------------------</p>
<p>Ray objects go through a well-defined lifecycle from creation to deletion.</p>
<h3>Object Lifecycle States</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Object Pinning and Reference Counting</h3>
From <code>src/ray/raylet/local_object_manager.h:67-75</code>:
<code>void PinObjectsAndWaitForFree(
<p>const std::vector&lt;ObjectID&gt; &amp;object_ids,</p>
<p>std::vector&lt;std::unique_ptr&lt;RayObject&gt;&gt; &amp;&amp;objects,</p>
<p>const rpc::Address &amp;owner_address,</p>
<p>const ObjectID &amp;generator_id = ObjectID::Nil());</p>
<p>struct LocalObjectInfo {</p>
<p>rpc::Address owner_address;      // Object owner for reference counting</p>
<p>bool is_freed = false;          // Whether object can be freed</p>
<p>std::optional&lt;ObjectID&gt; generator_id;  // For dynamically created objects</p>
<p>size_t object_size;             // Object size for memory tracking</p>
<p>};</p>
<p></code></p>
<p>Reference Counting Protocol:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Memory Management and Spilling</h2>
<p>----------------------------------------</p>
<p>Ray implements sophisticated memory management with automatic spilling to external storage.</p>
<h3>Memory Management Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Spilling Algorithm</h3>
From <code>src/ray/raylet/local_object_manager.h:206-228</code>:
<code>// Spill objects asynchronously when space is needed
<p>bool TryToSpillObjects();</p>
<p>// Internal spilling implementation with batching</p>
<p>void SpillObjectsInternal(</p>
<p>const std::vector&lt;ObjectID&gt; &amp;objects_ids,</p>
<p>std::function&lt;void(const ray::Status &amp;)&gt; callback);</p>
<p>// Handle spilling completion and update metadata</p>
<p>void OnObjectSpilled(</p>
<p>const std::vector&lt;ObjectID&gt; &amp;object_ids,</p>
<p>const rpc::SpillObjectsReply &amp;worker_reply);</p>
<p></code></p>
<p>Spilling Decision Algorithm:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Restoration and Fused Operations</h3>
<p>Fused Restoration combines multiple small objects into single operations for efficiency:</p>
<code>// Maximum number of objects to fuse in single operation
<p>int64_t max_fused_object_count_;</p>
<p>// Restore spilled object from external storage</p>
<p>void AsyncRestoreSpilledObject(</p>
<p>const ObjectID &amp;object_id,</p>
<p>int64_t object_size,</p>
<p>const std::string &amp;object_url,</p>
<p>std::function&lt;void(const ray::Status &amp;)&gt; callback);</p>
<p></code></p>
<h2>Performance Characteristics</h2>
<p>----------------------------------------</p>
<h3>Throughput and Latency Analysis</h3>
<p>Local Operations:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Operation |</p>
<p>Latency |</p>
<p>Throughput |</p>
<p>Notes |</p>
<p>|</p>
<p>| </p>
<p>Local object access |</p>
<p>&lt; 1Œºs |</p>
<p>~50 GB/s |</p>
<p>Direct shared memory access |</p>
<p>|</p>
<p>| </p>
<p>Object creation |</p>
<p>1-10Œºs |</p>
<p>~10 GB/s |</p>
<p>Memory allocation + metadata |</p>
<p>|</p>
<p>| </p>
<p>Object deletion |</p>
<p>&lt; 1Œºs |</p>
<p>~20 GB/s |</p>
<p>Reference counting + cleanup |</p>
<p>|</p>
<p>[/TABLE]</p>
<p>Distributed Operations:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Operation |</p>
<p>Latency |</p>
<p>Throughput |</p>
<p>Notes |</p>
<p>|</p>
<p>| </p>
<p>Remote object pull |</p>
<p>1-10ms + transfer_time |</p>
<p>~1-5 GB/s per node |</p>
<p>Network + chunking overhead |</p>
<p>|</p>
<p>| </p>
<p>Object location lookup |</p>
<p>0.1-1ms |</p>
<p>~10K ops/s |</p>
<p>Object directory query |</p>
<p>|</p>
<p>| </p>
<p>Spilling to S3 |</p>
<p>10-100ms + transfer_time |</p>
<p>~100-500 MB/s |</p>
<p>Network + storage latency |</p>
<p>|</p>
<p>[/TABLE]</p>
<p>Memory Management:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Implementation Details</h2>
<p>----------------------------------------</p>
<h3>Critical Code Paths</h3>
Object Manager Core Loop (<code>src/ray/object_manager/object_manager.cc</code>):
<code>class ObjectManager : public ObjectManagerInterface {
<p>// Handle pull request from remote nodes</p>
<p>void HandlePull(rpc::PullRequest request,</p>
<p>rpc::PullReply *reply,</p>
<p>rpc::SendReplyCallback send_reply_callback) override;</p>
<p>// Handle push from remote nodes  </p>
<p>void HandlePush(rpc::PushRequest request,</p>
<p>rpc::PushReply *reply,</p>
<p>rpc::SendReplyCallback send_reply_callback) override;</p>
<p>// Pull objects from remote nodes</p>
<p>uint64_t Pull(const std::vector&lt;rpc::ObjectReference&gt; &amp;object_refs,</p>
<p>BundlePriority prio,</p>
<p>const TaskMetricsKey &amp;task_key) override;</p>
<p>};</p>
<p></code></p>
<p>Local Object Manager Operations:</p>
<code>class LocalObjectManager {
<p>// Pin objects and wait for owner to free them</p>
<p>void PinObjectsAndWaitForFree(</p>
<p>const std::vector&lt;ObjectID&gt; &amp;object_ids,</p>
<p>std::vector&lt;std::unique_ptr&lt;RayObject&gt;&gt; &amp;&amp;objects,</p>
<p>const rpc::Address &amp;owner_address,</p>
<p>const ObjectID &amp;generator_id);</p>
<p>// Spill objects to external storage</p>
<p>void SpillObjectUptoMaxThroughput();</p>
<p>// Restore objects from external storage</p>
<p>void AsyncRestoreSpilledObject(</p>
<p>const ObjectID &amp;object_id,</p>
<p>int64_t object_size, </p>
<p>const std::string &amp;object_url,</p>
<p>std::function&lt;void(const ray::Status &amp;)&gt; callback);</p>
<p>};</p>
<p></code></p>
<h3>Error Handling and Recovery</h3>
<p>Fault Tolerance Mechanisms:</p>
<p>‚Ä¢ Object Reconstruction: If objects are lost, Ray can reconstruct them by re-executing the tasks that created them</p>
<p>‚Ä¢ Replication: Critical objects can be replicated across multiple nodes</p>
<p>‚Ä¢ Spill Redundancy: Objects spilled to external storage maintain multiple copies</p>
<p>‚Ä¢ Network Resilience: Failed transfers are automatically retried with exponential backoff</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Code Modification Guidelines</h2>
<p>----------------------------------------</p>
<h3>Adding New Object Store Features</h3>
<p>1. Local Storage Modifications:</p>
<p>To modify Plasma store behavior, focus on these key files:</p>
- <code>src/ray/object_manager/plasma/plasma.cc</code> - Core storage logic
- <code>src/ray/object_manager/plasma/plasma_allocator.cc</code> - Memory allocation
- <code>src/ray/raylet/local_object_manager.cc</code> - Raylet integration
<p>2. Distributed Transfer Modifications:</p>
<p>For object transfer improvements:</p>
- <code>src/ray/object_manager/object_manager.cc</code> - Main transfer logic
- <code>src/ray/object_manager/pull_manager.cc</code> - Pull request handling
- <code>src/ray/object_manager/push_manager.cc</code> - Push request handling
<p>3. Spilling and External Storage:</p>
<p>For spilling enhancements:</p>
- <code>src/ray/raylet/local_object_manager.cc</code> - Spilling coordination
<p>- External storage interfaces in worker processes</p>
<h3>Example: Adding a New Spilling Strategy</h3>
<code>// In LocalObjectManager class
<p>bool TryToSpillObjectsCustomStrategy() {</p>
<p>// 1. Implement custom object selection logic</p>
<p>std::vector&lt;ObjectID&gt; objects_to_spill = SelectObjectsCustomCriteria();</p>
<p>// 2. Check if objects meet spilling requirements</p>
<p>if (objects_to_spill.empty() || </p>
<p>total_size &lt; min_spilling_size_) {</p>
<p>return false;</p>
<p>}</p>
<p>// 3. Initiate spilling with custom parameters</p>
<p>SpillObjectsInternal(objects_to_spill, </p>
<p>[this](const ray::Status &amp;status) {</p>
<p>// Custom completion handling</p>
<p>});</p>
<p>return true;</p>
<p>}</p>
<p></code></p>
<h3>Testing and Validation</h3>
<p>Key Testing Areas:</p>
<p>‚Ä¢ Unit Tests: Individual component functionality</p>
<p>‚Ä¢ Integration Tests: Cross-component interactions  </p>
<p>‚Ä¢ Performance Tests: Throughput and latency benchmarks</p>
<p>‚Ä¢ Fault Injection: Network failures, storage failures, node crashes</p>
<p>‚Ä¢ Scale Tests: Large object handling, many-node clusters</p>
<p>Performance Validation Commands:</p>
<code># Test object store throughput
<p>ray start --head --object-store-memory=8000000000</p>
<p>python -c &quot;</p>
<p>import ray</p>
<p>import numpy as np</p>
<p>ray.init()</p>
<h1>Test large object creation/access patterns</h1>
<p>obj = ray.put(np.random.rand(100000000))  # ~800MB object</p>
<p>result = ray.get(obj)</p>
<p>&quot;</p>
<h1>Monitor object store stats</h1>
<p>ray status --verbose</p>
<p></code></p>
This guide is based on Ray's source code, particularly the object manager, plasma store, and local object manager implementations. For the most current details, refer to the source files in <code>src/ray/object_manager/</code> and <code>src/ray/raylet/</code>.

<div class="page-break"></div>
<h1>Part III: Advanced Ray Systems</h1>
<p>============================================================</p>
<h1>Chapter 9: Distributed Scheduling Implementation</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Scheduling Architecture Overview</p>
<p>‚Ä¢ Core Scheduling Components</p>
<p>‚Ä¢ Resource Management and Allocation</p>
<p>‚Ä¢ Task Scheduling Algorithms</p>
<p>‚Ä¢ Actor Placement and Scheduling</p>
<p>‚Ä¢ Placement Group Scheduling</p>
<p>‚Ä¢ Scheduling Strategies</p>
<p>‚Ä¢ Node Affinity and Label-Based Scheduling</p>
<p>‚Ä¢ Locality-Aware Scheduling</p>
<p>‚Ä¢ Cluster Resource Scheduling</p>
<p>‚Ä¢ Autoscaler Integration</p>
<p>‚Ä¢ Performance Characteristics</p>
<p>‚Ä¢ Configuration and Tuning</p>
<p>‚Ä¢ Implementation Deep Dive</p>
<p>‚Ä¢ Testing and Verification</p>
<p>‚Ä¢ Best Practices</p>
<p>‚Ä¢ Troubleshooting</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>Ray's distributed scheduling system is a sophisticated multi-layered scheduler designed to efficiently allocate resources and place tasks/actors across a distributed cluster. This chapter dives deep into the scheduling implementation, covering complex scheduling scenarios including resource constraints, placement groups, locality preferences, and autoscaling decisions while maintaining high performance and fault tolerance.</p>
<h3>What is Ray?</h3>
<p>Ray is an open-source unified framework for scaling AI workloads. It provides:</p>
<p>- Distributed Computing: Scale Python workloads across multiple machines</p>
<p>- Unified API: Single interface for tasks, actors, and data processing</p>
<p>- Fault Tolerance: Built-in error handling and recovery mechanisms</p>
<p>- Resource Management: Efficient allocation of CPU, GPU, and memory resources</p>
<p>- Ecosystem: Libraries for ML (Ray Train), reinforcement learning (Ray RLlib), hyperparameter tuning (Ray Tune), and more</p>
<h3>Key Features</h3>
<p>‚Ä¢ Multi-level Scheduling: Task-level, actor-level, and placement group scheduling</p>
<p>‚Ä¢ Resource-Aware: CPU, GPU, memory, and custom resource scheduling</p>
<p>‚Ä¢ Placement Strategies: PACK, SPREAD, STRICT_PACK, STRICT_SPREAD</p>
<p>‚Ä¢ Locality Optimization: Data locality-aware task placement</p>
<p>‚Ä¢ Dynamic Scaling: Integration with autoscaler for cluster growth/shrinkage</p>
<p>‚Ä¢ Label-Based Scheduling: Node affinity and label constraints</p>
<p>‚Ä¢ Performance Optimization: Efficient algorithms for large-scale clusters</p>
<h3>Scheduling Hierarchy</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Scheduling Architecture Overview</h2>
<p>----------------------------------------</p>
<h3>Multi-Level Scheduling Architecture</h3>
<p>Ray implements a hierarchical scheduling architecture with multiple decision points:</p>
<h4>1. Client-Side Scheduling</h4>
<p>[Diagram content removed for EPUB version]</p>
Location: <code>src/ray/core_worker/lease_policy.cc</code>
<p>The client-side scheduling makes initial placement decisions based on:</p>
<p>- Data locality (object location)</p>
<p>- Scheduling strategies (spread, node affinity)</p>
<p>- Resource requirements</p>
<h4>2. Raylet-Level Scheduling</h4>
<p>[Diagram content removed for EPUB version]</p>
Location: <code>src/ray/raylet/scheduling/cluster_task_manager.cc</code>
<h4>3. GCS-Level Scheduling</h4>
<p>[Diagram content removed for EPUB version]</p>
Location: <code>src/ray/gcs/gcs_server/gcs_actor_scheduler.cc</code>
<h3>Core Scheduling Flow</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Core Scheduling Components</h2>
<p>----------------------------------------</p>
<h3>ClusterResourceScheduler</h3>
Location: <code>src/ray/raylet/scheduling/cluster_resource_scheduler.h</code>
<p>The central coordinator for cluster-wide resource scheduling decisions.</p>
<code>class ClusterResourceScheduler {
<p>// Core scheduling method</p>
<p>scheduling::NodeID GetBestSchedulableNode(</p>
<p>const ResourceRequest &amp;resource_request,</p>
<p>const rpc::SchedulingStrategy &amp;scheduling_strategy,</p>
<p>bool actor_creation,</p>
<p>bool force_spillback,</p>
<p>const std::string &amp;preferred_node_id,</p>
<p>int64_t *total_violations,</p>
<p>bool *is_infeasible);</p>
<p>// Bundle scheduling for placement groups</p>
<p>SchedulingResult Schedule(</p>
<p>const std::vector&lt;const ResourceRequest *&gt; &amp;resource_request_list,</p>
<p>SchedulingOptions options);</p>
<p>}</p>
<p></code></p>
<p>Key Responsibilities:</p>
<p>- Node feasibility checking</p>
<p>- Resource availability tracking</p>
<p>- Scheduling strategy implementation</p>
<p>- Placement group bundle scheduling</p>
<h3>ClusterTaskManager</h3>
Location: <code>src/ray/raylet/scheduling/cluster_task_manager.h</code>
<p>Manages task queuing and scheduling at the cluster level.</p>
<code>class ClusterTaskManager {
<p>void QueueAndScheduleTask(</p>
<p>RayTask task,</p>
<p>bool grant_or_reject,</p>
<p>bool is_selected_based_on_locality,</p>
<p>rpc::RequestWorkerLeaseReply *reply,</p>
<p>rpc::SendReplyCallback send_reply_callback);</p>
<p>void ScheduleAndDispatchTasks();</p>
<p>}</p>
<p></code></p>
<p>Scheduling Queues:</p>
- <code>tasks_to_schedule_</code>: Tasks waiting for resources
- <code>infeasible_tasks_</code>: Tasks that cannot be scheduled
<h3>LocalTaskManager</h3>
Location: <code>src/ray/raylet/local_task_manager.h</code>
<p>Handles local task execution and worker management.</p>
<code>class LocalTaskManager {
<p>void QueueAndScheduleTask(std::shared_ptr&lt;internal::Work&gt; work);</p>
<p>void ScheduleAndDispatchTasks();</p>
<p>bool TrySpillback(const std::shared_ptr&lt;internal::Work&gt; &amp;work,</p>
<p>bool &amp;is_infeasible);</p>
<p>}</p>
<p></code></p>
<p>Fairness Policy: Implements CPU-fair scheduling to prevent resource starvation:</p>
<code>// From src/ray/raylet/local_task_manager.cc
<p>if (total_cpu_requests_ &gt; total_cpus) {</p>
<p>RAY_LOG(DEBUG) &lt;&lt; &quot;Applying fairness policy. Total CPU requests (&quot;</p>
<p>&lt;&lt; total_cpu_requests_ &lt;&lt; &quot;) exceed total CPUs (&quot; </p>
<p>&lt;&lt; total_cpus &lt;&lt; &quot;)&quot;;</p>
<p>// Apply fair dispatching logic</p>
<p>}</p>
<p></code></p>
<h3>Scheduling Policies</h3>
Location: <code>src/ray/raylet/scheduling/policy/</code>
<p>Ray implements multiple scheduling policies:</p>
<h4>HybridSchedulingPolicy</h4>
<p>‚Ä¢ Default scheduling strategy</p>
<p>‚Ä¢ Balances locality and load distribution</p>
<p>‚Ä¢ Configurable spread threshold</p>
<h4>SpreadSchedulingPolicy</h4>
<p>‚Ä¢ Distributes tasks across nodes</p>
<p>‚Ä¢ Minimizes resource contention</p>
<p>‚Ä¢ Used for embarrassingly parallel workloads</p>
<h4>NodeAffinitySchedulingPolicy</h4>
<p>‚Ä¢ Hard/soft node constraints</p>
<p>‚Ä¢ Supports spillback on unavailability</p>
<p>‚Ä¢ Critical for stateful workloads</p>
<h4>NodeLabelSchedulingPolicy</h4>
<code>class NodeLabelSchedulingPolicy : public ISchedulingPolicy {
<p>scheduling::NodeID Schedule(const ResourceRequest &amp;resource_request,</p>
<p>SchedulingOptions options) override;</p>
<p>private:</p>
<p>bool IsNodeMatchLabelExpression(const Node &amp;node,</p>
<p>const rpc::LabelMatchExpression &amp;expression);</p>
<p>};</p>
<p></code></p>
<h3>Scheduling Context and Options</h3>
Location: <code>src/ray/raylet/scheduling/policy/scheduling_options.h</code>
<code>struct SchedulingOptions {
<p>SchedulingType scheduling_type;</p>
<p>float spread_threshold;</p>
<p>bool avoid_local_node;</p>
<p>bool require_node_available;</p>
<p>bool avoid_gpu_nodes;</p>
<p>double max_cpu_fraction_per_node; // For placement groups</p>
<p>static SchedulingOptions Hybrid(bool avoid_local_node,</p>
<p>bool require_node_available,</p>
<p>const std::string &amp;preferred_node_id);</p>
<p>static SchedulingOptions BundlePack(double max_cpu_fraction_per_node = 1.0);</p>
<p>static SchedulingOptions BundleStrictSpread(double max_cpu_fraction_per_node = 1.0);</p>
<p>};</p>
<p></code></p>
<h2>Resource Management and Allocation</h2>
<p>----------------------------------------</p>
<h3>Resource Model</h3>
<p>Ray uses a multi-dimensional resource model:</p>
<code>// Resource types from src/ray/common/scheduling/scheduling_ids.h
<p>enum PredefinedResources {</p>
<p>CPU = 0,</p>
<p>MEM = 1,</p>
<p>GPU = 2,</p>
<p>OBJECT_STORE_MEM = 3,</p>
<p>// Custom resources start from 4</p>
<p>};</p>
<p></code></p>
<h3>Resource Request Structure</h3>
<pre><code><code>class ResourceRequest {
ResourceSet resource_set_;           // Required resources
LabelSelector label_selector_;       // Node label requirements
bool requires_object_store_memory_;  // Memory constraint flag
bool IsEmpty() const;
const ResourceSet &amp;GetResourceSet() const;
bool RequiresObjectStoreMemory() const;
};
</code></code></pre>
<h3>NodeResources</h3>
Location: <code>src/ray/common/scheduling/cluster_resource_data.h</code>
<code>struct NodeResources {
<p>NodeResourceSet total;      // Total node capacity</p>
<p>NodeResourceSet available; // Currently available</p>
<p>NodeResourceSet normal_task_resources; // Reserved for tasks</p>
<p>absl::flat_hash_map&lt;std::string, std::string&gt; labels; // Node labels</p>
<p>bool object_pulls_queued;   // Object store status</p>
<p>bool IsAvailable(const ResourceRequest &amp;resource_request) const;</p>
<p>bool IsFeasible(const ResourceRequest &amp;resource_request) const;</p>
<p>bool HasRequiredLabels(const LabelSelector &amp;label_selector) const;</p>
<p>float CalculateCriticalResourceUtilization() const;</p>
<p>};</p>
<p></code></p>
<h3>Resource Allocation Algorithm</h3>
<pre><code><code>bool ClusterResourceScheduler::IsSchedulable(
const ResourceRequest &amp;resource_request,
scheduling::NodeID node_id) const {
return cluster_resource_manager_-&gt;HasAvailableResources(
node_id,
resource_request,
/*ignore_object_store_memory_requirement*/ 
node_id == local_node_id_) &amp;&amp;
NodeAvailable(node_id);
}
</code></code></pre>
<h3>Dynamic Resource Management</h3>
<pre><code><code>// From src/ray/raylet/scheduling/cluster_resource_scheduler_test.cc
TEST_F(ClusterResourceSchedulerTest, DynamicResourceTest) {
// Add dynamic resources at runtime
resource_scheduler.GetLocalResourceManager().AddLocalResourceInstances(
scheduling::ResourceID(&quot;custom123&quot;), {0., 1.0, 1.0});
// Verify schedulability
auto result = resource_scheduler.GetBestSchedulableNode(resource_request, ...);
ASSERT_FALSE(result.IsNil());
}
</code></code></pre>
<h3>Resource Binpacking</h3>
<p>Ray implements sophisticated binpacking for resource allocation:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Task Scheduling Algorithms</h2>
<p>----------------------------------------</p>
<h3>Hybrid Scheduling Algorithm</h3>
<p>Default Strategy: Balances locality and load distribution</p>
<code>// Configuration from src/ray/raylet/scheduling/cluster_resource_scheduler.cc
<p>best_node_id = scheduling_policy_-&gt;Schedule(</p>
<p>resource_request,</p>
<p>SchedulingOptions::Hybrid(</p>
<p>/*avoid_local_node*/ force_spillback,</p>
<p>/*require_node_available*/ force_spillback,</p>
<p>preferred_node_id));</p>
<p></code></p>
<p>Algorithm Steps:</p>
<p>1. Score Calculation: Based on resource utilization</p>
<p>2. Top-K Selection: Choose from best k nodes (default: 20% of cluster)</p>
<p>3. Random Selection: Within top-k for load balancing</p>
<p>Scoring Function:</p>
<code>float NodeResources::CalculateCriticalResourceUtilization() const {
<p>float highest = 0;</p>
<p>for (const auto &amp;i : {CPU, MEM, OBJECT_STORE_MEM}) {</p>
<p>float utilization = 1 - (available / total);</p>
<p>if (utilization &gt; highest) {</p>
<p>highest = utilization;</p>
<p>}</p>
<p>}</p>
<p>return highest;</p>
<p>}</p>
<p></code></p>
<h3>Spread Scheduling Algorithm</h3>
<p>Purpose: Distribute tasks across maximum number of nodes</p>
<code>// From scheduling policy tests
<p>TEST_F(SchedulingPolicyTest, SpreadSchedulingStrategyTest) {</p>
<p>rpc::SchedulingStrategy scheduling_strategy;</p>
<p>scheduling_strategy.mutable_spread_scheduling_strategy();</p>
<p>auto node_id = resource_scheduler.GetBestSchedulableNode(</p>
<p>resource_request, LabelSelector(), scheduling_strategy, ...);</p>
<p>}</p>
<p></code></p>
<p>Implementation:</p>
<p>- Prioritizes nodes with lowest task count</p>
<p>- Avoids resource hotspots</p>
<p>- Maximizes fault tolerance</p>
<h3>Node Affinity Scheduling</h3>
<p>Hard Affinity: Must run on specific node</p>
<code>if (IsHardNodeAffinitySchedulingStrategy(scheduling_strategy)) {
<p>// Must schedule on specified node or fail</p>
<p>best_node_id = scheduling_policy_-&gt;Schedule(</p>
<p>resource_request,</p>
<p>SchedulingOptions::NodeAffinity(</p>
<p>force_spillback, force_spillback,</p>
<p>scheduling_strategy.node_affinity_scheduling_strategy().node_id(),</p>
<p>/*soft=*/false, /*spill_on_unavailable=*/false,</p>
<p>/*fail_on_unavailable=*/true));</p>
<p>}</p>
<p></code></p>
<p>Soft Affinity: Prefer specific node but allow spillback</p>
<code>scheduling_strategy.mutable_node_affinity_scheduling_strategy()-&gt;set_soft(true);
<p>// Will try preferred node first, then other nodes</p>
<p></code></p>
<h3>Fair Scheduling</h3>
<p>CPU Fair Scheduling: Prevents starvation across scheduling classes</p>
<code>// From src/ray/raylet/local_task_manager.cc
<p>if (total_cpu_requests_ &gt; total_cpus) {</p>
<p>// Calculate fair share per scheduling class</p>
<p>double fair_share = total_cpus / num_classes_with_cpu;</p>
<p>// Apply throttling based on fair share</p>
<p>for (auto &amp;[scheduling_class, dispatch_queue] : tasks_to_dispatch_) {</p>
<p>double cpu_request = /* CPU required by this class */;</p>
<p>if (cpu_request &gt; fair_share) {</p>
<p>// Throttle this class</p>
<p>next_update_time = current_time + throttle_delay;</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h2>Actor Placement and Scheduling</h2>
<p>----------------------------------------</p>
<h3>Actor Scheduling Architecture</h3>
Location: <code>src/ray/gcs/gcs_server/gcs_actor_scheduler.cc</code>
<p>Ray provides two actor scheduling modes:</p>
<h4>1. GCS-Based Actor Scheduling</h4>
<code>void GcsActorScheduler::ScheduleByGcs(std::shared_ptr&lt;GcsActor&gt; actor) {
<p>// Create task for actor creation</p>
<p>auto task = std::make_shared&lt;RayTask&gt;(actor-&gt;GetCreationTaskSpecification());</p>
<p>// Use cluster task manager for scheduling</p>
<p>cluster_task_manager_.QueueAndScheduleTask(</p>
<p>std::move(task),</p>
<p>/*grant_or_reject*/ false,</p>
<p>/*is_selected_based_on_locality*/ false,</p>
<p>reply.get(),</p>
<p>send_reply_callback);</p>
<p>}</p>
<p></code></p>
<h4>2. Raylet-Based Actor Scheduling</h4>
<pre><code><code>void GcsActorScheduler::ScheduleByRaylet(std::shared_ptr&lt;GcsActor&gt; actor) {
// Select forwarding node
auto node_id = SelectForwardingNode(actor);
// Lease worker directly from node
LeaseWorkerFromNode(actor, node.value());
}
</code></code></pre>
<h3>Actor Resource Requirements</h3>
<p>Placement vs Execution Resources:</p>
<code>// From src/ray/common/task/task_spec.cc
<p>const auto &amp;resource_set = </p>
<p>(is_actor_creation_task &amp;&amp; should_report_placement_resources)</p>
<p>? GetRequiredPlacementResources()  // For scheduling decisions</p>
<p>: GetRequiredResources();          // For execution</p>
<p></code></p>
<p>Actor Creation Example:</p>
<code>@ray.remote(num_cpus=2, num_gpus=1, memory=1000)
<p>class MyActor:</p>
<p>def __init__(self):</p>
<p>pass</p>
<p>def method(self):</p>
<p>pass</p>
<h1>Actor placement considers both creation and method resources</h1>
<p>actor = MyActor.remote()</p>
<p></code></p>
<h3>Actor Lifecycle and Scheduling</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Actor Scheduling Considerations</h3>
<p>Resource Lifetime: Actors hold resources for their entire lifetime</p>
<code>if (task_spec.IsActorCreationTask()) {
<p>// The actor belongs to this worker now</p>
<p>worker-&gt;SetLifetimeAllocatedInstances(allocated_instances);</p>
<p>} else {</p>
<p>worker-&gt;SetAllocatedInstances(allocated_instances);</p>
<p>}</p>
<p></code></p>
<p>Scheduling Class: Actors use placement resources for scheduling decisions</p>
<code>TEST(TaskSpecTest, TestActorSchedulingClass) {
<p>// Actor's scheduling class determined by placement resources</p>
<p>TaskSpecification actor_task(actor_task_spec_proto);</p>
<p>TaskSpecification regular_task(regular_task_spec_proto);</p>
<p>ASSERT_EQ(regular_task.GetSchedulingClass(), actor_task.GetSchedulingClass());</p>
<p>}</p>
<p></code></p>
<h2>Placement Group Scheduling</h2>
<p>----------------------------------------</p>
<h3>Placement Group Architecture</h3>
Location: <code>src/ray/gcs/gcs_server/gcs_placement_group_scheduler.cc</code>
<p>Placement groups enable gang scheduling of related resources across multiple nodes.</p>
<code>class GcsPlacementGroupScheduler {
<p>void SchedulePlacementGroup(</p>
<p>std::shared_ptr&lt;GcsPlacementGroup&gt; placement_group,</p>
<p>PGSchedulingFailureCallback failure_callback,</p>
<p>PGSchedulingSuccessfulCallback success_callback);</p>
<p>}</p>
<p></code></p>
<h3>Bundle Specification</h3>
Location: <code>src/ray/common/bundle_spec.h</code>
<code>class BundleSpecification {
<p>BundleID BundleId() const;</p>
<p>PlacementGroupID PlacementGroupId() const;</p>
<p>NodeID NodeId() const;</p>
<p>int64_t Index() const;</p>
<p>const ResourceRequest &amp;GetRequiredResources() const;</p>
<p>const absl::flat_hash_map&lt;std::string, double&gt; &amp;GetFormattedResources() const;</p>
<p>};</p>
<p></code></p>
<h3>Placement Strategies</h3>
<h4>PACK Strategy</h4>
<pre><code><code>case rpc::PlacementStrategy::PACK:
return SchedulingOptions::BundlePack(max_cpu_fraction_per_node);
</code></code></pre>
<p>‚Ä¢ Goal: Minimize number of nodes used</p>
<p>‚Ä¢ Use Case: Maximize locality, minimize network overhead</p>
<p>‚Ä¢ Algorithm: First-fit decreasing binpacking</p>
<h4>SPREAD Strategy</h4>
<pre><code><code>case rpc::PlacementStrategy::SPREAD:
return SchedulingOptions::BundleSpread(max_cpu_fraction_per_node);
</code></code></pre>
<p>‚Ä¢ Goal: Distribute bundles across nodes</p>
<p>‚Ä¢ Use Case: Fault tolerance, load distribution</p>
<p>‚Ä¢ Algorithm: Round-robin placement with load balancing</p>
<h4>STRICT_PACK Strategy</h4>
<pre><code><code>case rpc::PlacementStrategy::STRICT_PACK:
return SchedulingOptions::BundleStrictPack(
max_cpu_fraction_per_node,
soft_target_node_id);
</code></code></pre>
<p>‚Ä¢ Goal: All bundles on single node (if possible)</p>
<p>‚Ä¢ Use Case: Shared memory, minimal latency</p>
<p>‚Ä¢ Algorithm: Single-node placement with fallback</p>
<h4>STRICT_SPREAD Strategy</h4>
<pre><code><code>case rpc::PlacementStrategy::STRICT_SPREAD:
return SchedulingOptions::BundleStrictSpread(
max_cpu_fraction_per_node, 
CreateSchedulingContext(placement_group_id));
</code></code></pre>
<p>‚Ä¢ Goal: Each bundle on different node</p>
<p>‚Ä¢ Use Case: Maximum fault tolerance</p>
<p>‚Ä¢ Algorithm: One bundle per node constraint</p>
<h3>Bundle Scheduling Algorithm</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Bundle Resource Formatting</h3>
<p>Ray formats placement group resources with special naming:</p>
<code>// From src/ray/common/bundle_spec.h
<p>std::string FormatPlacementGroupResource(</p>
<p>const std::string &amp;original_resource_name,</p>
<p>const std::string &amp;group_id_str,</p>
<p>int64_t bundle_index) {</p>
<p>if (bundle_index == -1) {</p>
<p>// Wildcard resource: CPU_group_&lt;group_id&gt;</p>
<p>return original_resource_name + &quot;_group_&quot; + group_id_str;</p>
<p>} else {</p>
<p>// Indexed resource: CPU_group_&lt;bundle_index&gt;_&lt;group_id&gt;</p>
<p>return original_resource_name + &quot;_group_&quot; + </p>
<p>std::to_string(bundle_index) + &quot;_&quot; + group_id_str;</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h3>CPU Fraction Limits</h3>
<p>Purpose: Prevent placement groups from monopolizing nodes</p>
<code>bool AllocationWillExceedMaxCpuFraction(
<p>const NodeResources &amp;node_resources,</p>
<p>const ResourceRequest &amp;bundle_resource_request,</p>
<p>double max_cpu_fraction_per_node,</p>
<p>double available_cpus_before_current_pg_request) {</p>
<p>if (max_cpu_fraction_per_node == 1.0) {</p>
<p>return false; // No limit</p>
<p>}</p>
<p>auto max_reservable_cpus = </p>
<p>max_cpu_fraction_per_node * node_resources.total.Get(cpu_id).Double();</p>
<p>// Ensure at least 1 CPU is excluded from placement groups</p>
<p>if (max_reservable_cpus &gt; total_cpus - 1) {</p>
<p>max_reservable_cpus = total_cpus - 1;</p>
<p>}</p>
<p>return cpus_used_by_pg_after &gt; max_reservable_cpus;</p>
<p>}</p>
<p></code></p>
<h3>Placement Group Lifecycle</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Scheduling Strategies</h2>
<p>----------------------------------------</p>
<h3>Strategy Types and Implementation</h3>
Ray supports multiple scheduling strategies through the <code>rpc::SchedulingStrategy</code> protocol buffer:
<code>// From src/ray/raylet/scheduling/cluster_resource_scheduler.cc
<p>scheduling::NodeID ClusterResourceScheduler::GetBestSchedulableNode(</p>
<p>const ResourceRequest &amp;resource_request,</p>
<p>const rpc::SchedulingStrategy &amp;scheduling_strategy,</p>
<p>bool actor_creation,</p>
<p>bool force_spillback,</p>
<p>const std::string &amp;preferred_node_id,</p>
<p>int64_t *total_violations,</p>
<p>bool *is_infeasible) {</p>
<p>if (scheduling_strategy.scheduling_strategy_case() ==</p>
<p>rpc::SchedulingStrategy::SchedulingStrategyCase::kSpreadSchedulingStrategy) {</p>
<p>best_node_id = scheduling_policy_-&gt;Schedule(</p>
<p>resource_request,</p>
<p>SchedulingOptions::Spread(force_spillback, force_spillback));</p>
<p>} else if (scheduling_strategy.scheduling_strategy_case() ==</p>
<p>rpc::SchedulingStrategy::SchedulingStrategyCase::</p>
<p>kNodeAffinitySchedulingStrategy) {</p>
<p>best_node_id = scheduling_policy_-&gt;Schedule(</p>
<p>resource_request,</p>
<p>SchedulingOptions::NodeAffinity(/* ... */));</p>
<p>} else if (scheduling_strategy.has_node_label_scheduling_strategy()) {</p>
<p>best_node_id = scheduling_policy_-&gt;Schedule(</p>
<p>resource_request, </p>
<p>SchedulingOptions::NodeLabelScheduling(scheduling_strategy));</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h3>DEFAULT Strategy</h3>
<p>Implementation: Hybrid policy with configurable parameters</p>
<code># Environment variables controlling DEFAULT strategy
<p>RAY_scheduler_spread_threshold = 0.5      # Utilization threshold</p>
<p>RAY_scheduler_top_k_fraction = 0.2        # Top-k selection ratio  </p>
<p>RAY_scheduler_top_k_absolute = 5          # Minimum top-k count</p>
<p></code></p>
<p>Algorithm:</p>
<p>1. Calculate node scores based on resource utilization</p>
<p>2. Select top-k nodes with lowest scores</p>
<p>3. Randomly choose from top-k for load balancing</p>
<h3>SPREAD Strategy</h3>
<p>Purpose: Maximize distribution across nodes</p>
<code>import ray
<p>@ray.remote(scheduling_strategy=&quot;SPREAD&quot;)</p>
<p>def distributed_task():</p>
<p>return &quot;Running on different nodes&quot;</p>
<h1>Tasks will be distributed across available nodes</h1>
<p>futures = [distributed_task.remote() for _ in range(100)]</p>
<p></code></p>
<p>Implementation Details:</p>
<p>- Prioritizes nodes with fewer running tasks</p>
<p>- Considers resource utilization as secondary factor</p>
<p>- Useful for embarrassingly parallel workloads</p>
<h3>Node Affinity Strategy</h3>
<p>Hard Affinity: Must run on specific node</p>
<code>import ray
<p>from ray.util.scheduling_strategies import NodeAffinitySchedulingStrategy</p>
<p>@ray.remote(scheduling_strategy=NodeAffinitySchedulingStrategy(</p>
<p>node_id=&quot;specific-node-id&quot;, </p>
<p>soft=False</p>
<p>))</p>
<p>def pinned_task():</p>
<p>return &quot;Must run on specific node&quot;</p>
<p></code></p>
<p>Soft Affinity: Prefer specific node with fallback</p>
<code>@ray.remote(scheduling_strategy=NodeAffinitySchedulingStrategy(
<p>node_id=&quot;preferred-node-id&quot;, </p>
<p>soft=True</p>
<p>))</p>
<p>def preferred_task():</p>
<p>return &quot;Prefers specific node but can run elsewhere&quot;</p>
<p></code></p>
<h3>Placement Group Strategy</h3>
<p>Bundle-Specific Scheduling:</p>
<code>import ray
<p>from ray.util.placement_group import placement_group</p>
<p>from ray.util.scheduling_strategies import PlacementGroupSchedulingStrategy</p>
<h1>Create placement group</h1>
<p>pg = placement_group([{&quot;CPU&quot;: 2}, {&quot;CPU&quot;: 2}], strategy=&quot;PACK&quot;)</p>
<p>@ray.remote(scheduling_strategy=PlacementGroupSchedulingStrategy(</p>
<p>placement_group=pg,</p>
<p>placement_group_bundle_index=0</p>
<p>))</p>
<p>def task_on_bundle_0():</p>
<p>return &quot;Running on bundle 0&quot;</p>
<p>@ray.remote(scheduling_strategy=PlacementGroupSchedulingStrategy(</p>
<p>placement_group=pg,</p>
<p>placement_group_bundle_index=-1  # Any bundle</p>
<p>))</p>
<p>def task_on_any_bundle():</p>
<p>return &quot;Running on any available bundle&quot;</p>
<p></code></p>
<h2>Node Affinity and Label-Based Scheduling</h2>
<p>----------------------------------------</p>
<h3>Node Label Scheduling Policy</h3>
Location: <code>src/ray/raylet/scheduling/policy/node_label_scheduling_policy.cc</code>
<p>Ray supports sophisticated label-based scheduling for fine-grained node selection:</p>
<code>scheduling::NodeID NodeLabelSchedulingPolicy::Schedule(
<p>const ResourceRequest &amp;resource_request,</p>
<p>SchedulingOptions options) {</p>
<p>// 1. Select feasible nodes</p>
<p>auto hard_match_nodes = SelectFeasibleNodes(resource_request);</p>
<p>// 2. Filter by hard expressions</p>
<p>if (node_label_scheduling_strategy.hard().expressions().size() &gt; 0) {</p>
<p>hard_match_nodes = FilterNodesByLabelMatchExpressions(</p>
<p>hard_match_nodes, node_label_scheduling_strategy.hard());</p>
<p>}</p>
<p>// 3. Filter by soft expressions  </p>
<p>auto hard_and_soft_match_nodes = FilterNodesByLabelMatchExpressions(</p>
<p>hard_match_nodes, node_label_scheduling_strategy.soft());</p>
<p>return SelectBestNode(hard_match_nodes, hard_and_soft_match_nodes, resource_request);</p>
<p>}</p>
<p></code></p>
<h3>Label Matching Implementation</h3>
<pre><code><code>bool NodeLabelSchedulingPolicy::IsNodeMatchLabelExpression(
const Node &amp;node, const rpc::LabelMatchExpression &amp;expression) const {
const auto &amp;key = expression.key();
const auto &amp;operator_type = expression.operator_();
const auto &amp;values = expression.values();
switch (operator_type) {
case rpc::LabelMatchExpression::IN:
return IsNodeLabelInValues(node, key, values);
case rpc::LabelMatchExpression::NOT_IN:
return !IsNodeLabelInValues(node, key, values);
case rpc::LabelMatchExpression::EXISTS:
return IsNodeLabelKeyExists(node, key);
case rpc::LabelMatchExpression::DOES_NOT_EXIST:
return !IsNodeLabelKeyExists(node, key);
}
}
</code></code></pre>
<h3>Label Selector Usage</h3>
<pre><code><code>import ray
from ray.util.scheduling_strategies import NodeLabelSchedulingStrategy
<h1>Hard constraints (must match)</h1>
hard_constraints = {
&quot;ray.io/node-type&quot;: &quot;gpu-node&quot;,
&quot;zone&quot;: &quot;us-west-1a&quot;
}
<h1>Soft constraints (preferred)</h1>
soft_constraints = {
&quot;instance-type&quot;: &quot;p3.2xlarge&quot;
}
@ray.remote(scheduling_strategy=NodeLabelSchedulingStrategy(
hard=hard_constraints,
soft=soft_constraints
))
def gpu_task():
return &quot;Running on GPU node in preferred zone&quot;
</code></code></pre>
<h3>Node Label Management</h3>
<p>Static Labels: Set during node startup</p>
<code># Set node labels via environment
<p>export RAY_NODE_LABELS='{&quot;zone&quot;:&quot;us-west-1a&quot;,&quot;instance-type&quot;:&quot;m5.large&quot;}'</p>
<p>ray start --head</p>
<p></code></p>
<p>Dynamic Labels: Updated at runtime</p>
<code>// From cluster resource data
<p>struct NodeResources {</p>
<p>absl::flat_hash_map&lt;std::string, std::string&gt; labels;</p>
<p>bool HasRequiredLabels(const LabelSelector &amp;label_selector) const;</p>
<p>bool NodeLabelMatchesConstraint(const LabelConstraint &amp;constraint) const;</p>
<p>};</p>
<p></code></p>
<h2>Locality-Aware Scheduling</h2>
<p>----------------------------------------</p>
<h3>Locality-Aware Lease Policy</h3>
Location: <code>src/ray/core_worker/lease_policy.cc</code>
<p>Ray implements data locality-aware scheduling to minimize data movement:</p>
<code>std::pair&lt;rpc::Address, bool&gt; LocalityAwareLeasePolicy::GetBestNodeForTask(
<p>const TaskSpecification &amp;spec) {</p>
<p>// Check for explicit scheduling strategies first</p>
<p>if (spec.IsSpreadSchedulingStrategy() || spec.IsNodeAffinitySchedulingStrategy()) {</p>
<p>return std::make_pair(fallback_rpc_address_, false);</p>
<p>}</p>
<p>// Pick node based on locality</p>
<p>if (auto node_id = GetBestNodeIdForTask(spec)) {</p>
<p>if (auto addr = node_addr_factory_(node_id.value())) {</p>
<p>return std::make_pair(addr.value(), true);</p>
<p>}</p>
<p>}</p>
<p>return std::make_pair(fallback_rpc_address_, false);</p>
<p>}</p>
<p></code></p>
<h3>Locality Calculation</h3>
<p>Criteria: Node with most object bytes local</p>
<code>std::optional&lt;NodeID&gt; LocalityAwareLeasePolicy::GetBestNodeIdForTask(
<p>const TaskSpecification &amp;spec) {</p>
<p>const auto &amp;dependencies = spec.GetDependencies();</p>
<p>if (dependencies.empty()) {</p>
<p>return std::nullopt;</p>
<p>}</p>
<p>// Calculate locality scores for each node</p>
<p>absl::flat_hash_map&lt;NodeID, int64_t&gt; locality_scores;</p>
<p>for (const auto &amp;obj_id : dependencies) {</p>
<p>auto locality_data = locality_data_provider_.GetLocalityData(obj_id);</p>
<p>for (const auto &amp;node_id : locality_data.nodes_containing_object) {</p>
<p>locality_scores[node_id] += locality_data.object_size;</p>
<p>}</p>
<p>}</p>
<p>// Return node with highest locality score</p>
<p>return GetNodeWithMaxScore(locality_scores);</p>
<p>}</p>
<p></code></p>
<h3>Locality vs Strategy Priority</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Locality Testing</h3>
<code>// From src/ray/tests/test_scheduling.py
<p>def test_locality_aware_leasing(ray_start_cluster):</p>
<p>@ray.remote(resources={&quot;pin&quot;: 1})</p>
<p>def non_local():</p>
<p>return ray._private.worker.global_worker.node.unique_id</p>
<p>@ray.remote</p>
<p>def f(x):</p>
<p>return ray._private.worker.global_worker.node.unique_id</p>
<h1>Test that task f() runs on the same node as non_local()</h1>
<h1>due to data locality</h1>
<p>assert ray.get(f.remote(non_local.remote())) == non_local_node.unique_id</p>
<p></code></p>
<h2>Cluster Resource Scheduling</h2>
<p>----------------------------------------</p>
<h3>Cluster Resource Manager</h3>
Location: <code>src/ray/raylet/scheduling/cluster_resource_manager.h</code>
<p>Maintains global view of cluster resources:</p>
<code>class ClusterResourceManager {
<p>// Add or update node resources</p>
<p>void AddOrUpdateNode(scheduling::NodeID node_id,</p>
<p>const NodeResources &amp;node_resources);</p>
<p>// Check resource availability</p>
<p>bool HasAvailableResources(scheduling::NodeID node_id,</p>
<p>const ResourceRequest &amp;resource_request) const;</p>
<p>// Resource allocation</p>
<p>bool SubtractNodeAvailableResources(scheduling::NodeID node_id,</p>
<p>const ResourceRequest &amp;resource_request);</p>
<p>};</p>
<p></code></p>
<h3>Resource Synchronization</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Resource Reporting</h3>
Location: <code>src/ray/raylet/scheduling/scheduler_resource_reporter.cc</code>
<code>void SchedulerResourceReporter::FillResourceUsage(rpc::ResourcesData &amp;data) const {
<p>// Report resource demands by shape</p>
<p>auto resource_load_by_shape = data.mutable_resource_load_by_shape();</p>
<p>for (const auto &amp;[scheduling_class, task_queue] : tasks_to_schedule_) {</p>
<p>const auto &amp;resources = scheduling_class_descriptor.resource_set.GetResourceMap();</p>
<p>auto by_shape_entry = resource_load_by_shape-&gt;Add();</p>
<p>for (const auto &amp;resource : resources) {</p>
<p>(*by_shape_entry-&gt;mutable_shape())[resource.first] = resource.second;</p>
<p>}</p>
<p>by_shape_entry-&gt;set_num_ready_requests_queued(task_queue.size());</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h2>Autoscaler Integration</h2>
<p>----------------------------------------</p>
<h3>Resource Demand Scheduler</h3>
Location: <code>python/ray/autoscaler/v2/scheduler.py</code>
<p>The autoscaler uses sophisticated scheduling algorithms to determine cluster scaling decisions:</p>
<code>class ResourceDemandScheduler(IResourceScheduler):
<p>def schedule(self, request: SchedulingRequest) -&gt; SchedulingReply:</p>
<p>ctx = self.ScheduleContext.from_schedule_request(request)</p>
<h1>1. Enforce min workers per type</h1>
<p>self._enforce_min_workers_per_type(ctx)</p>
<h1>2. Enforce resource constraints</h1>
<p>infeasible_constraints = self._enforce_resource_constraints(</p>
<p>ctx, request.cluster_resource_constraints)</p>
<h1>3. Schedule gang resource requests</h1>
<p>infeasible_gang_requests = self._sched_gang_resource_requests(</p>
<p>ctx, request.gang_resource_requests)</p>
<h1>4. Schedule regular resource requests</h1>
<p>infeasible_requests = self._sched_resource_requests(</p>
<p>ctx, ResourceRequestUtil.ungroup_by_count(request.resource_requests))</p>
<h1>5. Enforce idle termination</h1>
<p>self._enforce_idle_termination(ctx)</p>
<p>return SchedulingReply(</p>
<p>to_launch=ctx.get_launch_requests(),</p>
<p>to_terminate=ctx.get_terminate_requests(),</p>
<p>infeasible_resource_requests=infeasible_requests,</p>
<p>infeasible_gang_resource_requests=infeasible_gang_requests,</p>
<p>infeasible_cluster_resource_constraints=infeasible_constraints</p>
<p>)</p>
<p></code></p>
<h3>Binpacking Algorithm</h3>
<pre><code><code>def _try_schedule(
ctx: ScheduleContext,
requests_to_sched: List[ResourceRequest],
resource_request_source: ResourceRequestSource,
) -&gt; Tuple[List[SchedulingNode], List[ResourceRequest]]:
<h1>Sort requests by complexity for better binpacking</h1>
def _sort_resource_request(req: ResourceRequest) -&gt; Tuple:
return (
len(req.placement_constraints),
len(req.resources_bundle.values()),
sum(req.resources_bundle.values()),
sorted(req.resources_bundle.items()),
)
requests_to_sched = sorted(
requests_to_sched, key=_sort_resource_request, reverse=True)
<h1>Try scheduling on existing nodes first</h1>
while len(requests_to_sched) &gt; 0 and len(existing_nodes) &gt; 0:
best_node, requests_to_sched, existing_nodes = \
self._sched_best_node(requests_to_sched, existing_nodes, resource_request_source)
if best_node is None:
break
target_nodes.append(best_node)
<h1>Try scheduling on new nodes</h1>
for node_type, num_available in node_type_available.items():
if num_available &gt; 0:
new_node = SchedulingNode.from_node_config(
ctx.get_node_type_configs()[node_type],
status=SchedulingNodeStatus.TO_LAUNCH)
<h1>Try to schedule remaining requests on new node</h1>
</code></code></pre>
<h3>Placement Group Autoscaling</h3>
<pre><code><code>def placement_groups_to_resource_demands(
pending_placement_groups: List[PlacementGroupTableData],
) -&gt; Tuple[List[ResourceDict], List[List[ResourceDict]]]:
resource_demand_vector = []
unconverted = []
for placement_group in pending_placement_groups:
shapes = [dict(bundle.unit_resources) for bundle in placement_group.bundles 
if bundle.node_id == b&quot;&quot;]  # Only unplaced bundles
if placement_group.strategy == PlacementStrategy.PACK:
resource_demand_vector.extend(shapes)
elif placement_group.strategy == PlacementStrategy.STRICT_PACK:
<h1>Combine all bundles into single demand</h1>
combined = collections.defaultdict(float)
for shape in shapes:
for label, quantity in shape.items():
combined[label] += quantity
resource_demand_vector.append(combined)
elif placement_group.strategy == PlacementStrategy.STRICT_SPREAD:
<h1>Cannot be converted - needs special handling</h1>
unconverted.append(shapes)
return resource_demand_vector, unconverted
</code></code></pre>
<h3>Autoscaler Configuration</h3>
<pre><code><code># Example autoscaler configuration
cluster_name: ray-cluster
max_workers: 100
upscaling_speed: 1.0
idle_timeout_minutes: 5
available_node_types:
ray.head.default:
min_workers: 0
max_workers: 0
resources: {&quot;CPU&quot;: 4}
ray.worker.cpu:
min_workers: 0
max_workers: 50
resources: {&quot;CPU&quot;: 8, &quot;memory&quot;: 32000000000}
ray.worker.gpu:
min_workers: 0
max_workers: 10
resources: {&quot;CPU&quot;: 16, &quot;GPU&quot;: 4, &quot;memory&quot;: 64000000000}
</code></code></pre>
<h2>Performance Characteristics</h2>
<p>----------------------------------------</p>
<h3>Scheduling Latency</h3>
<p>Typical Latencies:</p>
<p>- Local scheduling: 1-5ms</p>
<p>- Remote scheduling: 10-50ms</p>
<p>- Placement group creation: 100-1000ms</p>
<p>- Autoscaler response: 30-300s</p>
<h3>Scalability Metrics</h3>
<p>Cluster Size: Ray scheduling tested up to 1000+ nodes</p>
<p>Task Throughput: </p>
<p>- Simple tasks: 100K+ tasks/second</p>
<p>- Complex scheduling: 10K+ tasks/second</p>
<p>- Placement groups: 100+ groups/second</p>
<h3>Memory Usage</h3>
<p>Scheduler Memory Overhead:</p>
<code>// Per-node overhead in ClusterResourceManager
<p>struct NodeResources {</p>
<p>NodeResourceSet total;      // ~1KB per node</p>
<p>NodeResourceSet available; // ~1KB per node  </p>
<p>NodeResourceSet normal_task_resources; // ~1KB per node</p>
<p>absl::flat_hash_map&lt;std::string, std::string&gt; labels; // Variable</p>
<p>};</p>
<p>// Total: ~3KB + labels per node</p>
<p></code></p>
<p>Task Queue Memory:</p>
<code>// Per-task overhead in scheduling queues
<p>class Work {</p>
<p>RayTask task;                    // ~2KB per task</p>
<p>TaskResourceInstances allocated; // ~500B per task</p>
<p>WorkStatus state;               // ~100B per task</p>
<p>};</p>
<p>// Total: ~2.6KB per queued task</p>
<p></code></p>
<h3>Performance Optimization</h3>
<p>Top-K Selection: Reduces scheduling complexity from O(N) to O(K)</p>
<code>// Default configuration
<p>RAY_scheduler_top_k_fraction = 0.2  // 20% of nodes</p>
<p>RAY_scheduler_top_k_absolute = 5    // Minimum 5 nodes</p>
<p></code></p>
<p>Caching: Resource views cached to avoid repeated calculations</p>
<code>class ClusterResourceManager {
<p>// Cached resource calculations</p>
<p>mutable absl::flat_hash_map&lt;scheduling::NodeID, float&gt; utilization_cache_;</p>
<p>mutable int64_t cache_timestamp_;</p>
<p>};</p>
<p></code></p>
<h2>Configuration and Tuning</h2>
<p>----------------------------------------</p>
<h3>Environment Variables</h3>
<p>Core Scheduling:</p>
<code># Spread threshold for hybrid scheduling
<p>export RAY_scheduler_spread_threshold=0.5</p>
<h1>Top-k node selection</h1>
<p>export RAY_scheduler_top_k_fraction=0.2</p>
<p>export RAY_scheduler_top_k_absolute=5</p>
<h1>Worker management</h1>
<p>export RAY_num_workers_soft_limit=1000</p>
<p>export RAY_maximum_startup_concurrency=10</p>
<p></code></p>
<p>Resource Management:</p>
<code># Object store memory scheduling
<p>export RAY_object_store_memory=1000000000</p>
<h1>Pull manager configuration  </h1>
<p>export RAY_object_manager_pull_timeout_ms=10000</p>
<p>export RAY_object_manager_max_bytes_in_flight=100000000</p>
<p></code></p>
<p>Placement Groups:</p>
<code># CPU fraction limits
<p>export RAY_placement_group_max_cpu_fraction_per_node=0.8</p>
<h1>Bundle scheduling timeout</h1>
<p>export RAY_placement_group_bundle_resource_timeout_s=30</p>
<p></code></p>
<h3>Runtime Configuration</h3>
<p>Cluster Resource Constraints:</p>
<code>import ray
<h1>Set cluster-wide resource constraints</h1>
<p>ray.autoscaler.sdk.request_resources([</p>
<p>{&quot;CPU&quot;: 100, &quot;GPU&quot;: 10},  # Ensure cluster can handle this workload</p>
<p>{&quot;memory&quot;: 1000000000}    # Minimum memory requirement</p>
<p>])</p>
<p></code></p>
<p>Node Type Configuration:</p>
<code># Configure node types for autoscaling
<p>node_config = {</p>
<p>&quot;ray.worker.cpu&quot;: {</p>
<p>&quot;min_workers&quot;: 2,</p>
<p>&quot;max_workers&quot;: 20,</p>
<p>&quot;resources&quot;: {&quot;CPU&quot;: 8, &quot;memory&quot;: 32000000000}</p>
<p>},</p>
<p>&quot;ray.worker.gpu&quot;: {</p>
<p>&quot;min_workers&quot;: 0, </p>
<p>&quot;max_workers&quot;: 5,</p>
<p>&quot;resources&quot;: {&quot;CPU&quot;: 16, &quot;GPU&quot;: 4, &quot;memory&quot;: 64000000000}</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h3>Performance Tuning</h3>
<p>For High Throughput:</p>
<code># Increase worker limits
<p>export RAY_num_workers_soft_limit=2000</p>
<p>export RAY_maximum_startup_concurrency=50</p>
<h1>Reduce scheduling overhead</h1>
<p>export RAY_scheduler_top_k_absolute=10</p>
<p>export RAY_scheduler_spread_threshold=0.3</p>
<p></code></p>
<p>For Low Latency:</p>
<code># Prioritize local scheduling
<p>export RAY_scheduler_spread_threshold=0.8</p>
<p>export RAY_scheduler_top_k_fraction=0.1</p>
<h1>Reduce worker startup time</h1>
<p>export RAY_worker_lease_timeout_milliseconds=1000</p>
<p></code></p>
<p>For Large Clusters:</p>
<code># Optimize for scale
<p>export RAY_scheduler_top_k_fraction=0.1  # Top 10% of nodes</p>
<p>export RAY_raylet_report_resources_period_milliseconds=1000</p>
<p>export RAY_gcs_resource_report_poll_period_milliseconds=1000</p>
<p></code></p>
<h2>Best Practices</h2>
<p>----------------------------------------</p>
<h3>Task Scheduling</h3>
<p>1. Use Appropriate Scheduling Strategies:</p>
<code># For embarrassingly parallel workloads
<p>@ray.remote(scheduling_strategy=&quot;SPREAD&quot;)</p>
<p>def parallel_task(data):</p>
<p>return process(data)</p>
<h1>For data-dependent tasks (default locality-aware)</h1>
<p>@ray.remote</p>
<p>def dependent_task(large_object):</p>
<p>return analyze(large_object)</p>
<h1>For specific hardware requirements</h1>
<p>@ray.remote(scheduling_strategy=NodeAffinitySchedulingStrategy(</p>
<p>node_id=gpu_node_id, soft=True))</p>
<p>def gpu_task():</p>
<p>return train_model()</p>
<p></code></p>
<p>2. Resource Specification:</p>
<code># Be specific about resource requirements
<p>@ray.remote(num_cpus=2, num_gpus=1, memory=4000*1024*1024)</p>
<p>def resource_intensive_task():</p>
<p>return compute()</p>
<h1>Use custom resources for specialized hardware</h1>
<p>@ray.remote(resources={&quot;accelerator&quot;: 1})</p>
<p>def accelerated_task():</p>
<p>return specialized_compute()</p>
<p></code></p>
<h3>Actor Placement</h3>
<p>1. Consider Resource Lifetime:</p>
<code># Actors hold resources for their lifetime
<p>@ray.remote(num_cpus=4, num_gpus=1)</p>
<p>class ModelServer:</p>
<p>def __init__(self):</p>
<p>self.model = load_large_model()</p>
<p>def predict(self, data):</p>
<p>return self.model.predict(data)</p>
<h1>Create fewer, long-lived actors rather than many short-lived ones</h1>
<p>server = ModelServer.remote()</p>
<p></code></p>
<p>2. Use Placement Groups for Related Actors:</p>
<code># Group related actors together
<p>pg = placement_group([{&quot;CPU&quot;: 4}, {&quot;CPU&quot;: 4}, {&quot;CPU&quot;: 4}], strategy=&quot;PACK&quot;)</p>
<p>actors = [</p>
<p>Actor.options(scheduling_strategy=PlacementGroupSchedulingStrategy(</p>
<p>placement_group=pg, placement_group_bundle_index=i</p>
<p>)).remote() for i in range(3)</p>
<p>]</p>
<p></code></p>
<h3>Placement Group Design</h3>
<p>1. Choose Appropriate Strategies:</p>
<code># For tightly coupled workloads
<p>pg_pack = placement_group([{&quot;CPU&quot;: 2, &quot;GPU&quot;: 1}] * 4, strategy=&quot;PACK&quot;)</p>
<h1>For fault tolerance</h1>
<p>pg_spread = placement_group([{&quot;CPU&quot;: 2}] * 8, strategy=&quot;SPREAD&quot;)</p>
<h1>For strict requirements</h1>
<p>pg_strict = placement_group([{&quot;CPU&quot;: 4}] * 2, strategy=&quot;STRICT_SPREAD&quot;)</p>
<p></code></p>
<p>2. Bundle Size Optimization:</p>
<code># Avoid bundles larger than single node capacity
<h1>Bad: Bundle requires more than any node has</h1>
<p>bad_pg = placement_group([{&quot;CPU&quot;: 64, &quot;GPU&quot;: 8}])  # If max node has 32 CPU</p>
<h1>Good: Bundle fits on available nodes</h1>
<p>good_pg = placement_group([{&quot;CPU&quot;: 16, &quot;GPU&quot;: 2}] * 4)</p>
<p></code></p>
<h3>Autoscaler Optimization</h3>
<p>1. Configure Appropriate Limits:</p>
<code># Set realistic min/max workers
<p>available_node_types:</p>
<p>ray.worker.default:</p>
<p>min_workers: 2      # Always keep some capacity</p>
<p>max_workers: 100    # Prevent runaway scaling</p>
<p>upscaling_speed: 2.0  # Scale up aggressively</p>
<p></code></p>
<p>2. Use Resource Constraints:</p>
<code># Ensure cluster can handle expected workload
<p>ray.autoscaler.sdk.request_resources([</p>
<p>{&quot;CPU&quot;: 200, &quot;memory&quot;: 500000000000},  # Expected peak usage</p>
<p>])</p>
<p></code></p>
<h2>Troubleshooting</h2>
<p>----------------------------------------</p>
<h3>Common Scheduling Issues</h3>
<p>1. Tasks Stuck in Pending State:</p>
<p>Symptoms: Tasks remain in PENDING_SCHEDULING state</p>
<p>Causes:</p>
<p>- Insufficient cluster resources</p>
<p>- Infeasible resource requirements</p>
<p>- Node affinity to unavailable nodes</p>
<p>Debugging:</p>
<code># Check cluster resources
<p>print(ray.cluster_resources())</p>
<p>print(ray.available_resources())</p>
<h1>Check task resource requirements</h1>
<p>@ray.remote(num_cpus=1)</p>
<p>def debug_task():</p>
<p>return ray.get_runtime_context().get_assigned_resources()</p>
<h1>Check for infeasible tasks</h1>
<p>ray.autoscaler.sdk.request_resources([{&quot;CPU&quot;: 1000}])  # Will show if infeasible</p>
<p></code></p>
<p>2. Poor Load Balancing:</p>
<p>Symptoms: Some nodes overloaded while others idle</p>
<p>Causes:</p>
<p>- Inappropriate scheduling strategy</p>
<p>- Data locality overriding load balancing</p>
<p>- Sticky worker assignment</p>
<p>Solutions:</p>
<code># Use SPREAD strategy for better distribution
<p>@ray.remote(scheduling_strategy=&quot;SPREAD&quot;)</p>
<p>def distributed_task():</p>
<p>return compute()</p>
<h1>Adjust spread threshold</h1>
<p>import os</p>
<p>os.environ[&quot;RAY_scheduler_spread_threshold&quot;] = &quot;0.3&quot;</p>
<p></code></p>
<p>3. Placement Group Creation Failures:</p>
<p>Symptoms: Placement groups fail to create or timeout</p>
<p>Causes:</p>
<p>- Insufficient cluster capacity</p>
<p>- Conflicting resource constraints</p>
<p>- Network partitions</p>
<p>Debugging:</p>
<code>import ray
<p>from ray.util.placement_group import placement_group</p>
<h1>Check placement group status</h1>
<p>pg = placement_group([{&quot;CPU&quot;: 2}] * 4, strategy=&quot;STRICT_SPREAD&quot;)</p>
<p>print(pg.ready())  # False if creation failed</p>
<h1>Check bundle placement</h1>
<p>print(ray.util.placement_group_table())</p>
<p></code></p>
<h3>Performance Issues</h3>
<p>1. High Scheduling Latency:</p>
<p>Symptoms: Long delays between task submission and execution</p>
<p>Causes:</p>
<p>- Large cluster with inefficient node selection</p>
<p>- Complex placement constraints</p>
<p>- Resource fragmentation</p>
<p>Solutions:</p>
<code># Reduce top-k selection size
<p>export RAY_scheduler_top_k_fraction=0.1</p>
<h1>Increase spread threshold for faster local scheduling</h1>
<p>export RAY_scheduler_spread_threshold=0.7</p>
<p></code></p>
<p>2. Memory Issues in Scheduler:</p>
<p>Symptoms: Raylet OOM, high memory usage in scheduling components</p>
<p>Causes:</p>
<p>- Large number of queued tasks</p>
<p>- Memory leaks in scheduling data structures</p>
<p>- Excessive resource tracking overhead</p>
<p>Solutions:</p>
<code># Limit concurrent tasks
<p>export RAY_num_workers_soft_limit=500</p>
<h1>Reduce resource reporting frequency</h1>
<p>export RAY_raylet_report_resources_period_milliseconds=5000</p>
<p></code></p>
<h3>Debugging Tools</h3>
<p>1. Ray Status Commands:</p>
<code># Check cluster state
<p>ray status</p>
<h1>Check resource usage</h1>
<p>ray status --verbose</p>
<h1>Check placement groups</h1>
<p>ray status --placement-groups</p>
<p></code></p>
<p>2. Programmatic Debugging:</p>
<code># Check scheduling state
<p>import ray._private.state as state</p>
<h1>Get pending tasks</h1>
<p>pending_tasks = state.tasks(filters=[(&quot;state&quot;, &quot;=&quot;, &quot;PENDING_SCHEDULING&quot;)])</p>
<h1>Get resource usage by node</h1>
<p>nodes = state.nodes()</p>
<p>for node in nodes:</p>
<p>print(f&quot;Node {node['node_id']}: {node['resources_total']}&quot;)</p>
<p></code></p>
<p>3. Logging Configuration:</p>
<code># Enable debug logging for scheduling
<p>export RAY_LOG_LEVEL=DEBUG</p>
<p>export RAY_BACKEND_LOG_LEVEL=DEBUG</p>
<h1>Focus on specific components</h1>
<p>export RAY_LOG_TO_STDERR=1</p>
<p>ray start --head --log-to-driver</p>
<p></code></p>
<h3>Monitoring and Observability</h3>
<p>1. Metrics Collection:</p>
<code># Custom metrics for scheduling performance
<p>import ray</p>
<p>from ray.util.metrics import Counter, Histogram</p>
<p>scheduling_latency = Histogram(</p>
<p>&quot;ray_scheduling_latency_seconds&quot;,</p>
<p>description=&quot;Time from task submission to scheduling&quot;,</p>
<p>boundaries=[0.001, 0.01, 0.1, 1.0, 10.0]</p>
<p>)</p>
<p>task_queue_size = Counter(</p>
<p>&quot;ray_task_queue_size&quot;,</p>
<p>description=&quot;Number of tasks in scheduling queue&quot;</p>
<p>)</p>
<p></code></p>
<p>2. Dashboard Integration:</p>
<p>- Use Ray Dashboard for real-time cluster monitoring</p>
<p>- Monitor resource utilization trends</p>
<p>- Track placement group creation success rates</p>
<p>- Observe task scheduling patterns</p>
<p>This comprehensive guide covers Ray's distributed scheduling system from architecture to implementation details, providing developers and operators with the knowledge needed to effectively use and optimize Ray's scheduling capabilities in production environments.</p>

<div class="page-break"></div>
<h1>Part III: Advanced Ray Systems</h1>
<p>============================================================</p>
<h1>Chapter 10: Autoscaling System</h1>
<p>============================================================</p>
<h1>Ray Autoscaling - Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Autoscaling Architecture Overview</p>
<p>‚Ä¢ Core Autoscaling Components</p>
<p>‚Ä¢ Resource Demand Detection</p>
<p>‚Ä¢ Node Lifecycle Management</p>
<p>‚Ä¢ Scheduling and Binpacking Algorithms</p>
<p>‚Ä¢ Cloud Provider Integration</p>
<p>‚Ä¢ Autoscaler Policies and Strategies</p>
<p>‚Ä¢ Load Metrics and Monitoring</p>
<p>‚Ä¢ Placement Group Autoscaling</p>
<p>‚Ä¢ Resource Constraints and Limits</p>
<p>‚Ä¢ Multi-Cloud and Hybrid Deployments</p>
<p>‚Ä¢ Performance Optimization</p>
<p>‚Ä¢ Configuration and Tuning</p>
<p>‚Ä¢ Production Deployment</p>
<p>‚Ä¢ Troubleshooting and Debugging</p>
<p>‚Ä¢ Best Practices</p>
<p>‚Ä¢ Advanced Topics</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>Ray's autoscaling system is like having a smart assistant that watches your computing workload and automatically adjusts your cluster size. When you have more work to do, it adds more machines. When things quiet down, it removes unused machines to save money. Think of it as an intelligent resource manager that ensures you always have just the right amount of computing power for your needs.</p>
<h3>What Makes Ray Autoscaling Special?</h3>
<p>Smart Decision Making: Unlike simple autoscalers that just count CPU usage, Ray's autoscaler understands the specific resources your tasks need - CPUs, GPUs, memory, and custom resources. It can predict exactly what type of machines you need before you run out of capacity.</p>
<p>Lightning Fast: The autoscaler can make scaling decisions in seconds, not minutes. It doesn't wait for machines to become overloaded - it anticipates demand and scales proactively.</p>
<p>Cost Efficient: By understanding your workload patterns, it minimizes cloud costs by spinning up the cheapest combination of machines that can handle your work.</p>
<p>Multi-Cloud Ready: Works seamlessly across AWS, GCP, Azure, Kubernetes, and even your local data center.</p>
<h3>Core Features</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>‚Ä¢ Resource-Aware Scaling: Understands your exact compute needs (CPU, GPU, memory)</p>
<p>‚Ä¢ Placement Group Support: Handles complex multi-node workloads that need specific arrangements</p>
<p>‚Ä¢ Intelligent Binpacking: Finds the most cost-effective way to fit your workload</p>
<p>‚Ä¢ Preemptible Instance Support: Uses cheaper spot/preemptible instances when appropriate</p>
<p>‚Ä¢ Custom Resource Types: Supports specialized hardware like TPUs, FPGAs, or custom accelerators</p>
<h2>Autoscaling Architecture Overview</h2>
<p>----------------------------------------</p>
<p>Think of Ray's autoscaling system as a well-orchestrated team where each component has a specific job, but they all work together seamlessly.</p>
<h3>The Big Picture: How It All Works Together</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>What Happens During Autoscaling (In Plain English)</h3>
<p>‚Ä¢ </p>
<p>üëÄ Watching Phase: The system continuously monitors your cluster, tracking how many tasks are waiting, what resources they need, and how busy each machine is.</p>
<p>‚Ä¢ </p>
<p>ü§î Thinking Phase: When it notices unmet demand, the autoscaler calculates the optimal mix of machines to add, considering costs, availability, and your constraints.</p>
<p>‚Ä¢ </p>
<p>üöÄ Acting Phase: It launches new machines through cloud APIs, installs Ray software, and integrates them into your cluster.</p>
<p>‚Ä¢ </p>
<p>üßπ Cleanup Phase: When machines sit idle too long, it safely removes them to save costs.</p>
<h3>Multi-Level Decision Making</h3>
<p>Ray's autoscaler operates at multiple levels to make optimal decisions:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Core Autoscaling Components</h2>
<p>----------------------------------------</p>
<p>Let's dive into the key players that make Ray's autoscaling system work. Think of these as different departments in a company, each with specific responsibilities.</p>
<h3>1. StandardAutoscaler - The Main Controller</h3>
Location: <code>python/ray/autoscaler/_private/autoscaler.py</code>
<p>This is the "CEO" of the autoscaling system - it coordinates everything and makes the final decisions.</p>
<code>class StandardAutoscaler:
<p>def __init__(self, config_reader, load_metrics, gcs_client, ...):</p>
<h1>The brain of the operation</h1>
<p>self.provider = self._get_node_provider(provider_config, cluster_name)</p>
<p>self.resource_demand_scheduler = ResourceDemandScheduler(...)</p>
<p>self.load_metrics = load_metrics</p>
<h1>Key configuration settings</h1>
<p>self.max_workers = config.get(&quot;max_workers&quot;, 0)</p>
<p>self.upscaling_speed = config.get(&quot;upscaling_speed&quot;, 1.0)</p>
<p>self.idle_timeout_minutes = config.get(&quot;idle_timeout_minutes&quot;, 5)</p>
<p></code></p>
<p>What It Does (In Simple Terms):</p>
<p>- Wakes up every few seconds to check if the cluster needs changes</p>
<p>- Decides when to add new machines (scale up)</p>
<p>- Decides when to remove idle machines (scale down)</p>
<p>- Ensures the cluster never exceeds your budget or size limits</p>
<p>Key Responsibilities:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>2. ResourceDemandScheduler - The Smart Planner</h3>
Location: <code>python/ray/autoscaler/_private/resource_demand_scheduler.py</code>
<p>This component is like a smart logistics coordinator that figures out the most efficient way to arrange your computing resources.</p>
<code>class ResourceDemandScheduler:
<p>def get_nodes_to_launch(self, </p>
<p>resource_demands,           # What you need</p>
<p>unused_resources_by_ip,     # What's available</p>
<p>pending_placement_groups,   # Complex arrangements</p>
<p>max_resources_by_ip):       # Machine capacities</p>
<h1>Step 1: Understand current cluster state</h1>
<p>node_resources, node_type_counts = self.calculate_node_resources(...)</p>
<h1>Step 2: Respect minimum worker requirements</h1>
<p>adjusted_min_workers = self._add_min_workers_nodes(...)</p>
<h1>Step 3: Handle placement groups (complex workloads)</h1>
<p>spread_pg_nodes = self.reserve_and_allocate_spread(...)</p>
<h1>Step 4: Use &quot;bin packing&quot; to find optimal machine mix</h1>
<p>nodes_to_add, unfulfilled = get_nodes_for(...)</p>
<p>return total_nodes_to_add, final_unfulfilled</p>
<p></code></p>
<p>The Bin Packing Magic: Think of this like playing Tetris with cloud machines. You have different shaped "resource blocks" (your tasks) and different sized "containers" (machine types). The scheduler finds the combination that wastes the least space and costs the least money.</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>3. LoadMetrics - The Cluster Monitor</h3>
Location: <code>python/ray/autoscaler/_private/load_metrics.py</code>
<p>This is like having a health monitor attached to your cluster that constantly reports vital signs.</p>
<code>class LoadMetrics:
<p>def __init__(self):</p>
<h1>Tracks what resources each machine has</h1>
<p>self.static_resources_by_ip = {}      # Total capacity</p>
<p>self.dynamic_resources_by_ip = {}     # Currently available</p>
<h1>Tracks what work is waiting</h1>
<p>self.pending_resource_requests = []   # Individual tasks</p>
<p>self.pending_placement_groups = []    # Complex arrangements</p>
<h1>Tracks cluster health</h1>
<p>self.last_heartbeat_time_by_ip = {}   # When we last heard from nodes</p>
<p>self.last_heartbeat_failed = {}       # Which nodes are unresponsive</p>
<p></code></p>
<p>What It Monitors:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>4. Node Providers - The Cloud Connectors</h3>
Location: <code>python/ray/autoscaler/_private/providers.py</code>
<p>These are like specialized translators that know how to talk to different cloud providers. Each provider speaks its own "language" (API), but Ray abstracts this complexity.</p>
<code># AWS Provider
<p>class AWSNodeProvider(NodeProvider):</p>
<p>def create_node(self, node_config, tags, count):</p>
<h1>Launches EC2 instances using AWS API</h1>
<p>response = self.ec2.run_instances(</p>
<p>ImageId=node_config[&quot;ImageId&quot;],</p>
<p>InstanceType=node_config[&quot;InstanceType&quot;],</p>
<p>MinCount=count, MaxCount=count,</p>
<p>SubnetId=node_config[&quot;SubnetId&quot;]</p>
<p>)</p>
<p>return [instance.id for instance in response[&quot;Instances&quot;]]</p>
<h1>GCP Provider  </h1>
<p>class GCPNodeProvider(NodeProvider):</p>
<p>def create_node(self, node_config, tags, count):</p>
<h1>Launches Compute Engine instances using GCP API</h1>
<p>operation = self.compute.instances().insert(</p>
<p>project=self.project_id,</p>
<p>zone=self.zone,</p>
<p>body=instance_config</p>
<p>).execute()</p>
<p>return operation[&quot;targetId&quot;]</p>
<p></code></p>
<p>Supported Cloud Providers:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>5. GCS Autoscaler State Manager - The Central Coordinator</h3>
Location: <code>src/ray/gcs/gcs_server/gcs_autoscaler_state_manager.cc</code>
<p>This component runs inside Ray's Global Control Service (GCS) and acts as the central hub for all autoscaling information.</p>
<code>class GcsAutoscalerStateManager {
<p>void UpdateResourceLoadAndUsage(rpc::ResourcesData data) {</p>
<p>// Receives resource reports from all nodes</p>
<p>NodeID node_id = NodeID::FromBinary(data.node_id());</p>
<p>node_resource_info_[node_id] = std::move(data);</p>
<p>}</p>
<p>void GetPendingResourceRequests(rpc::autoscaler::ClusterResourceState *state) {</p>
<p>// Aggregates demand from all nodes</p>
<p>auto aggregate_load = GetAggregatedResourceLoad();</p>
<p>for (const auto &amp;[shape, demand] : aggregate_load) {</p>
<p>if (demand.num_ready_requests_queued() &gt; 0) {</p>
<p>// Add to autoscaling demand</p>
<p>auto pending_req = state-&gt;add_pending_resource_requests();</p>
<p>pending_req-&gt;set_count(demand.num_ready_requests_queued());</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p>};</p>
<p></code></p>
<p>Role in the System:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Resource Demand Detection</h2>
<p>----------------------------------------</p>
<p>Understanding how Ray detects and measures resource demand is crucial because this drives all autoscaling decisions. Think of it like a restaurant that needs to predict how many customers will arrive and what they'll order.</p>
<h3>How Ray Sees Resource Demand</h3>
<p>Ray tracks demand at multiple levels, each providing different insights:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Resource Demand Aggregation Process</h3>
<p>Here's how Ray collects and processes demand information:</p>
<code># From python/ray/autoscaler/_private/load_metrics.py
<p>class LoadMetrics:</p>
<p>def summary(self) -&gt; LoadMetricsSummary:</p>
<h1>Step 1: Collect demand from each node's queued tasks</h1>
<p>aggregate_load = {}</p>
<p>for node_ip, resource_data in self.resource_usage_by_ip.items():</p>
<p>for resource_shape, demand in resource_data.items():</p>
<p>total_demand = (demand.num_ready_requests_queued() + </p>
<p>demand.num_infeasible_requests_queued() +</p>
<p>demand.backlog_size())</p>
<p>if total_demand &gt; 0:</p>
<p>aggregate_load[resource_shape] = total_demand</p>
<h1>Step 2: Add placement group demands</h1>
<p>pg_demands = self._get_placement_group_demands()</p>
<h1>Step 3: Add explicit resource requests</h1>
<p>explicit_requests = self.resource_requests or []</p>
<p>return LoadMetricsSummary(</p>
<p>resource_demand=aggregate_load,</p>
<p>pg_demand=pg_demands,</p>
<p>request_demand=explicit_requests</p>
<p>)</p>
<p></code></p>
<h3>Types of Resource Shapes</h3>
<p>Ray thinks about resources in "shapes" - specific combinations of resources that tasks need:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Real-Time Demand Tracking</h3>
<p>The GCS continuously receives updates from all cluster nodes about their resource usage and pending work:</p>
<code>// From src/ray/gcs/gcs_server/gcs_autoscaler_state_manager.cc
<p>void GcsAutoscalerStateManager::UpdateResourceLoadAndUsage(rpc::ResourcesData data) {</p>
<p>NodeID node_id = NodeID::FromBinary(data.node_id());</p>
<p>// Update this node's resource information</p>
<p>auto &amp;node_info = node_resource_info_[node_id];</p>
<p>node_info.second = std::move(data);</p>
<p>node_info.first = absl::Now();  // Last update time</p>
<p>// The data includes:</p>
<p>// - Total resources on this node</p>
<p>// - Currently available resources  </p>
<p>// - Resource demands by shape (queued tasks)</p>
<p>// - Object store memory usage</p>
<p>// - Placement group demands</p>
<p>}</p>
<p></code></p>
<h3>Demand Processing Pipeline</h3>
<p>Here's the complete flow of how demand information travels through the system:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Intelligent Demand Prediction</h3>
<p>Ray doesn't just react to current demand - it predicts future needs:</p>
<pre><code><code># Proactive scaling based on trends
def _should_scale_up_preemptively(self, load_metrics):
<h1>Look at demand growth rate</h1>
current_demand = len(load_metrics.pending_tasks)
demand_growth_rate = (current_demand - self.last_demand) / self.update_interval
<h1>If demand is growing quickly, scale up before we run out</h1>
if demand_growth_rate &gt; self.preemptive_threshold:
return True
<h1>Look at placement group patterns</h1>
pending_pgs = load_metrics.pending_placement_groups
if len(pending_pgs) &gt; 0:
<h1>Placement groups often come in batches</h1>
return True
return False
</code></code></pre>

<div class="page-break"></div>
<h1>Part III: Advanced Ray Systems</h1>
<p>============================================================</p>
<h1>Chapter 11: High Availability and Fault Tolerance</h1>
<p>============================================================</p>
<h1>Ray High Availability: Comprehensive Technical Guide</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Architecture Overview</p>
<p>‚Ä¢ Core HA Components</p>
<p>‚Ä¢ GCS Fault Tolerance</p>
<p>‚Ä¢ Node Failure Handling</p>
<p>‚Ä¢ Actor Fault Tolerance</p>
<p>‚Ä¢ Object Fault Tolerance</p>
<p>‚Ä¢ Network Partition Recovery</p>
<p>‚Ä¢ Health Monitoring</p>
<p>‚Ä¢ Recovery Mechanisms</p>
<p>‚Ä¢ Performance Impact</p>
<p>‚Ä¢ Implementation Details</p>
<p>‚Ä¢ Configuration Guidelines</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>Ray's High Availability (HA) system provides comprehensive fault tolerance across all layers of the distributed system. It ensures that Ray clusters can survive and recover from various types of failures including node crashes, network partitions, process failures, and storage outages. The HA system is designed to minimize downtime and maintain service continuity while preserving data consistency and system reliability.</p>
<h3>Key Principles</h3>
<p>‚Ä¢ Layered Fault Tolerance: Different components have specialized recovery mechanisms</p>
<p>‚Ä¢ Automatic Recovery: Most failures are handled automatically without manual intervention</p>
<p>‚Ä¢ Graceful Degradation: System continues operating with reduced capacity during failures</p>
<p>‚Ä¢ State Preservation: Critical state is persisted to enable recovery after failures</p>
<p>‚Ä¢ Minimal Performance Impact: HA mechanisms are optimized for production workloads</p>
<h3>Failure Types Handled</h3>
<p>‚Ä¢ Head Node Failures: GCS server crashes, head node hardware failures</p>
<p>‚Ä¢ Worker Node Failures: Raylet crashes, worker node hardware failures  </p>
<p>‚Ä¢ Process Failures: Actor crashes, task failures, worker process exits</p>
<p>‚Ä¢ Network Partitions: Network splits, connectivity issues</p>
<p>‚Ä¢ Storage Failures: Redis outages, disk failures, I/O errors</p>
<p>‚Ä¢ Resource Exhaustion: Memory pressure, CPU saturation, disk space</p>
<h2>Architecture Overview</h2>
<p>----------------------------------------</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>HA Design Philosophy</h3>
<p>Failure Isolation: Failures in one component don't cascade to others</p>
<p>Fast Recovery: Minimize time between failure detection and recovery completion</p>
<p>Consistency Preservation: Maintain data consistency during recovery operations</p>
<p>Observability: Comprehensive monitoring and alerting for failure scenarios</p>
<h2>Core HA Components</h2>
<p>----------------------------------------</p>
<p>The Ray HA system consists of several interconnected components working together to provide comprehensive fault tolerance.</p>
<h3>Component Interaction Model</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>HA Component Responsibilities</h3>
<p>[TABLE]</p>
<p>| </p>
<p>Component |</p>
<p>Primary Function |</p>
<p>Failure Types Handled |</p>
<p>Recovery Method |</p>
<p>|</p>
<p>| </p>
<p>GCS Health Manager |</p>
<p>Node health monitoring |</p>
<p>Process crashes, network issues |</p>
<p>Proactive health checks |</p>
<p>|</p>
<p>| </p>
<p>Actor Manager |</p>
<p>Actor lifecycle |</p>
<p>Actor process failures |</p>
<p>Automatic restart with state |</p>
<p>|</p>
<p>| </p>
<p>Object Manager |</p>
<p>Object availability |</p>
<p>Data loss, node failures |</p>
<p>Lineage reconstruction |</p>
<p>|</p>
<p>| </p>
<p>Node Manager |</p>
<p>Cluster membership |</p>
<p>Node crashes, departures |</p>
<p>Membership updates |</p>
<p>|</p>
<p>| </p>
<p>Storage Manager |</p>
<p>State persistence |</p>
<p>Storage failures |</p>
<p>Backup/restore operations |</p>
<p>|</p>
<p>[/TABLE]</p>
<h2>GCS Fault Tolerance</h2>
<p>----------------------------------------</p>
<p>The Global Control Service (GCS) is the central coordination point, making its fault tolerance critical for cluster survival.</p>
<h3>GCS HA Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>GCS Recovery Process</h3>
From <code>python/ray/tests/test_gcs_fault_tolerance.py:45-100</code>:
<p>[Diagram content removed for EPUB version]</p>
<p>GCS Recovery Configuration:</p>
<code>// From test configuration
<p>struct GCSRecoveryConfig {</p>
<p>int64_t gcs_rpc_server_reconnect_timeout_s = 60;  // Reconnection timeout</p>
<p>int64_t gcs_server_request_timeout_seconds = 10;  // Request timeout</p>
<p>int64_t redis_db_connect_retries = 50;            // Redis retry attempts</p>
<p>bool enable_external_redis = true;                // Use persistent Redis</p>
<p>};</p>
<p></code></p>
<h3>Critical State Preserved</h3>
<p>‚Ä¢ Node Registry: All active and failed nodes</p>
<p>‚Ä¢ Actor Information: Actor metadata and placement</p>
<p>‚Ä¢ Job State: Running and completed jobs</p>
<p>‚Ä¢ Resource Allocation: Cluster resource assignments</p>
<p>‚Ä¢ Placement Groups: Group configurations and status</p>
<h2>Node Failure Handling</h2>
<p>----------------------------------------</p>
<p>Ray implements sophisticated node failure detection and recovery mechanisms to maintain cluster health.</p>
<h3>Node State Transitions</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Health Check Protocol</h3>
From <code>src/ray/gcs/gcs_server/gcs_health_check_manager.h:40-60</code>:
<code>class GcsHealthCheckManager {
<p>// Health check configuration</p>
<p>int64_t initial_delay_ms_;    // Delay before first check</p>
<p>int64_t timeout_ms_;         // Timeout per health check</p>
<p>int64_t period_ms_;          // Interval between checks  </p>
<p>int64_t failure_threshold_;  // Failures before marking dead</p>
<p>// Health check process</p>
<p>void StartHealthCheck() {</p>
<p>// Send gRPC health check to node</p>
<p>stub_-&gt;Check(request_, &amp;response_, [this](Status status) {</p>
<p>if (status.ok()) {</p>
<p>health_check_remaining_ = failure_threshold_;  // Reset counter</p>
<p>ScheduleNextCheck();</p>
<p>} else {</p>
<p>health_check_remaining_--;</p>
<p>if (health_check_remaining_ &lt;= 0) {</p>
<p>manager_-&gt;FailNode(node_id_);  // Mark node as failed</p>
<p>} else {</p>
<p>ScheduleNextCheck();  // Retry after delay</p>
<p>}</p>
<p>}</p>
<p>});</p>
<p>}</p>
<p>};</p>
<p></code></p>
<h3>Node Failure Impact and Recovery</h3>
<p>Immediate Effects:</p>
<p>- All running tasks on the node are terminated</p>
<p>- Actors hosted on the node become unavailable</p>
<p>- Objects stored locally are marked as lost</p>
<p>- Resource allocations are freed</p>
<p>Recovery Actions:</p>
<p>- Failed tasks are automatically retried on healthy nodes</p>
- Actors with <code>max_restarts &gt; 0</code> are restarted elsewhere
<p>- Lost objects are reconstructed via lineage if possible</p>
<p>- Resource scheduling excludes the failed node</p>
<h2>Actor Fault Tolerance</h2>
<p>----------------------------------------</p>
<p>Ray actors can automatically recover from failures through configurable restart policies and state management.</p>
<h3>Actor Restart Mechanisms</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Actor Restart Configuration</h3>
From <code>doc/source/ray-core/doc_code/actor_restart.py:8-15</code>:
<code>@ray.remote(max_restarts=4, max_task_retries=-1)
<p>class FaultTolerantActor:</p>
<p>def __init__(self):</p>
<p>self.counter = 0</p>
<h1>Actor state is reconstructed by re-running constructor</h1>
<p>def increment_and_possibly_fail(self):</p>
<p>if self.counter == 10:</p>
<p>os._exit(0)  # Simulate actor failure</p>
<p>self.counter += 1</p>
<p>return self.counter</p>
<p></code></p>
<p>Restart Policy Parameters:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Parameter |</p>
<p>Default |</p>
<p>Description |</p>
<p>Effect |</p>
<p>|</p>
<p>| </p>
<code>max_restarts</code> |
<p>0 |</p>
<p>Maximum actor restarts |</p>
<p>Controls restart attempts |</p>
<p>|</p>
<p>| </p>
<code>max_task_retries</code> |
<p>0 |</p>
<p>Task retry attempts |</p>
<p>Enables at-least-once semantics |</p>
<p>|</p>
<p>| </p>
<code>max_pending_calls</code> |
<p>-1 |</p>
<p>Queue size limit |</p>
<p>Prevents memory overflow |</p>
<p>|</p>
<p>[/TABLE]</p>
<h3>Actor Lifecycle During Failures</h3>
<p>[Diagram content removed for EPUB version]</p>
<h2>Object Fault Tolerance</h2>
<p>----------------------------------------</p>
<p>Ray provides automatic object recovery through lineage reconstruction and data replication.</p>
<h3>Object Recovery Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Object Recovery Algorithm</h3>
From <code>src/ray/core_worker/object_recovery_manager.h:70-90</code>:
<code>// Object recovery algorithm steps:
<p>bool RecoverObject(const ObjectID &amp;object_id) {</p>
<p>// 1. Check object ownership and missing status</p>
<p>if (!IsObjectMissing(object_id) || !IsObjectOwned(object_id)) {</p>
<p>return false;  // Cannot recover</p>
<p>}</p>
<p>// 2. Look for existing copies on other nodes</p>
<p>auto locations = GetObjectLocations(object_id);</p>
<p>if (!locations.empty()) {</p>
<p>return PinObjectFromLocation(object_id, locations);</p>
<p>}</p>
<p>// 3. Attempt lineage reconstruction</p>
<p>auto task_spec = GetCreationTaskSpec(object_id);</p>
<p>if (task_spec.has_value()) {</p>
<p>return ResubmitTask(task_spec.value());</p>
<p>}</p>
<p>return false;  // Object not recoverable</p>
<p>}</p>
<p></code></p>
<h3>Object Recovery Limitations</h3>
<p>Recoverable Objects:</p>
<p>- Objects created by deterministic tasks</p>
<p>- Objects with living owners</p>
<p>- Objects with available lineage information</p>
<p>Non-Recoverable Objects:</p>
- Objects created by <code>ray.put()</code> (no lineage)
<p>- Objects with dead owners</p>
<p>- Objects from non-deterministic tasks</p>
<p>- Objects exceeding retry limits</p>
<h2>Health Monitoring</h2>
<p>----------------------------------------</p>
<p>Ray implements comprehensive health monitoring across all cluster components.</p>
<h3>Multi-Layer Health Monitoring</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Health Check Implementation</h3>
<p>GCS Health Check Manager Configuration:</p>
<code>// Health check parameters
<p>struct HealthCheckConfig {</p>
<p>int64_t initial_delay_ms = 5000;        // Delay before first check</p>
<p>int64_t timeout_ms = 10000;             // Timeout per check</p>
<p>int64_t period_ms = 30000;              // Check interval</p>
<p>int64_t failure_threshold = 3;          // Failures before marking dead</p>
<p>};</p>
<p>// Health check process</p>
<p>class HealthCheckContext {</p>
<p>void StartHealthCheck() {</p>
<p>auto deadline = std::chrono::steady_clock::now() + </p>
<p>std::chrono::milliseconds(timeout_ms_);</p>
<p>stub_-&gt;async()-&gt;Check(&amp;context_, &amp;request_, &amp;response_, </p>
<p>[this](grpc::Status status) {</p>
<p>if (status.ok()) {</p>
<p>ResetFailureCount();</p>
<p>ScheduleNextCheck();</p>
<p>} else {</p>
<p>IncrementFailureCount();</p>
<p>if (failure_count_ &gt;= failure_threshold_) {</p>
<p>ReportNodeFailure();</p>
<p>} else {</p>
<p>ScheduleNextCheck();</p>
<p>}</p>
<p>}</p>
<p>});</p>
<p>}</p>
<p>};</p>
<p></code></p>
<h2>Recovery Mechanisms</h2>
<p>----------------------------------------</p>
<p>Ray implements several coordinated recovery mechanisms to handle different failure scenarios.</p>
<h3>Recovery Strategy Selection</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Recovery Coordination Protocol</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Performance Impact Analysis</h3>
<p>Recovery Time Objectives:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Component |</p>
<p>Detection Time |</p>
<p>Recovery Time |</p>
<p>Availability Target |</p>
<p>|</p>
<p>| </p>
<p>Node failure |</p>
<p>30-90 seconds |</p>
<p>2-5 minutes |</p>
<p>99.9% |</p>
<p>|</p>
<p>| </p>
<p>Actor failure |</p>
<p>1-10 seconds |</p>
<p>5-30 seconds |</p>
<p>99.95% |</p>
<p>|</p>
<p>| </p>
<p>Object loss |</p>
<p>Near-instant |</p>
<p>10-60 seconds |</p>
<p>99.99% |</p>
<p>|</p>
<p>| </p>
<p>GCS failure |</p>
<p>10-30 seconds |</p>
<p>30-120 seconds |</p>
<p>99.9% |</p>
<p>|</p>
<p>[/TABLE]</p>
<p>Throughput Impact During Recovery:</p>
<p>‚Ä¢ Node Failure: 10-30% throughput reduction during task migration</p>
<p>‚Ä¢ Actor Restart: Minimal impact on other actors</p>
<p>‚Ä¢ Object Reconstruction: Temporary latency increase for dependent tasks</p>
<p>‚Ä¢ Network Partition: Proportional to partition size</p>
<h2>Implementation Details</h2>
<p>----------------------------------------</p>
<h3>Critical Recovery Code Paths</h3>
<p>Node Failure Handler:</p>
<code>// From GcsNodeManager::OnNodeFailure
<p>void GcsNodeManager::OnNodeFailure(const NodeID &amp;node_id,</p>
<p>const StatusCallback &amp;callback) {</p>
<p>auto node = GetAliveNode(node_id);</p>
<p>if (!node) return;  // Node already marked dead</p>
<p>// Remove from alive nodes and mark as dead</p>
<p>auto death_info = InferDeathInfo(node_id);</p>
<p>auto dead_node = RemoveNode(node_id, death_info);</p>
<p>// Notify all listeners (resource manager, actor manager, etc.)</p>
<p>for (auto &amp;listener : node_removed_listeners_) {</p>
<p>listener(dead_node);</p>
<p>}</p>
<p>// Persist state change</p>
<p>RAY_CHECK_OK(gcs_table_storage_-&gt;NodeTable().Put(</p>
<p>node_id, *dead_node, callback));</p>
<p>}</p>
<p></code></p>
<p>Actor Restart Logic:</p>
<code>// Actor restart decision process
<p>bool ShouldRestartActor(const ActorID &amp;actor_id) {</p>
<p>auto actor_info = GetActorInfo(actor_id);</p>
<p>if (!actor_info) return false;</p>
<p>int current_restarts = actor_info-&gt;num_restarts();</p>
<p>int max_restarts = actor_info-&gt;max_restarts();</p>
<p>// Check restart policy</p>
<p>if (max_restarts == 0) return false;           // No restarts allowed</p>
<p>if (max_restarts == -1) return true;           // Infinite restarts</p>
<p>return current_restarts &lt; max_restarts;        // Within limit</p>
<p>}</p>
<p></code></p>
<h3>Error Handling Patterns</h3>
<p>Graceful Degradation Example:</p>
<code>Status HandleObjectRecovery(const ObjectID &amp;object_id) {
<p>// Try multiple recovery strategies in order</p>
<p>if (auto status = TryPinFromOtherNodes(object_id); status.ok()) {</p>
<p>return status;</p>
<p>}</p>
<p>if (auto status = TryLineageReconstruction(object_id); status.ok()) {</p>
<p>return status;</p>
<p>}</p>
<p>if (auto status = TrySpillRecovery(object_id); status.ok()) {</p>
<p>return status;</p>
<p>}</p>
<p>// All recovery methods failed</p>
<p>return Status::ObjectLost(&quot;Object cannot be recovered&quot;);</p>
<p>}</p>
<p></code></p>
<h2>Configuration Guidelines</h2>
<p>----------------------------------------</p>
<h3>Ray Cluster Configuration</h3>
<pre><code><code>// From ray/core/src/ray/ray_config.h
struct RayConfig {
int64_t gcs_rpc_server_reconnect_timeout_s = 60;  // Reconnection timeout
int64_t gcs_server_request_timeout_seconds = 10;  // Request timeout
int64_t redis_db_connect_retries = 50;            // Redis retry attempts
bool enable_external_redis = true;                // Use persistent Redis
};
</code></code></pre>
<h3>Health Monitoring Configuration</h3>
<pre><code><code>// From ray/core/src/ray/ray_config.h
struct HealthCheckConfig {
int64_t initial_delay_ms = 5000;        // Delay before first check
int64_t timeout_ms = 10000;             // Timeout per check
int64_t period_ms = 30000;              // Check interval
int64_t failure_threshold = 3;          // Failures before marking dead
};
</code></code></pre>
<h3>Recovery Configuration</h3>
<pre><code><code>// From ray/core/src/ray/ray_config.h
struct GCSRecoveryConfig {
int64_t gcs_rpc_server_reconnect_timeout_s = 60;  // Reconnection timeout
int64_t gcs_server_request_timeout_seconds = 10;  // Request timeout
int64_t redis_db_connect_retries = 50;            // Redis retry attempts
bool enable_external_redis = true;                // Use persistent Redis
};
</code></code></pre>
<h2>Network Partition Recovery</h2>
<p>----------------------------------------</p>
<p>Ray handles network partitions through timeout-based detection and coordinated recovery.</p>
<h3>Partition Detection and Isolation</h3>
<p>[Diagram content removed for EPUB version]</p>
<h3>Split-Brain Prevention</h3>
<p>Quorum-Based Decision Making:</p>
<code>// Partition handling logic
<p>class PartitionDetector {</p>
<p>bool ShouldShutdownOnPartition() {</p>
<p>size_t visible_nodes = GetVisibleNodeCount();</p>
<p>size_t total_nodes = GetTotalNodeCount();</p>
<p>// Require majority quorum to continue operation</p>
<p>return visible_nodes &lt;= total_nodes / 2;</p>
<p>}</p>
<p>void HandleNetworkPartition() {</p>
<p>if (ShouldShutdownOnPartition()) {</p>
<p>RAY_LOG(WARNING) &lt;&lt; &quot;Node in minority partition, shutting down&quot;;</p>
<p>InitiateGracefulShutdown();</p>
<p>} else {</p>
<p>RAY_LOG(INFO) &lt;&lt; &quot;Node in majority partition, continuing operation&quot;;</p>
<p>MarkMinorityNodesAsFailed();</p>
<p>}</p>
<p>}</p>
<p>};</p>
<p></code></p>
<h2>Production Deployment Best Practices</h2>
<p>----------------------------------------</p>
<h3>Redis High Availability Setup</h3>
<p>Redis Cluster Configuration:</p>
<code># Redis HA configuration for GCS persistence
<p>apiVersion: v1</p>
<p>kind: ConfigMap</p>
<p>metadata:</p>
<p>name: redis-config</p>
<p>data:</p>
<p>redis.conf: |</p>
<h1>High availability settings</h1>
<p>save 900 1      # Save if at least 1 key changed in 900 seconds</p>
<p>save 300 10     # Save if at least 10 keys changed in 300 seconds</p>
<p>save 60 10000   # Save if at least 10000 keys changed in 60 seconds</p>
<h1>Replication settings</h1>
<p>replica-read-only yes</p>
<p>replica-serve-stale-data yes</p>
<h1>Persistence settings</h1>
<p>appendonly yes</p>
<p>appendfsync everysec</p>
<h1>Memory management</h1>
<p>maxmemory-policy allkeys-lru</p>
<h1>Network settings</h1>
<p>timeout 300</p>
<p>tcp-keepalive 300</p>
<p></code></p>
<h3>KubeRay HA Configuration</h3>
<p>RayService with GCS Fault Tolerance:</p>
<code>apiVersion: ray.io/v1alpha1
<p>kind: RayService</p>
<p>metadata:</p>
<p>name: rayservice-ha</p>
<p>spec:</p>
<p>serviceUnhealthySecondThreshold: 900</p>
<p>deploymentUnhealthySecondThreshold: 300</p>
<p>rayClusterConfig:</p>
<p>headGroupSpec:</p>
<p>template:</p>
<p>spec:</p>
<p>containers:</p>
<p>- name: ray-head</p>
<p>image: rayproject/ray:2.8.0</p>
<p>env:</p>
<h1>GCS fault tolerance configuration</h1>
<p>- name: RAY_external_storage_namespace</p>
<p>value: &quot;ray-cluster&quot;</p>
<p>- name: RAY_redis_address</p>
<p>value: &quot;redis-master:6379&quot;</p>
<p>- name: RAY_gcs_rpc_server_reconnect_timeout_s</p>
<p>value: &quot;60&quot;</p>
<p>- name: RAY_gcs_server_request_timeout_seconds</p>
<p>value: &quot;10&quot;</p>
<p>- name: RAY_redis_db_connect_retries</p>
<p>value: &quot;50&quot;</p>
<p>resources:</p>
<p>limits:</p>
<p>cpu: &quot;2&quot;</p>
<p>memory: &quot;4Gi&quot;</p>
<p>requests:</p>
<p>cpu: &quot;1&quot;</p>
<p>memory: &quot;2Gi&quot;</p>
<p>workerGroupSpecs:</p>
<p>- replicas: 3</p>
<p>minReplicas: 1</p>
<p>maxReplicas: 10</p>
<p>groupName: worker-group</p>
<p>template:</p>
<p>spec:</p>
<p>containers:</p>
<p>- name: ray-worker</p>
<p>image: rayproject/ray:2.8.0</p>
<p>resources:</p>
<p>limits:</p>
<p>cpu: &quot;4&quot;</p>
<p>memory: &quot;8Gi&quot;</p>
<p>requests:</p>
<p>cpu: &quot;2&quot;</p>
<p>memory: &quot;4Gi&quot;</p>
<p></code></p>
<h3>Health Check Configuration</h3>
<p>Comprehensive Health Monitoring:</p>
<code># Application-level health monitoring
<p>import ray</p>
<p>import time</p>
<p>import logging</p>
<p>@ray.remote</p>
<p>class HealthMonitor:</p>
<p>def __init__(self):</p>
<p>self.start_time = time.time()</p>
<p>self.check_interval = 30  # seconds</p>
<p>def check_cluster_health(self):</p>
<p>&quot;&quot;&quot;Comprehensive cluster health check&quot;&quot;&quot;</p>
<p>health_status = {</p>
<p>'timestamp': time.time(),</p>
<p>'uptime': time.time() - self.start_time,</p>
<p>'nodes': {},</p>
<p>'actors': {},</p>
<p>'objects': {}</p>
<p>}</p>
<h1>Check node health</h1>
<p>nodes = ray.nodes()</p>
<p>for node in nodes:</p>
<p>health_status['nodes'][node['NodeID']] = {</p>
<p>'alive': node['Alive'],</p>
<p>'resources': node['Resources'],</p>
<p>'cpu_usage': node.get('cpu', 0),</p>
<p>'memory_usage': node.get('memory', 0)</p>
<p>}</p>
<h1>Check actor health  </h1>
<p>try:</p>
<p>actors = ray.util.state.list_actors()</p>
<p>for actor in actors:</p>
<p>health_status['actors'][actor['actor_id']] = {</p>
<p>'state': actor['state'],</p>
<p>'pid': actor.get('pid'),</p>
<p>'node_id': actor.get('node_id')</p>
<p>}</p>
<p>except Exception as e:</p>
<p>logging.warning(f&quot;Failed to get actor status: {e}&quot;)</p>
<p>return health_status</p>
<p>def monitor_continuously(self):</p>
<p>&quot;&quot;&quot;Continuous health monitoring loop&quot;&quot;&quot;</p>
<p>while True:</p>
<p>try:</p>
<p>health = self.check_cluster_health()</p>
<h1>Log unhealthy components</h1>
<p>dead_nodes = [nid for nid, info in health['nodes'].items() </p>
<p>if not info['alive']]</p>
<p>if dead_nodes:</p>
<p>logging.warning(f&quot;Dead nodes detected: {dead_nodes}&quot;)</p>
<p>failed_actors = [aid for aid, info in health['actors'].items()</p>
<p>if info['state'] == 'FAILED']</p>
<p>if failed_actors:</p>
<p>logging.warning(f&quot;Failed actors detected: {failed_actors}&quot;)</p>
<p>except Exception as e:</p>
<p>logging.error(f&quot;Health check failed: {e}&quot;)</p>
<p>time.sleep(self.check_interval)</p>
<p></code></p>
<h2>Testing and Validation</h2>
<p>----------------------------------------</p>
<h3>Chaos Engineering for HA Testing</h3>
<p>Node Failure Simulation:</p>
<code>import ray
<p>import psutil</p>
<p>import random</p>
<p>import time</p>
<p>@ray.remote</p>
<p>class ChaosAgent:</p>
<p>&quot;&quot;&quot;Simulates various failure scenarios for HA testing&quot;&quot;&quot;</p>
<p>def simulate_node_failure(self, duration_seconds=60):</p>
<p>&quot;&quot;&quot;Simulate node failure by stopping raylet process&quot;&quot;&quot;</p>
<p>try:</p>
<h1>Find raylet process</h1>
<p>for proc in psutil.process_iter(['pid', 'name']):</p>
<p>if 'raylet' in proc.info['name']:</p>
<p>proc.terminate()</p>
<p>break</p>
<p>time.sleep(duration_seconds)</p>
<h1>Raylet should be restarted by process manager</h1>
<p>return &quot;Node failure simulation completed&quot;</p>
<p>except Exception as e:</p>
<p>return f&quot;Simulation failed: {e}&quot;</p>
<p>def simulate_memory_pressure(self, allocation_mb=1000):</p>
<p>&quot;&quot;&quot;Simulate memory pressure&quot;&quot;&quot;</p>
<p>data = []</p>
<p>try:</p>
<h1>Allocate memory to create pressure</h1>
<p>for _ in range(allocation_mb):</p>
<p>data.append(b'x' * 1024 * 1024)  # 1MB chunks</p>
<p>time.sleep(30)  # Hold memory for 30 seconds</p>
<p>return &quot;Memory pressure simulation completed&quot;</p>
<p>except MemoryError:</p>
<p>return &quot;Memory exhausted as expected&quot;</p>
<p>finally:</p>
<p>del data  # Release memory</p>
<p>def simulate_network_partition(self, target_nodes, duration_seconds=60):</p>
<p>&quot;&quot;&quot;Simulate network partition using iptables rules&quot;&quot;&quot;</p>
<p>import subprocess</p>
<p>try:</p>
<h1>Block traffic to/from target nodes</h1>
<p>for node in target_nodes:</p>
<p>subprocess.run(['iptables', '-A', 'INPUT', '-s', node, '-j', 'DROP'])</p>
<p>subprocess.run(['iptables', '-A', 'OUTPUT', '-d', node, '-j', 'DROP'])</p>
<p>time.sleep(duration_seconds)</p>
<h1>Restore connectivity</h1>
<p>for node in target_nodes:</p>
<p>subprocess.run(['iptables', '-D', 'INPUT', '-s', node, '-j', 'DROP'])</p>
<p>subprocess.run(['iptables', '-D', 'OUTPUT', '-d', node, '-j', 'DROP'])</p>
<p>return &quot;Network partition simulation completed&quot;</p>
<p>except Exception as e:</p>
<p>return f&quot;Network simulation failed: {e}&quot;</p>
<p></code></p>
<p>HA Test Suite:</p>
<code>import pytest
<p>import ray</p>
<p>import time</p>
<p>class TestRayHighAvailability:</p>
<p>def setup_method(self):</p>
<p>&quot;&quot;&quot;Setup test cluster&quot;&quot;&quot;</p>
<p>ray.init(address='ray://localhost:10001')</p>
<p>def teardown_method(self):</p>
<p>&quot;&quot;&quot;Cleanup after test&quot;&quot;&quot;</p>
<p>ray.shutdown()</p>
<p>def test_actor_restart_on_failure(self):</p>
<p>&quot;&quot;&quot;Test actor automatic restart after failure&quot;&quot;&quot;</p>
<p>@ray.remote(max_restarts=3)</p>
<p>class TestActor:</p>
<p>def __init__(self):</p>
<p>self.counter = 0</p>
<p>def increment(self):</p>
<p>self.counter += 1</p>
<p>if self.counter == 5:</p>
<p>import os</p>
<p>os._exit(1)  # Simulate crash</p>
<p>return self.counter</p>
<p>actor = TestActor.remote()</p>
<h1>Should succeed for first 4 calls</h1>
<p>for i in range(4):</p>
<p>result = ray.get(actor.increment.remote())</p>
<p>assert result == i + 1</p>
<h1>5th call causes crash, but actor should restart</h1>
<p>with pytest.raises(ray.exceptions.RayActorError):</p>
<p>ray.get(actor.increment.remote())</p>
<h1>Actor should be restarted and accessible</h1>
<p>time.sleep(5)  # Wait for restart</p>
<p>result = ray.get(actor.increment.remote())</p>
<p>assert result == 1  # Counter reset after restart</p>
<p>def test_object_reconstruction(self):</p>
<p>&quot;&quot;&quot;Test object reconstruction after data loss&quot;&quot;&quot;</p>
<p>@ray.remote</p>
<p>def create_data(size_mb):</p>
<p>return b'x' * (size_mb * 1024 * 1024)</p>
<h1>Create object</h1>
<p>obj_ref = create_data.remote(10)</p>
<p>original_data = ray.get(obj_ref)</p>
<h1>Simulate object loss (this is hard to do directly)</h1>
<h1>In practice, you'd kill the node storing the object</h1>
<h1>Object should be reconstructible</h1>
<p>reconstructed_data = ray.get(obj_ref)</p>
<p>assert original_data == reconstructed_data</p>
<p>def test_gcs_recovery(self):</p>
<p>&quot;&quot;&quot;Test GCS server recovery (requires external Redis)&quot;&quot;&quot;</p>
<h1>Submit some actors and tasks</h1>
<p>@ray.remote</p>
<p>class PersistentActor:</p>
<p>def get_pid(self):</p>
<p>import os</p>
<p>return os.getpid()</p>
<p>actors = [PersistentActor.remote() for _ in range(5)]</p>
<p>pids_before = ray.get([actor.get_pid.remote() for actor in actors])</p>
<h1>Kill GCS server (in real test, you'd restart GCS process)</h1>
<h1>This requires external coordination</h1>
<h1>Verify actors survive GCS restart</h1>
<p>time.sleep(10)  # Wait for GCS recovery</p>
<p>pids_after = ray.get([actor.get_pid.remote() for actor in actors])</p>
<h1>Actor PIDs should be unchanged (actors survived)</h1>
<p>assert pids_before == pids_after</p>
<p></code></p>
<h3>Performance Benchmarking</h3>
<p>HA Overhead Measurement:</p>
<code>import ray
<p>import time</p>
<p>import statistics</p>
<p>def benchmark_ha_overhead():</p>
<p>&quot;&quot;&quot;Measure performance overhead of HA features&quot;&quot;&quot;</p>
<h1>Baseline: No HA features</h1>
<p>ray.init(address='ray://localhost:10001')</p>
<p>@ray.remote</p>
<p>class BaselineActor:</p>
<p>def compute(self, data):</p>
<p>return sum(data)</p>
<h1>Benchmark baseline</h1>
<p>actor = BaselineActor.remote()</p>
<p>data = list(range(10000))</p>
<p>start_time = time.time()</p>
<p>futures = [actor.compute.remote(data) for _ in range(100)]</p>
<p>results = ray.get(futures)</p>
<p>baseline_time = time.time() - start_time</p>
<p>ray.shutdown()</p>
<h1>HA enabled: With fault tolerance</h1>
<p>ray.init(address='ray://localhost:10001')</p>
<p>@ray.remote(max_restarts=3, max_task_retries=2)</p>
<p>class HAEnabledActor:</p>
<p>def compute(self, data):</p>
<p>return sum(data)</p>
<h1>Benchmark with HA</h1>
<p>actor = HAEnabledActor.remote()</p>
<p>start_time = time.time()</p>
<p>futures = [actor.compute.remote(data) for _ in range(100)]</p>
<p>results = ray.get(futures)</p>
<p>ha_time = time.time() - start_time</p>
<p>overhead_percent = ((ha_time - baseline_time) / baseline_time) * 100</p>
<p>print(f&quot;Baseline time: {baseline_time:.2f}s&quot;)</p>
<p>print(f&quot;HA enabled time: {ha_time:.2f}s&quot;)</p>
<p>print(f&quot;HA overhead: {overhead_percent:.2f}%&quot;)</p>
<p>return overhead_percent</p>
<p>if __name__ == &quot;__main__&quot;:</p>
<p>overhead = benchmark_ha_overhead()</p>
<p>assert overhead &lt; 10, f&quot;HA overhead too high: {overhead}%&quot;</p>
<p></code></p>
<h2>Best Practices and Recommendations</h2>
<p>----------------------------------------</p>
<h3>Production Deployment Checklist</h3>
<p>Infrastructure Setup:</p>
<p>- [ ] Deploy Redis cluster with replication and persistence</p>
<p>- [ ] Configure external storage for object spilling</p>
<p>- [ ] Set up monitoring and alerting systems</p>
<p>- [ ] Implement automated backup procedures</p>
<p>- [ ] Configure network policies and firewalls</p>
<p>Ray Configuration:</p>
<p>- [ ] Enable GCS fault tolerance with external Redis</p>
<p>- [ ] Configure appropriate health check intervals</p>
<p>- [ ] Set reasonable retry limits for tasks and actors</p>
<p>- [ ] Tune memory and resource allocation</p>
<p>- [ ] Enable comprehensive logging and metrics</p>
<p>Application Design:</p>
<p>- [ ] Design actors with restart capabilities</p>
<p>- [ ] Implement idempotent task functions</p>
<p>- [ ] Avoid storing critical state only in memory</p>
<p>- [ ] Use placement groups for co-location requirements</p>
<p>- [ ] Handle exceptions and failures gracefully</p>
<h3>Common Pitfalls and Solutions</h3>
<p>[TABLE]</p>
<p>| </p>
<p>Problem |</p>
<p>Cause |</p>
<p>Solution |</p>
<p>|</p>
<p>| </p>
<p>Split-brain scenarios |</p>
<p>Network partitions |</p>
<p>Use quorum-based decisions |</p>
<p>|</p>
<p>| </p>
<p>Data loss after failures |</p>
<p>No persistent storage |</p>
<p>Enable external Redis |</p>
<p>|</p>
<p>| </p>
<p>Long recovery times |</p>
<p>Aggressive health checks |</p>
<p>Tune timeout parameters |</p>
<p>|</p>
<p>| </p>
<p>Resource leaks |</p>
<p>Failed cleanup |</p>
<p>Implement proper error handling |</p>
<p>|</p>
<p>| </p>
<p>Cascading failures |</p>
<p>Tight coupling |</p>
<p>Design for failure isolation |</p>
<p>|</p>
<p>[/TABLE]</p>
<h3>Monitoring and Alerting</h3>
<p>Key Metrics to Monitor:</p>
<code># Essential HA metrics
<p>ha_metrics = {</p>
<p>'node_failures_per_hour': 'Rate of node failures',</p>
<p>'actor_restart_rate': 'Actor restart frequency',</p>
<p>'object_reconstruction_time': 'Time to reconstruct lost objects',</p>
<p>'gcs_recovery_time': 'GCS server recovery duration',</p>
<p>'network_partition_events': 'Network split occurrences',</p>
<p>'health_check_failures': 'Health check failure rate',</p>
<p>'storage_backend_availability': 'Redis/storage uptime',</p>
<p>'cluster_resource_utilization': 'Resource usage efficiency'</p>
<p>}</p>
<h1>Alert thresholds</h1>
<p>alert_thresholds = {</p>
<p>'node_failure_rate': 5,           # More than 5 failures per hour</p>
<p>'actor_restart_rate': 10,         # More than 10 restarts per minute</p>
<p>'gcs_recovery_time': 300,         # More than 5 minutes</p>
<p>'health_check_failure_rate': 20,  # More than 20% failure rate</p>
<p>'storage_availability': 99.9      # Less than 99.9% uptime</p>
<p>}</p>
<p></code></p>
This comprehensive guide covers Ray's High Availability features, implementation details, and production deployment best practices. For the most current implementation details, refer to the source files in the Ray repository, particularly <code>src/ray/gcs/gcs_server/</code>, <code>src/ray/core_worker/</code>, and the fault tolerance documentation in <code>doc/source/ray-core/fault_tolerance/</code>.

<div class="page-break"></div>
<h1>Part IV: System Internals</h1>
<p>============================================================</p>
<h1>Chapter 12: Network Communication and Protocols</h1>
<p>============================================================</p>
<h1>Ray's Custom Protocol Over Unix Domain Sockets: A Deep Technical Dive</h1>
<p>============================================================</p>
<h2>Table of Contents</h2>
<p>----------------------------------------</p>
<p>‚Ä¢ Introduction</p>
<p>‚Ä¢ Protocol Architecture Overview</p>
<p>‚Ä¢ Wire Protocol Format</p>
<p>‚Ä¢ Why Not gRPC Over UDS?</p>
<p>‚Ä¢ Message Types and Structure</p>
<p>‚Ä¢ Connection Establishment</p>
<p>‚Ä¢ Communication Patterns</p>
<p>‚Ä¢ Performance Characteristics</p>
<p>‚Ä¢ Comparison with Other Systems</p>
<p>‚Ä¢ Implementation Details</p>
<p>‚Ä¢ Advantages and Trade-offs</p>
<p>‚Ä¢ Conclusion</p>
<h2>Introduction</h2>
<p>----------------------------------------</p>
<p>Ray uses a custom binary protocol over Unix Domain Sockets (UDS) for high-frequency, low-latency communication between workers and the local raylet. This is fundamentally different from the gRPC-over-TCP approach used for inter-node communication.</p>
<h3>Why a Custom Protocol?</h3>
<p>Ray's design prioritizes performance for the critical path - the frequent interactions between workers and their local raylet. These include:</p>
<p>- Task submission and completion notifications</p>
<p>- Object dependency resolution</p>
<p>- Worker lifecycle events</p>
<p>- Resource allocation requests</p>
<p>The custom protocol achieves microsecond-level latency compared to gRPC's millisecond overhead for these frequent, simple operations.</p>
<h2>Protocol Architecture Overview</h2>
<p>----------------------------------------</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Key Components</h3>
<p>‚Ä¢ Unix Domain Sockets: IPC transport mechanism</p>
<p>‚Ä¢ FlatBuffers: Zero-copy serialization format</p>
<p>‚Ä¢ Custom Message Protocol: Ray-specific message framing</p>
<p>‚Ä¢ Connection Management: Per-worker persistent connections</p>
<h2>Wire Protocol Format</h2>
<p>----------------------------------------</p>
<p>Ray's wire protocol is elegantly simple, optimized for both performance and correctness:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Message Header Structure</h3>
From <code>src/ray/common/client_connection.cc:217-250</code>:
<code>Status ServerConnection::WriteMessage(int64_t type, int64_t length, const uint8_t *message) {
<p>auto write_cookie = RayConfig::instance().ray_cookie();</p>
<p>return WriteBuffer({</p>
<p>boost::asio::buffer(&amp;write_cookie, sizeof(write_cookie)),    // 8 bytes</p>
<p>boost::asio::buffer(&amp;type, sizeof(type)),                   // 8 bytes  </p>
<p>boost::asio::buffer(&amp;length, sizeof(length)),               // 8 bytes</p>
<p>boost::asio::buffer(message, length),                       // variable</p>
<p>});</p>
<p>}</p>
<p></code></p>
<p>Header Breakdown:</p>
<p>- Ray Cookie (8 bytes): Protocol identifier and version check</p>
<p>- Message Type (8 bytes): Identifies the FlatBuffer schema to use</p>
<p>- Payload Length (8 bytes): Size of the FlatBuffer payload</p>
<p>- Payload (variable): The actual FlatBuffer-serialized message</p>
<h2>Why Not gRPC Over UDS?</h2>
<p>----------------------------------------</p>
<p>You correctly noted that gRPC can run over Unix Domain Sockets. Here's why Ray chose a custom approach:</p>
<h3>1. Performance Requirements</h3>
<p>Ray's Latency Requirements:</p>
<p>- Task submission: &lt; 10 microseconds</p>
<p>- Object dependency checks: &lt; 5 microseconds</p>
<p>- Worker lifecycle events: &lt; 1 microsecond</p>
<p>gRPC Overhead (even over UDS):</p>
<p>- HTTP/2 framing: ~20-50 microseconds</p>
<p>- Protobuf serialization: ~10-30 microseconds</p>
<p>- Connection state management: ~5-15 microseconds</p>
<p>- Total gRPC overhead: 35-95 microseconds</p>
<h3>2. Message Pattern Optimization</h3>
<p>Ray's communication patterns are very specific:</p>
<p>[Diagram content removed for EPUB version]</p>
<p>Ray's optimization:</p>
<p>- 90% of messages are tiny (&lt; 50 bytes)</p>
<p>- These only need 24-byte headers + minimal payload</p>
<p>- No need for HTTP/2 features (multiplexing, flow control, etc.)</p>
<h3>3. Custom Requirements</h3>
<p>Ray needs specific features that gRPC doesn't optimize for:</p>
<p>Synchronous Object Dependencies:</p>
<p>- Worker blocks until objects are available</p>
<p>- Need immediate notification when dependencies resolve</p>
<p>- gRPC's async model adds unnecessary complexity</p>
<p>Zero-Copy Object Access:</p>
<p>- FlatBuffers allow direct buffer access</p>
<p>- No need to deserialize into objects</p>
<p>- Critical for high-frequency, small messages</p>
<p>Predictable Performance:</p>
<p>- Custom protocol has deterministic behavior</p>
<p>- No hidden complexity from HTTP/2 state machine</p>
<p>- Easier to profile and optimize</p>
<h2>Message Types and Structure</h2>
<p>----------------------------------------</p>
Ray defines comprehensive message types from <code>src/ray/raylet/format/node_manager.fbs</code>:
<p>[Diagram content removed for EPUB version]</p>
<h3>Core Message Categories</h3>
<p>1. Connection Lifecycle</p>
- <code>RegisterClientRequest/Reply</code>: Worker registration and capabilities
- <code>DisconnectClientRequest/Reply</code>: Graceful worker shutdown
- <code>AnnounceWorkerPort/Reply</code>: gRPC port setup for remote communication
<p>2. Task Management</p>
- <code>SubmitTask</code>: Submit task for execution
- <code>ExecuteTask</code>: Assign task to worker
- <code>ActorCreationTaskDone</code>: Actor initialization complete
<p>3. Object Dependency Management</p>
- <code>FetchOrReconstruct</code>: Request object availability
- <code>WaitRequest/Reply</code>: Wait for object dependencies
- <code>NotifyUnblocked</code>: Signal dependency resolution
<h2>Connection Establishment</h2>
<p>----------------------------------------</p>
<p>The connection establishment follows a specific handshake protocol:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Registration Details</h3>
<p>From the FlatBuffer schema:</p>
<code>table RegisterClientRequest {
<p>worker_type: int;           // Worker, Driver, etc.</p>
<p>worker_id: string;          // Unique worker identifier  </p>
<p>worker_pid: long;           // Process ID</p>
<p>startup_token: long;        // Security token</p>
<p>job_id: string;            // Job association</p>
<p>runtime_env_hash: int;     // Environment fingerprint</p>
<p>language: int;             // Python, Java, C++, etc.</p>
<p>ip_address: string;        // Network address</p>
<p>port: int;                 // gRPC listening port</p>
<p>serialized_job_config: string; // Job configuration</p>
<p>}</p>
<p></code></p>
<h2>Communication Patterns</h2>
<p>----------------------------------------</p>
<p>Ray uses different communication patterns optimized for specific use cases:</p>
<h3>1. Fire-and-Forget Pattern</h3>
<p>For non-critical notifications that don't require responses:</p>
<p>[Diagram content removed for EPUB version]</p>
<p>Implementation:</p>
<code>Status RayletClient::ActorCreationTaskDone() {
<p>return conn_-&gt;WriteMessage(MessageType::ActorCreationTaskDone);</p>
<p>}</p>
<p></code></p>
<h3>2. Request-Reply Pattern</h3>
<p>For operations requiring confirmation or data return:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>3. Asynchronous Notification Pattern</h3>
<p>For events that may arrive at any time:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Performance Characteristics</h2>
<p>----------------------------------------</p>
<h3>Latency Analysis</h3>
<p>Ray's custom protocol achieves significant performance advantages:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Throughput Characteristics</h3>
<p>Message Size Efficiency:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Message Type |</p>
<p>Ray Protocol |</p>
<p>gRPC Equivalent |</p>
<p>Savings |</p>
<p>|</p>
<p>| </p>
<code>ActorCreationTaskDone</code> |
<p>24 bytes |</p>
<p>~200 bytes |</p>
<p>88% |</p>
<p>|</p>
<p>| </p>
<code>NotifyUnblocked</code> |
<p>48 bytes |</p>
<p>~250 bytes |</p>
<p>81% |</p>
<p>|</p>
<p>| </p>
<code>RegisterClient</code> |
<p>~300 bytes |</p>
<p>~500 bytes |</p>
<p>40% |</p>
<p>|</p>
<p>[/TABLE]</p>
<p>Connection Overhead:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Aspect |</p>
<p>Ray Protocol |</p>
<p>gRPC |</p>
<p>|</p>
<p>| </p>
<p>Connection setup |</p>
<p>~100Œºs |</p>
<p>~2ms |</p>
<p>|</p>
<p>| </p>
<p>Per-message overhead |</p>
<p>24 bytes |</p>
<p>50-100 bytes |</p>
<p>|</p>
<p>| </p>
<p>Memory per connection |</p>
<p>~8KB |</p>
<p>~32KB |</p>
<p>|</p>
<p>[/TABLE]</p>
<h2>Comparison with Other Systems</h2>
<p>----------------------------------------</p>
<h3>ScyllaDB Similarity Analysis</h3>
<p>Based on the provided ScyllaDB documentation, there are interesting parallels:</p>
<p>Similarities:</p>
<p>1. Custom Protocol Focus: Both Ray and ScyllaDB choose custom protocols for performance-critical paths</p>
<p>2. Memory Management: Both systems carefully manage memory allocation and use semaphores for resource control</p>
<p>3. Chunked Processing: Both handle large requests by breaking them into chunks</p>
<p>Key Differences:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Aspect |</p>
<p>Ray |</p>
<p>ScyllaDB |</p>
<p>|</p>
<p>| </p>
<p>Transport |</p>
<p>Unix Domain Sockets |</p>
<p>TCP/Network |</p>
<p>|</p>
<p>| </p>
<p>Serialization |</p>
<p>FlatBuffers |</p>
<p>Custom binary format |</p>
<p>|</p>
<p>| </p>
<p>Use Case |</p>
<p>Local IPC only |</p>
<p>Network communication |</p>
<p>|</p>
<p>| </p>
<p>Memory Strategy |</p>
<p>Zero-copy when possible |</p>
<p>Pre-reservation with expansion |</p>
<p>|</p>
<p>[/TABLE]</p>
<h3>Ray vs. gRPC Design Philosophy</h3>
<p>Ray's Approach:</p>
<p>[Diagram content removed for EPUB version]</p>
<p>gRPC's Approach:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Implementation Details</h2>
<p>----------------------------------------</p>
<h3>FlatBuffers Integration</h3>
<p>Ray chose FlatBuffers over Protocol Buffers for several reasons:</p>
<p>[Diagram content removed for EPUB version]</p>
<h3>Connection Management</h3>
<p>Each worker maintains a persistent connection to the raylet:</p>
<code>class RayletConnection {
<p>private:</p>
<p>std::shared_ptr&lt;ServerConnection&gt; conn_;           // UDS connection</p>
<p>std::mutex mutex_;                                // Thread safety</p>
<p>std::mutex write_mutex_;                          // Write synchronization</p>
<p>public:</p>
<p>Status WriteMessage(MessageType type, flatbuffers::FlatBufferBuilder *fbb);</p>
<p>Status AtomicRequestReply(MessageType request_type, MessageType reply_type, </p>
<p>std::vector&lt;uint8_t&gt; *reply, flatbuffers::FlatBufferBuilder *fbb);</p>
<p>};</p>
<p></code></p>
<h3>Error Handling and Recovery</h3>
<p>Ray's protocol includes robust error handling:</p>
<p>1. Connection-Level Errors:</p>
<code>void RayletConnection::ShutdownIfLocalRayletDisconnected(const Status &amp;status) {
<p>if (!status.ok() &amp;&amp; IsRayletFailed(RayConfig::instance().RAYLET_PID())) {</p>
<p>RAY_LOG(WARNING) &lt;&lt; &quot;Local raylet died. Terminating process.&quot;;</p>
<p>QuickExit();  // Fast process termination</p>
<p>}</p>
<p>}</p>
<p></code></p>
<p>2. Protocol-Level Validation:</p>
<code>// Cookie validation for message integrity
<p>if (read_cookie != RayConfig::instance().ray_cookie()) {</p>
<p>return Status::IOError(&quot;Ray cookie mismatch - protocol corruption detected&quot;);</p>
<p>}</p>
<p>// Message type validation</p>
<p>if (expected_type != read_type) {</p>
<p>return Status::IOError(&quot;Message type mismatch - connection corrupted&quot;);</p>
<p>}</p>
<p></code></p>
<p>3. Graceful Shutdown:</p>
<p>[Diagram content removed for EPUB version]</p>
<h2>Advantages and Trade-offs</h2>
<p>----------------------------------------</p>
<h3>Advantages</h3>
<p>1. Performance Benefits:</p>
<p>- Ultra-low latency: 1-10Œºs vs 50-200Œºs for gRPC</p>
<p>- High throughput: Minimal serialization overhead</p>
<p>- Zero-copy operations: Direct buffer access where possible</p>
<p>- Reduced memory footprint: ~8KB vs ~32KB per connection</p>
<p>2. Simplicity Benefits:</p>
<p>- Minimal dependencies: No complex gRPC stack</p>
<p>- Deterministic behavior: Simple protocol, predictable performance</p>
<p>- Easy debugging: Human-readable message types and simple framing</p>
<p>3. Optimization Benefits:</p>
<p>- Custom tuning: Protocol optimized for Ray's specific use cases</p>
<p>- Efficient batching: Can batch multiple small messages</p>
<p>- Direct integration: Tight coupling with Ray's object model</p>
<h3>Trade-offs</h3>
<p>1. Development Overhead:</p>
<p>- Custom protocol maintenance: Need to maintain protocol evolution</p>
<p>- Limited tooling: Fewer debugging tools compared to gRPC</p>
<p>- Documentation burden: Need to document protocol thoroughly</p>
<p>2. Feature Limitations:</p>
<p>- No built-in features: No automatic compression, authentication, etc.</p>
<p>- Local-only: Cannot be used for network communication</p>
<p>- Platform-specific: Unix Domain Sockets are not available on all platforms</p>
<p>3. Ecosystem Integration:</p>
<p>- Non-standard: Harder for external tools to integrate</p>
<p>- Learning curve: Developers need to understand custom protocol</p>
<p>- Testing complexity: Need custom testing infrastructure</p>
<h3>When This Approach Makes Sense</h3>
<p>Ray's custom protocol is justified because:</p>
<p>‚Ä¢ High-frequency, low-latency requirements: Worker-raylet communication is extremely frequent</p>
<p>‚Ä¢ Simple message patterns: Most messages are small and follow predictable patterns  </p>
<p>‚Ä¢ Local-only communication: No need for network features like load balancing</p>
<p>‚Ä¢ Performance-critical path: This communication is on the critical path for task execution</p>
<p>‚Ä¢ Controlled environment: Ray controls both ends of the communication</p>
<h2>Conclusion</h2>
<p>----------------------------------------</p>
<p>Ray's custom protocol over Unix Domain Sockets represents a performance-first design decision that prioritizes the critical path of distributed computing. The choice demonstrates that there's no one-size-fits-all solution in distributed systems design.</p>
<p>Key Takeaways:</p>
<p>‚Ä¢ </p>
<p>When performance matters most, custom protocols can provide significant advantages over general-purpose solutions</p>
<p>‚Ä¢ </p>
<p>Protocol simplicity can be a feature - Ray's 24-byte header and FlatBuffer payload are easy to understand and debug</p>
<p>‚Ä¢ </p>
<p>Hybrid approaches work well - Ray uses custom protocols for local communication and gRPC for remote communication</p>
<p>‚Ä¢ </p>
<p>Context matters - What works for Ray's local IPC may not work for other use cases like network communication</p>
<p>This approach is similar to ScyllaDB's philosophy of optimizing the critical path, but differs in implementation details based on the specific requirements of each system.</p>
This analysis is based on Ray's source code, particularly files in <code>src/ray/raylet_client/</code>, <code>src/ray/common/client_connection.cc</code>, and <code>src/ray/raylet/format/node_manager.fbs</code>.

<div class="page-break"></div>
<h1>Part IV: System Internals</h1>
<p>============================================================</p>
<h1>Chapter 13: Port Assignment and Management</h1>
<p>============================================================</p>
<h1>Ray Port Assignment: Complete Guide</h1>
<p>============================================================</p>
<h2>Overview</h2>
<p>----------------------------------------</p>
<p>This document provides a comprehensive explanation of how Ray allocates and manages ports for actors and tasks. Understanding this mechanism is crucial for configuring Ray clusters properly, especially in environments with strict firewall rules or limited port availability.</p>
<h2>Key Concepts</h2>
<p>----------------------------------------</p>
<h3>1. Single Port Pool Architecture</h3>
Ray uses a unified port pool managed by the <code>WorkerPool</code> class for both actors and tasks. This is not separate pools - it's one shared resource.
Code Reference: <code>src/ray/raylet/worker_pool.h:834</code>
<code>/// Keeps track of unused ports that newly-created workers can bind on.
<p>/// If null, workers will not be passed ports and will choose them randomly.</p>
<p>std::unique_ptr&lt;std::queue&lt;int&gt;&gt; free_ports_;</p>
<p></code></p>
<h3>2. Port Allocation Model</h3>
<p>‚Ä¢ One port per worker (regardless of CPU usage)</p>
<p>‚Ä¢ Both actors and tasks use the same pool</p>
<p>‚Ä¢ Ports are assigned when workers register with the raylet</p>
<p>‚Ä¢ Ports are returned to the pool when workers terminate</p>
<h2>Port Pool Creation</h2>
<p>----------------------------------------</p>
<h3>Port Pool Initialization</h3>
The port pool is created during <code>WorkerPool</code> construction with ports from either:
<p>‚Ä¢ Port Range (min_worker_port to max_worker_port)</p>
<p>‚Ä¢ Explicit Port List (worker_port_list)</p>
Code Reference: <code>src/ray/raylet/worker_pool.cc:148-161</code>
<code>// Initialize free ports list with all ports in the specified range.
<p>if (!worker_ports.empty()) {</p>
<p>free_ports_ = std::make_unique&lt;std::queue&lt;int&gt;&gt;();</p>
<p>for (int port : worker_ports) {</p>
<p>free_ports_-&gt;push(port);</p>
<p>}</p>
<p>} else if (min_worker_port != 0 &amp;&amp; max_worker_port != 0) {</p>
<p>free_ports_ = std::make_unique&lt;std::queue&lt;int&gt;&gt;();</p>
<p>if (max_worker_port == 0) {</p>
<p>max_worker_port = 65535;  // Maximum valid port number</p>
<p>}</p>
<p>for (int port = min_worker_port; port &lt;= max_worker_port; port++) {</p>
<p>free_ports_-&gt;push(port);</p>
<p>}</p>
<p>}</p>
<p></code></p>
<h3>Configuration Options</h3>
<h4>Method 1: Port Range</h4>
<pre><code><code># Command line
ray start --min-worker-port=10000 --max-worker-port=10100
<h1>Python API</h1>
ray.init(min_worker_port=10000, max_worker_port=10100)
</code></code></pre>
<h4>Method 2: Explicit Port List</h4>
<pre><code><code># Command line
ray start --worker-port-list=&quot;10000,10001,10002,10003&quot;
<h1>Python API  </h1>
ray.init(worker_port_list=[10000, 10001, 10002, 10003])
</code></code></pre>
Code Reference: <code>src/ray/raylet/main.cc:55-60</code>
<code>DEFINE_int32(min_worker_port, 0, &quot;The lowest port that workers' gRPC servers will bind on.&quot;);
<p>DEFINE_int32(max_worker_port, 0, &quot;The highest port that workers' gRPC servers will bind on.&quot;);</p>
<p>DEFINE_string(worker_port_list, &quot;&quot;, &quot;An explicit list of ports that workers' gRPC servers will bind on.&quot;);</p>
<p></code></p>
<h2>Port Assignment Process</h2>
<p>----------------------------------------</p>
<h3>Worker Registration and Port Assignment</h3>
<p>When any worker (task or actor) starts, it follows this exact process:</p>
Code Reference: <code>src/ray/raylet/worker_pool.cc:796-812</code>
<code>// The port that this worker's gRPC server should listen on
<p>int port = 0;</p>
<p>Status status = GetNextFreePort(&amp;port);</p>
<p>if (!status.ok()) {</p>
<p>return PopWorkerStatus::Failed;</p>
<p>}</p>
<p>worker-&gt;SetAssignedPort(port);</p>
<p></code></p>
<h3>Port Allocation Function</h3>
Code Reference: <code>src/ray/raylet/worker_pool.cc:683-701</code>
<code>Status WorkerPool::GetNextFreePort(int *port) {
<p>if (free_ports_ == nullptr || free_ports_-&gt;empty()) {</p>
<p>return Status::Invalid(</p>
<p>&quot;No available ports. Please specify a wider port range using --min-worker-port and &quot;</p>
<p>&quot;--max-worker-port.&quot;);</p>
<p>}</p>
<p>// Try up to the current number of ports.</p>
<p>int current_size = free_ports_-&gt;size();</p>
<p>for (int i = 0; i &lt; current_size; i++) {</p>
<p>*port = free_ports_-&gt;front();</p>
<p>free_ports_-&gt;pop();</p>
<p>if (IsPortAvailable(*port)) {</p>
<p>return Status::OK();</p>
<p>} else {</p>
<p>// Port is occupied, try next one</p>
<p>free_ports_-&gt;push(*port);</p>
<p>}</p>
<p>}</p>
<p>return Status::Invalid(</p>
<p>&quot;No available ports. Please specify a wider port range using --min-worker-port and &quot;</p>
<p>&quot;--max-worker-port.&quot;);</p>
<p>}</p>
<p></code></p>
<h2>Actor vs Task Port Usage</h2>
<p>----------------------------------------</p>
<h3>Actors: Long-lived Port Dedication</h3>
<pre><code><code>@ray.remote
class MyActor:
def method(self):
return &quot;Hello&quot;
<h1>This actor gets a dedicated port for its entire lifetime</h1>
actor = MyActor.remote()
</code></code></pre>
<p>Characteristics:</p>
<p>- Dedicated Port: Each actor gets its own port</p>
<p>- Long-lived: Port is held until actor terminates/dies</p>
<p>- Persistent: Same port for all method calls on the actor</p>
<p>- gRPC Server: Actor runs a gRPC server on its assigned port</p>
<h3>Tasks: Short-lived Port Usage</h3>
<code>@ray.remote
<p>def my_task():</p>
<p>return &quot;Hello&quot;</p>
<h1>This task gets a port from the pool temporarily</h1>
<p>future = my_task.remote()</p>
<p></code></p>
<p>Characteristics:</p>
<p>- Temporary Port: Task gets port from pool when worker is assigned</p>
<p>- Short-lived: Port returned to pool when task completes</p>
<p>- Worker Reuse: Same worker (and port) can execute multiple sequential tasks</p>
<p>- Pooled Workers: Tasks share a pool of workers</p>
<h2>Worker Pool Size Limits</h2>
<p>----------------------------------------</p>
<h3>The <code>num_workers_soft_limit</code> Configuration</h3>
<p>This is the critical parameter that controls maximum port usage.</p>
Code Reference: <code>src/ray/raylet/node_manager.cc:130-150</code>
<code>[this, config]() {
<p>// Callback to determine the maximum number of idle workers to keep around.</p>
<p>if (config.num_workers_soft_limit &gt;= 0) {</p>
<p>return config.num_workers_soft_limit;</p>
<p>}</p>
<p>// If no limit is provided, use the available number of CPUs,</p>
<p>// assuming that each incoming task will likely require 1 CPU.</p>
<p>return static_cast&lt;int64_t&gt;(</p>
<p>cluster_resource_scheduler_-&gt;GetLocalResourceManager()</p>
<p>.GetLocalAvailableCpus());</p>
<p>}</p>
<p></code></p>
Default Behavior: <code>num_workers_soft_limit = -1</code> ‚Üí defaults to CPU count
Code Reference: <code>src/ray/common/ray_config_def.h:617-624</code>
<code>/// The soft limit of the number of workers to keep around.
<p>/// We apply this limit to the idle workers instead of total workers,</p>
<p>/// because the total number of workers used depends on the</p>
<p>/// application. -1 means using the available number of CPUs.</p>
<p>RAY_CONFIG(int64_t, num_workers_soft_limit, -1)</p>
<p></code></p>
<h3>Configuration Examples</h3>
<pre><code><code># Limit to 50 concurrent workers (and thus 50 ports max)
ray start --num-workers-soft-limit=50
<h1>Python API</h1>
ray.init(num_workers_soft_limit=50)
</code></code></pre>
<h2>Port Exhaustion Scenarios</h2>
<p>----------------------------------------</p>
<h3>When Do You Run Out of Ports?</h3>
<h4>Scenario 1: Too Many Concurrent Actors</h4>
<pre><code><code># Node: 16 CPUs, Default ports: 16
<h1>Problem: Creating 100 long-lived actors</h1>
actors = [MyActor.remote() for _ in range(100)]  # ‚ùå FAIL after 16
</code></code></pre>
<h4>Scenario 2: Fractional CPU Tasks</h4>
<pre><code><code># Node: 16 CPUs, Default ports: 16  
<h1>Problem: Tasks with fractional CPU requirements</h1>
@ray.remote(num_cpus=0.1)  # Only 0.1 CPU per task
def light_task():
return &quot;done&quot;
<h1>Can theoretically run 160 concurrent tasks (16 CPUs / 0.1)</h1>
<h1>But only 16 ports available!</h1>
futures = [light_task.remote() for _ in range(160)]  # ‚ùå FAIL after 16
</code></code></pre>
<h3>Error Messages</h3>
Code Reference: <code>src/ray/raylet/worker_pool.cc:693-701</code>
<code>return Status::Invalid(
<p>&quot;No available ports. Please specify a wider port range using --min-worker-port and &quot;</p>
<p>&quot;--max-worker-port.&quot;);</p>
<p></code></p>
<h2>Best Practices &amp; Solutions</h2>
<p>----------------------------------------</p>
<h3>1. Calculate Required Ports</h3>
<pre><code><code>Required Ports = Max Concurrent Workers
= Max(Long-lived Actors + Peak Concurrent Tasks)
</code></code></pre>
<h3>2. Configure Appropriate Port Range</h3>
<pre><code><code># For 1000 concurrent workers
ray start --min-worker-port=10000 --max-worker-port=11000 --num-workers-soft-limit=1000
</code></code></pre>
<h3>3. Use Explicit Port Lists for Control</h3>
<pre><code><code># Firewall-friendly: specify exact ports
ray start --worker-port-list=&quot;10000,10001,10002,10003,10004&quot;
</code></code></pre>
<h3>4. Monitor Port Usage</h3>
<pre><code><code># Check cluster resources
print(ray.cluster_resources())
<h1>Check current worker count</h1>
import ray._private.worker
print(len(ray._private.worker.global_worker.core_worker.get_all_reference_counts()))
</code></code></pre>
<h2>Advanced Configuration Examples</h2>
<p>----------------------------------------</p>
<h3>Large Cluster Setup (1000 nodes)</h3>
<pre><code><code># Head node
ray start --head \
--port=6379 \
--min-worker-port=20000 \
--max-worker-port=25000 \
--num-workers-soft-limit=5000
<h1>Worker nodes  </h1>
ray start --address=head_ip:6379 \
--min-worker-port=20000 \
--max-worker-port=25000 \
--num-workers-soft-limit=5000
</code></code></pre>
<h3>Actor-Heavy Workload</h3>
<pre><code><code># For 500 concurrent actors per node
ray start --min-worker-port=30000 --max-worker-port=30500 --num-workers-soft-limit=500
</code></code></pre>
<h3>Mixed Workload (Actors + Tasks)</h3>
<pre><code><code># 100 actors + 400 peak concurrent tasks = 500 total
ray start --min-worker-port=40000 --max-worker-port=40500 --num-workers-soft-limit=500
</code></code></pre>
<h2>Port Usage Summary</h2>
<p>----------------------------------------</p>
<p>[TABLE]</p>
<p>| </p>
<p>Component |</p>
<p>Port Usage |</p>
<p>Lifetime |</p>
<p>Pool Source |</p>
<p>|</p>
<p>| </p>
<p>Actor |</p>
<p>1 dedicated port |</p>
<p>Until actor dies |</p>
<p>Worker port pool |</p>
<p>|</p>
<p>| </p>
<p>Task |</p>
<p>1 temporary port |</p>
<p>Until task completes |</p>
<p>Worker port pool |</p>
<p>|</p>
<p>| </p>
<p>Node Manager |</p>
<p>1 fixed port |</p>
<p>Node lifetime |</p>
<p>Fixed configuration |</p>
<p>|</p>
<p>| </p>
<p>Object Manager |</p>
<p>1 fixed port |</p>
<p>Node lifetime |</p>
<p>Fixed configuration |</p>
<p>|</p>
<p>| </p>
<p>GCS |</p>
<p>1 fixed port |</p>
<p>Cluster lifetime |</p>
<p>Fixed configuration |</p>
<p>|</p>
<p>| </p>
<p>Dashboard |</p>
<p>1 fixed port |</p>
<p>Node lifetime |</p>
<p>Fixed configuration |</p>
<p>|</p>
<p>[/TABLE]</p>
<h2>Total Port Calculation for Ray Cluster</h2>
<p>----------------------------------------</p>
<pre><code><code>Total Ports Per Node = Core Ray Ports + Worker Ports
Core Ray Ports = 7 (fixed)
- Node Manager: 1
- Object Manager: 1  
- Metrics Agent: 1
- Runtime Env Agent: 1
- Dashboard Agent: 1
- Metrics Export: 1
- Ray Client Server: 1 (head only)
Worker Ports = num_workers_soft_limit (configurable)
- Default: CPU count
- Configurable: --num-workers-soft-limit
Example for 16-CPU node:
Total = 7 + 16 = 23 ports minimum
</code></code></pre>
<h2>Common Issues and Solutions</h2>
<p>----------------------------------------</p>
<h3>Issue 1: Port Exhaustion with Fractional CPU Tasks</h3>
Problem: <code>num_workers_soft_limit</code> defaults to CPU count, but fractional CPU tasks can exceed this.
Solution: Increase <code>num_workers_soft_limit</code> and port range:
<code>ray start --num-workers-soft_limit=100 --min-worker-port=20000 --max-worker-port=20100
<p></code></p>
<h3>Issue 2: Firewall Restrictions</h3>
<p>Problem: Need to specify exact ports for firewall rules.</p>
<p>Solution: Use explicit port lists:</p>
<code>ray start --worker-port-list=&quot;10000,10001,10002,10003&quot;
<p></code></p>
<h3>Issue 3: Actor Port Leakage</h3>
<p>Problem: Dead actors not releasing ports properly.</p>
<p>Solution: Ensure proper actor cleanup:</p>
<code># Explicit cleanup
<p>ray.kill(actor)</p>
<p>del actor</p>
<h1>Or use context managers for automatic cleanup</h1>
<p></code></p>
<h2>Code References Summary</h2>
<p>----------------------------------------</p>
<p>[TABLE]</p>
<p>| </p>
<p>Component |</p>
<p>File |</p>
<p>Key Functions |</p>
<p>|</p>
<p>| </p>
<p>Port Pool Management |</p>
<code>src/ray/raylet/worker_pool.cc</code> |
<code>GetNextFreePort()</code>, <code>PopWorker()</code> |
<p>|</p>
<p>| </p>
<p>Port Configuration |</p>
<code>src/ray/raylet/main.cc</code> |
<p>Command line flag definitions |</p>
<p>|</p>
<p>| </p>
<p>Worker Limits |</p>
<code>src/ray/raylet/node_manager.cc</code> |
<code>num_workers_soft_limit</code> logic |
<p>|</p>
<p>| </p>
<p>Port Pool Storage |</p>
<code>src/ray/raylet/worker_pool.h</code> |
<code>free_ports_</code> member variable |
<p>|</p>
<p>[/TABLE]</p>
<h2>Conclusion</h2>
<p>----------------------------------------</p>
<p>Ray's port allocation is straightforward but requires careful planning:</p>
<p>‚Ä¢ Single shared pool for all workers (actors + tasks)</p>
<p>‚Ä¢ One port per concurrent worker</p>
‚Ä¢ Bounded by <code>num_workers_soft_limit</code> (defaults to CPU count)
<p>‚Ä¢ Configure based on your workload (actors vs tasks, CPU requirements)</p>
<p>‚Ä¢ Plan for peak concurrency, not just average usage</p>
<p>Understanding this model helps you properly size your port ranges and avoid common pitfalls in production Ray deployments.</p>
<h2>Advanced Q&amp;A: Port Management Deep Dive</h2>
<p>----------------------------------------</p>
<p>This section covers advanced questions about Ray's port management system that frequently arise in production environments.</p>
<h3>Q1: What happens when a task invokes ray.get() and blocks?</h3>
CPU: ‚úÖ Task RELEASES CPU when blocked on <code>ray.get()</code>
<p>Port: ‚ùå Port is KEPT OPEN during blocking</p>
<p>Detailed Explanation:</p>
When a task calls <code>ray.get()</code> and blocks waiting for another task's result:
<p>‚Ä¢ CPU Resource Management:</p>
<code>cpp
<p>// Code Reference: src/ray/raylet/local_task_manager.cc</p>
<p>bool LocalTaskManager::ReleaseCpuResourcesFromBlockedWorker(</p>
<p>std::shared_ptr&lt;WorkerInterface&gt; worker) {</p>
<p>// CPU resources are released back to the scheduler</p>
<p>}</code></p>
<p>‚Ä¢ The worker's CPU allocation is returned to the resource pool</p>
<p>‚Ä¢ Other tasks can use those CPU resources</p>
<p>‚Ä¢ </p>
<p>This prevents deadlocks in resource-constrained environments</p>
<p>‚Ä¢ </p>
<p>Port Resource Management:</p>
<code>cpp
<p>// Code Reference: src/ray/raylet/worker.h</p>
/// Whether the worker is blocked. Workers become blocked in a </code>ray.get<code>
<p>bool blocked_;</code></p>
<p>‚Ä¢ The worker keeps its gRPC server port open</p>
<p>‚Ä¢ Port remains allocated until task completely finishes</p>
<p>‚Ä¢ This is necessary for receiving results and maintaining communication</p>
<p>Why Ports Stay Open: </p>
<p>- The worker's gRPC server must remain accessible to receive the result</p>
<p>- Communication channels with raylet must stay active</p>
<p>- The worker process itself continues running (just blocked)</p>
<h3>Q2: Who assigns tasks to raylet and via which port?</h3>
<p>Answer: GCS (Global Control Service) assigns tasks to raylets via the Node Manager Port</p>
<p>Complete Task Assignment Flow:</p>
<code>1. Task Submission:
<p>Worker/Driver ‚Üí GCS (via GCS Port ~6379)</p>
<p>2. Task Scheduling:</p>
<p>GCS ‚Üí Raylet (via Node Manager Port ~10001)</p>
<p>3. Worker Assignment:</p>
<p>Raylet ‚Üí Worker (via Worker's gRPC Port from pool)</p>
<p>4. Result Return:</p>
<p>Worker ‚Üí Raylet ‚Üí GCS ‚Üí Requester</p>
<p></code></p>
<p>Code References:</p>
<code>// Node Manager Port Configuration
<p>// src/ray/raylet/main.cc:48</p>
<p>DEFINE_int32(node_manager_port, -1, &quot;The port of node manager.&quot;);</p>
<p>// GCS to Raylet Communication</p>
<p>// Tasks are assigned via gRPC calls to the Node Manager service</p>
<p>// The raylet listens on node_manager_port for task assignments</p>
<p></code></p>
<p>Port Usage:</p>
<p>- GCS Port: For initial task submission and cluster coordination</p>
<p>- Node Manager Port: For task assignment from GCS to raylet</p>
<p>- Worker Ports: For task execution and inter-task communication</p>
<h3>Q3: What is Ray communication for tasks on the same node?</h3>
<p>Answer: Tasks on the same node communicate directly via worker ports, bypassing raylet for task-to-task calls.</p>
<p>Same-Node Communication Flow:</p>
<code>Task A (Port 10000) ‚Üí Direct gRPC ‚Üí Task B (Port 10001)
<p>‚Üë</p>
<p>(No raylet involvement)</p>
<p></code></p>
<p>Cross-Node Communication Flow:</p>
<code>Task A (Node 1, Port 10000) ‚Üí Raylet 1 ‚Üí Network ‚Üí Raylet 2 ‚Üí Task B (Node 2, Port 10001)
<p></code></p>
<p>Why Direct Communication:</p>
<p>- Performance: Eliminates raylet as middleman</p>
<p>- Efficiency: Reduces network hops and latency</p>
<p>- Scalability: Reduces load on raylet for local communication</p>
<h3>Q4: Can ray.get() cause port starvation?</h3>
<p>YES! This is a critical production consideration.</p>
<p>Scenario: </p>
<p>- Available ports: 64 (typical small range)</p>
- Running tasks: 60 (all blocked on <code>ray.get()</code>)
<p>- New task requests: 10</p>
<p>Result: </p>
<p>- All 64 ports occupied by blocked workers</p>
<p>- New tasks cannot start ‚Üí Port starvation</p>
<p>- Cluster appears "hung" despite available CPU</p>
<p>Solutions:</p>
<p>1. Increase Port Range:</p>
<code>bash
<p>ray start --min-worker-port=10000 --max-worker-port=20000  # 10K ports</code></p>
<p>‚Ä¢ </p>
<p>Tune Worker Pool:</p>
<code>bash
<p>ray start --num-workers-soft_limit=1000  # Allow more concurrent workers</code></p>
<p>‚Ä¢ </p>
<p>Application Design:</p>
``<code>python
<h1>Instead of blocking many workers</h1>
<p>futures = [task.remote() for _ in range(1000)]</p>
<p>results = ray.get(futures)  # Single blocking point</p>
<h1>Better: Batch processing</h1>
<p>batch_size = 50</p>
<p>for batch in chunks(futures, batch_size):</p>
<p>ray.get(batch)  # Process in smaller batches</p>
</code>`<code>
<h3>Q5: Port allocation for different worker types</h3>
<p>All worker types use the same port pool:</p>
<p>[TABLE]</p>
<p>| </p>
<p>Worker Type |</p>
<p>Port Source |</p>
<p>Port Lifetime |</p>
<p>Notes |</p>
<p>|</p>
<p>| </p>
<p>Actor Workers |</p>
<p>Worker port pool |</p>
<p>Until actor dies |</p>
<p>Dedicated, long-lived |</p>
<p>|</p>
<p>| </p>
<p>Task Workers |</p>
<p>Worker port pool |</p>
<p>Until task completes |</p>
<p>Shared, short-lived |</p>
<p>|</p>
<p>| </p>
<p>Driver Workers |</p>
<p>Worker port pool |</p>
<p>Until driver exits |</p>
<p>Dedicated, session-lived |</p>
<p>|</p>
<p>[/TABLE]</p>
<p>Code Reference:</p>
<p></code>// src/ray/raylet/worker_pool.cc:683-700</p>
<p>Status WorkerPool::GetNextFreePort(int *port) {</p>
<p>// Same pool used for ALL worker types</p>
<p>if (free_ports_-&gt;empty()) {</p>
<p>return Status::Invalid(&quot;No available ports...&quot;);</p>
<p>}</p>
<p>*port = free_ports_-&gt;front();</p>
<p>free_ports_-&gt;pop();</p>
<p>return Status::OK();</p>
<p>}</p>
<code>
<h3>Q6: Maximum theoretical port usage</h3>
<p>Calculation:</p>
<p></code>Max Ports = min(</p>
<p>max_worker_port - min_worker_port + 1,  // Port range size</p>
<p>num_workers_soft_limit,                 // Worker pool limit</p>
<p>System file descriptor limit            // OS limit</p>
<p>)</p>
<code>
<p>Example:</p>
<p></code>Node: 16 CPUs</p>
<p>Port Range: 10000-65535 (55,536 ports)</p>
<p>Worker Limit: Default = 16 (CPU count)</p>
<p>Actual Max: 16 ports (limited by worker pool)</p>
<code>
<p>To Use More Ports:</p>
<p></code># Increase worker pool beyond CPU count</p>
<p>ray start --num_workers_soft_limit=1000 --min-worker-port=10000 --max-worker-port=11000</p>
<h1>Result: Can use up to 1000 ports concurrently</h1>
<code>
<h2>Production Recommendations</h2>
<p>----------------------------------------</p>
<p>Based on the above Q&amp;A, here are production recommendations:</p>
<h3>Port Planning:</h3>
‚Ä¢ Calculate realistic port needs: </code>(Expected concurrent tasks + actors) * 1.5<code>
<p>‚Ä¢ Set generous ranges: Better to over-provision than under-provision</p>
‚Ä¢ Monitor port usage: Track </code>free_ports_<code> queue size
<h3>Application Design:</h3>
‚Ä¢ Minimize blocking: Reduce </code>ray.get()<code> calls in tight loops
<p>‚Ä¢ Batch operations: Process results in batches, not individually</p>
‚Ä¢ Use futures wisely: Collect futures first, then </code>ray.get()<code> in batches
<h3>Configuration:</h3>
<p>‚Ä¢ Explicit port lists for controlled environments</p>
<p>‚Ä¢ Wide port ranges for dynamic workloads  </p>
<p>‚Ä¢ Monitor worker pool metrics in production</p>
<p>This comprehensive understanding of Ray's port management will help you design robust, scalable Ray applications that avoid common port-related pitfalls in production environments. </p>
<h2>Sequence Diagrams and Flow Charts</h2>
<p>----------------------------------------</p>
<p>This section provides visual representations of Ray's port allocation and communication flows to help understand the system architecture.</p>
<h3>1. Port Pool Initialization Flow</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>üìÅ Text-based diagram (backup)</p>
<p></code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Raylet Start  ‚îÇ    ‚îÇ   WorkerPool     ‚îÇ    ‚îÇ   Port Queue    ‚îÇ</p>
<p>‚îÇ                 ‚îÇ    ‚îÇ   Constructor    ‚îÇ    ‚îÇ                 ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>‚îÇ 1. Initialize        ‚îÇ                       ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ                       ‚îÇ</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>‚îÇ                      ‚îÇ 2. Create free_ports_ ‚îÇ</p>
<p>‚îÇ                      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>‚îÇ                      ‚îÇ 3. Parse port range   ‚îÇ</p>
<p>‚îÇ                      ‚îÇ    or explicit list   ‚îÇ</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>‚îÇ                      ‚îÇ 4. Push ports to queue‚îÇ</p>
<p>‚îÇ                      ‚îÇ    (10000‚Üí10100)      ‚îÇ</p>
<p>‚îÇ                      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>‚îÇ 5. Pool Ready        ‚îÇ                       ‚îÇ</p>
<p>‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                       ‚îÇ</p>
<p>‚îÇ                      ‚îÇ                       ‚îÇ</p>
<p>Port Range: --min-worker-port=10000 --max-worker-port=10100</p>
<p>Result: 101 ports in queue [10000, 10001, 10002, ..., 10100]</p>
<code>
<h3>2. Worker Registration and Port Assignment Sequence</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>üìÅ Text-based diagram (backup)</p>
<p></code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ  Worker   ‚îÇ  ‚îÇ   Raylet    ‚îÇ  ‚îÇ WorkerPool  ‚îÇ  ‚îÇ Port Queue  ‚îÇ</p>
<p>‚îÇ Process   ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ 1. Register   ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ 2. PopWorker() ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ 3. GetNextFreePort()</p>
<p>‚îÇ               ‚îÇ                ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ 4. port=10005 ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ 5. SetAssignedPort(10005)       ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ 6. Port: 10005‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ 7. Start gRPC ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ    Server on  ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ    port 10005 ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>‚îÇ               ‚îÇ                ‚îÇ                ‚îÇ</p>
<p>Result: Worker now has dedicated port 10005 for its gRPC server</p>
<code>
<h3>3. Task Assignment Flow Diagram</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>üìÅ Text-based diagram (backup)</p>
<p></code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Driver/   ‚îÇ    ‚îÇ     GCS     ‚îÇ    ‚îÇ   Raylet    ‚îÇ    ‚îÇ   Worker    ‚îÇ</p>
<p>‚îÇ   Client    ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ 1. task.remote() ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ 2. Schedule Task ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ    (find node)   ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ 3. RequestWorker ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ    Lease         ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ 4. PopWorker()   ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ    (assign port) ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ 5. WorkerLease   ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ    (port info)   ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ 6. SubmitTask    ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ    (to worker)   ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ 7. Execute</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ    Task</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ 8. Task Result  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ                  ‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ                  ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ 9. ray.get()     ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ    result        ‚îÇ                  ‚îÇ                  ‚îÇ</p>
<p>‚îÇ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îÇ                  ‚îÇ</p>
<p>Ports Used:</p>
<p>- GCS Port: ~6379 (Driver ‚Üí GCS)</p>
<p>- Node Manager Port: ~10001 (GCS ‚Üí Raylet)  </p>
<p>- Worker Port: from pool, e.g., 10005 (Task execution)</p>
<code>
<h3>4. Actor vs Task Port Usage Lifecycle</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>[Diagram content removed for EPUB version]</p>
<p>üìÅ Text-based diagram (backup)</p>
<p></code>ACTOR LIFECYCLE:</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                        Actor Lifetime                           ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ Create ‚Üí Get Port 10005 ‚Üí Keep Port ‚Üí Method Calls ‚Üí Die       ‚îÇ</p>
<p>‚îÇ   ‚Üì         ‚Üì              ‚Üì           ‚Üì             ‚Üì         ‚îÇ</p>
<p>‚îÇ Start    Dedicated      Port Held   Same Port    Return Port   ‚îÇ</p>
<p>‚îÇ          Port           Throughout   Used         to Pool      ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>TASK LIFECYCLE:</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Task A  ‚îÇ ‚îÇ   Task B  ‚îÇ ‚îÇ   Task C  ‚îÇ ‚îÇ   Task D  ‚îÇ ‚îÇ   Task E  ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇPort: 10005‚îÇ ‚îÇPort: 10005‚îÇ ‚îÇPort: 10006‚îÇ ‚îÇPort: 10005‚îÇ ‚îÇPort: 10007‚îÇ</p>
<p>‚îÇWorker: W1 ‚îÇ ‚îÇWorker: W1 ‚îÇ ‚îÇWorker: W2 ‚îÇ ‚îÇWorker: W1 ‚îÇ ‚îÇWorker: W3 ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚Üì             ‚Üì             ‚Üì             ‚Üì             ‚Üì</p>
<p>Finish        Reuse         New Port      Reuse         New Port</p>
<p>Same Worker    (W1 busy)    Same Worker   (W1,W2 busy)</p>
<p>Key Difference:</p>
<p>- Actors: 1 Actor = 1 Dedicated Port (Long-term)</p>
<p>- Tasks: 1 Worker = 1 Port, Multiple Tasks Share Worker (Short-term)</p>
<code>
<h3>5. Same-Node vs Cross-Node Communication Flow</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>üìÅ Text-based diagram (backup)</p>
<p></code>SAME NODE COMMUNICATION (Direct):</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Task A    ‚îÇ    Direct gRPC Call       ‚îÇ   Task B    ‚îÇ</p>
<p>‚îÇ (Port 10005)‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ (Port 10006)‚îÇ</p>
<p>‚îÇ   Worker 1  ‚îÇ                           ‚îÇ   Worker 2  ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>‚Üë                                         ‚Üë</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Same Raylet ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>Benefits: Low latency, No raylet overhead, High throughput</p>
<p>CROSS NODE COMMUNICATION (Via Raylet):</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Task A    ‚îÇ    ‚îÇ  Raylet 1   ‚îÇ    ‚îÇ  Raylet 2   ‚îÇ    ‚îÇ   Task B    ‚îÇ</p>
<p>‚îÇ (Port 10005)‚îÇ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ(Node Mgr    ‚îÇ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ(Node Mgr    ‚îÇ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ (Port 10006)‚îÇ</p>
<p>‚îÇ Node 1      ‚îÇ    ‚îÇ Port 10001) ‚îÇ    ‚îÇ Port 10001) ‚îÇ    ‚îÇ Node 2      ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>Benefits: Network routing, Load balancing, Fault tolerance</p>
<code>
<h3>6. Port Exhaustion Scenario Diagram</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>üìÅ Text-based diagram (backup)</p>
<p></code>NORMAL OPERATION:</p>
<p>Port Pool: [10000, 10001, 10002, 10003, 10004] (5 ports available)</p>
<p>Active Workers: 2</p>
<p>Available Ports: 3</p>
<p>Status: ‚úÖ HEALTHY</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Worker 1  ‚îÇ ‚îÇ   Worker 2  ‚îÇ ‚îÇ    Pool     ‚îÇ</p>
<p>‚îÇ Port: 10000 ‚îÇ ‚îÇ Port: 10001 ‚îÇ ‚îÇ [10002,     ‚îÇ</p>
<p>‚îÇ Status: BUSY‚îÇ ‚îÇ Status: BUSY‚îÇ ‚îÇ  10003,     ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  10004]     ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>PORT EXHAUSTION:</p>
<p>Port Pool: [] (0 ports available)</p>
<p>Active Workers: 5 (all blocked on ray.get())</p>
<p>Available Ports: 0</p>
<p>Status: ‚ùå STARVED</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ   Worker 1  ‚îÇ ‚îÇ   Worker 2  ‚îÇ ‚îÇ   Worker 3  ‚îÇ ‚îÇ   Worker 4  ‚îÇ ‚îÇ   Worker 5  ‚îÇ</p>
<p>‚îÇ Port: 10000 ‚îÇ ‚îÇ Port: 10001 ‚îÇ ‚îÇ Port: 10002 ‚îÇ ‚îÇ Port: 10003 ‚îÇ ‚îÇ Port: 10004 ‚îÇ</p>
<p>‚îÇBLOCKED:     ‚îÇ ‚îÇBLOCKED:     ‚îÇ ‚îÇBLOCKED:     ‚îÇ ‚îÇBLOCKED:     ‚îÇ ‚îÇBLOCKED:     ‚îÇ</p>
<p>‚îÇray.get()    ‚îÇ ‚îÇray.get()    ‚îÇ ‚îÇray.get()    ‚îÇ ‚îÇray.get()    ‚îÇ ‚îÇray.get()    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>New Task Request ‚Üí ‚ùå FAIL: &quot;No available ports&quot;</p>
<code>
<h3>7. Worker Pool Size vs Port Range Decision Tree</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>üìÅ Text-based diagram (backup)</p>
<p></code>                    ‚îå‚îÄ START: Configure Ray Worker Ports ‚îÄ‚îê</p>
<p>‚îÇ                                     ‚îÇ</p>
<p>‚ñº                                     ‚îÇ</p>
<p>‚îå‚îÄ What's your workload? ‚îÄ‚îê                    ‚îÇ</p>
<p>‚îÇ                         ‚îÇ                    ‚îÇ</p>
<p>‚ñº                         ‚ñº                    ‚îÇ</p>
<p>‚îå‚îÄ Many Actors ‚îÄ‚îê        ‚îå‚îÄ Many Tasks ‚îÄ‚îê             ‚îÇ</p>
<p>‚îÇ (Long-lived)  ‚îÇ        ‚îÇ (Short-lived) ‚îÇ             ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ</p>
<p>‚îÇ                        ‚îÇ                     ‚îÇ</p>
<p>‚ñº                        ‚ñº                     ‚îÇ</p>
<p>‚îå‚îÄ Port Need = ‚îÄ‚îê         ‚îå‚îÄ Port Need = ‚îÄ‚îê            ‚îÇ</p>
<p>‚îÇ Actor Count   ‚îÇ         ‚îÇ Peak Concurrent‚îÇ            ‚îÇ</p>
<p>‚îÇ Example: 500  ‚îÇ         ‚îÇ Tasks: 200     ‚îÇ            ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ</p>
<p>‚îÇ                         ‚îÇ                    ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Combine ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ</p>
<p>‚îÇ                                      ‚îÇ</p>
<p>‚ñº                                      ‚îÇ</p>
<p>‚îå‚îÄ Total Port Need ‚îÄ‚îê                         ‚îÇ</p>
<p>‚îÇ = 500 + 200 = 700 ‚îÇ                         ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ</p>
<p>‚îÇ                                    ‚îÇ</p>
<p>‚ñº                                    ‚îÇ</p>
<p>‚îå‚îÄ Configure num_workers_soft_limit = 700 ‚îÄ‚îê          ‚îÇ</p>
<p>‚îÇ Configure port range = 10000-10700       ‚îÇ          ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ</p>
<p>‚îÇ                                    ‚îÇ</p>
<p>‚ñº                                    ‚îÇ</p>
<p>‚îå‚îÄ RESULT: 700 concurrent workers ‚îÄ‚îê        ‚îÇ</p>
<p>‚îÇ Each with dedicated port         ‚îÇ        ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ</p>
<code>
<h3>8. Complete Ray Cluster Port Architecture</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>üìÅ Text-based diagram (backup)</p>
<p></code>RAY CLUSTER PORT LAYOUT:</p>
<p>HEAD NODE:</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                        HEAD NODE                           ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ GCS Server:           Port 6379                            ‚îÇ</p>
<p>‚îÇ Dashboard:            Port 8265                            ‚îÇ</p>
<p>‚îÇ Ray Client Server:    Port 10001                          ‚îÇ</p>
<p>‚îÇ Node Manager:         Port 10002                           ‚îÇ</p>
<p>‚îÇ Object Manager:       Port 10003                           ‚îÇ</p>
<p>‚îÇ Metrics Agent:        Port 10004                           ‚îÇ</p>
<p>‚îÇ Runtime Env Agent:    Port 10005                           ‚îÇ</p>
<p>‚îÇ                                                            ‚îÇ</p>
<p>‚îÇ Worker Pool:          Ports 20000-20100 (100 ports)       ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Actor 1:          Port 20000                           ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Actor 2:          Port 20001                           ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Task Worker 1:    Port 20002                           ‚îÇ</p>
<p>‚îÇ ‚îî‚îÄ Task Worker 2:    Port 20003                           ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>WORKER NODE 1:</p>
<p>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                      WORKER NODE 1                         ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ Node Manager:         Port 10002                           ‚îÇ</p>
<p>‚îÇ Object Manager:       Port 10003                           ‚îÇ</p>
<p>‚îÇ Metrics Agent:        Port 10004                           ‚îÇ</p>
<p>‚îÇ Runtime Env Agent:    Port 10005                           ‚îÇ</p>
<p>‚îÇ                                                            ‚îÇ</p>
<p>‚îÇ Worker Pool:          Ports 20000-20100 (100 ports)       ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Actor 3:          Port 20000                           ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Actor 4:          Port 20001                           ‚îÇ</p>
<p>‚îÇ ‚îú‚îÄ Task Worker 3:    Port 20002                           ‚îÇ</p>
<p>‚îÇ ‚îî‚îÄ Task Worker 4:    Port 20003                           ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>COMMUNICATION FLOWS:</p>
<p>Driver ‚îÄ‚îÄ(6379)‚îÄ‚îÄ‚Üí GCS ‚îÄ‚îÄ(10002)‚îÄ‚îÄ‚Üí Node Manager ‚îÄ‚îÄ(20000+)‚îÄ‚îÄ‚Üí Workers</p>
<p>‚Üë                      ‚Üì</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ Cluster State ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>Worker ‚îÄ‚îÄ(20000+)‚îÄ‚îÄ‚Üí Worker (Same Node: Direct)</p>
<p>Worker ‚îÄ‚îÄ(10003)‚îÄ‚îÄ‚îÄ‚Üí Object Manager ‚îÄ‚îÄ(Network)‚îÄ‚îÄ‚Üí Object Manager ‚îÄ‚îÄ(20000+)‚îÄ‚îÄ‚Üí Worker</p>
<code>
<h3>9. Visual Summary: Port Types and Usage Patterns</h3>
<p>[Diagram content removed for EPUB version]</p>
<p>üìÅ Text-based diagram (backup)</p>
<p></code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê</p>
<p>‚îÇ                          RAY PORT CATEGORIES                                ‚îÇ</p>
<p>‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§</p>
<p>‚îÇ                                                                             ‚îÇ</p>
<p>‚îÇ 1. INFRASTRUCTURE PORTS (Fixed, 1 per node)                               ‚îÇ</p>
<p>‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ</p>
<p>‚îÇ    ‚îÇ ‚Ä¢ GCS Port (6379)           ‚Ä¢ Node Manager (10002)             ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ ‚Ä¢ Dashboard (8265)          ‚Ä¢ Object Manager (10003)            ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ ‚Ä¢ Metrics Agent (10004)     ‚Ä¢ Runtime Env Agent (10005)        ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ</p>
<p>‚îÇ                                                                             ‚îÇ</p>
<p>‚îÇ 2. WORKER PORTS (Dynamic, from shared pool)                               ‚îÇ</p>
<p>‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ</p>
<p>‚îÇ    ‚îÇ                    SHARED PORT POOL                             ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    [20000, 20001, 20002, 20003, ..., 20100]                   ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ                         ‚îÇ                                       ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ           ‚ñº                           ‚ñº                        ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    ‚îå‚îÄ ACTORS ‚îÄ‚îê                ‚îå‚îÄ TASKS ‚îÄ‚îê                    ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    ‚îÇ Port: 1:1 ‚îÇ                ‚îÇPort: N:1 ‚îÇ                    ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    ‚îÇ Lifetime: ‚îÇ                ‚îÇLifetime: ‚îÇ                    ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    ‚îÇ Long      ‚îÇ                ‚îÇ Short    ‚îÇ                    ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ</p>
<p>‚îÇ                                                                             ‚îÇ</p>
<p>‚îÇ 3. PORT LIMITS                                                             ‚îÇ</p>
<p>‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ</p>
<p>‚îÇ    ‚îÇ Max Concurrent Ports = min(                                     ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ   Port Range Size,           // e.g., 100                      ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ   num_workers_soft_limit,    // e.g., 50                       ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ   System FD Limit           // e.g., 1024                      ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ )                                                               ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îÇ Result: 50 concurrent workers maximum                           ‚îÇ     ‚îÇ</p>
<p>‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ</p>
<p>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò</p>
<p>`</p>
<p>These Mermaid diagrams provide a modern, professional visualization of Ray's port allocation system while maintaining backward compatibility with the text-based versions. The diagrams will render beautifully in GitHub, GitLab, and most modern documentation platforms, while the collapsed text versions ensure the documentation works everywhere.</p>


</body>
</html>
